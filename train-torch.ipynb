{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from tqdm import trange\n",
    "# from torchtext.vocab import Vectors, GloVe, CharNGram, FastText\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torchtext import data as torchtext_data\n",
    "from torchtext import datasets\n",
    "\n",
    "import jittor as jt\n",
    "import gpt2\n",
    "import time\n",
    "\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myDataset(jt.dataset.Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        super().__init__()\n",
    "        self.x = x #2d\n",
    "        self.y = jt.array(y) #1d\n",
    "        lengths = [len(seq) for seq in x]\n",
    "        padding = jt.zeros(len(lengths), max(lengths))\n",
    "        for i, seq in enumerate(x):\n",
    "            padding[i,:lengths[i]] = seq[:lengths[i]]\n",
    "        self.x = padding\n",
    "    \n",
    "    def __getitem__(self, k):\n",
    "        return self.x[k], self.y[k]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "tokenizer = transformers.GPT2Tokenizer.from_pretrained('gpt2-medium')\n",
    "# model = transformers.GPT2LMHeadModel.from_pretrained('gpt2-medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationHead(jt.nn.Module):\n",
    "    def __init__(self, class_size=5, embed_size=2048):\n",
    "        super().__init__()\n",
    "        self.class_size = class_size\n",
    "        self.embed_size = embed_size\n",
    "        self.mlp = jt.nn.Linear(embed_size, class_size)\n",
    "    def execute(self, hidden_state):\n",
    "        lm_logits = self.mlp(hidden_state)\n",
    "        return lm_logits\n",
    "\n",
    "class Discriminator2mean(jt.nn.Module):\n",
    "    def __init__(self, class_size=5, embed_size=1024, head=None):\n",
    "        super().__init__()\n",
    "        if head == None:\n",
    "            self.classifierhead = ClassificationHead(class_size=class_size, embed_size=embed_size)\n",
    "        else:\n",
    "            self.classifierhead = head\n",
    "        self.model = transformers.GPT2LMHeadModel.from_pretrained('gpt2-medium')\n",
    "        self.embed_size = embed_size\n",
    "    \n",
    "    def get_classifier(self):\n",
    "        return self.classifierhead\n",
    "\n",
    "    def get_classifier_param(self):\n",
    "        return self.classifierhead.parameters()\n",
    "\n",
    "    def execute(self, x):\n",
    "        mask_src = 1 - x.equal(0).unsqueeze(1).detach()\n",
    "        mask_src = mask_src.repeat(1, self.embed_size, 1) #batch_size, 1024, length (repeat each sentence for 1024 times)\n",
    "        mask_src = torch.tensor(mask_src.tolist())\n",
    "        x = torch.tensor(x.tolist(),dtype=torch.long)\n",
    "        output_dict = self.model(x, output_hidden_states=True)\n",
    "        hidden = output_dict.hidden_states[-1]\n",
    "\n",
    "        hidden = hidden.permute(0, 2, 1)\n",
    "        hidden = hidden * mask_src  # / torch.sum(mask_src, dim=-1).unsqueeze(2).repeat(1, 1, batch_length)\n",
    "        #\n",
    "        hidden = hidden.permute(0, 2, 1)\n",
    "        x =  torch.sum(hidden, dim=1)/(torch.sum(mask_src, dim=-1) + 1e-10)\n",
    "        \n",
    "        x = jt.array(x.tolist(), dtype=jt.int64)\n",
    "        x = self.classifierhead(x)\n",
    "        x = jt.nn.log_softmax(x, dim=-1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "jt.flags.use_cuda = jt.has_cuda\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Train a discriminator on top of GPT-2 representations')\n",
    "parser.add_argument('--batch_size', type=int, default=64, metavar='N',\n",
    "                    help='input batch size for training (default: 64)')\n",
    "parser.add_argument('--log_interval', type=int, default=10, metavar='N',\n",
    "                    help='how many batches to wait before logging training status')\n",
    "parser.add_argument('--epochs', type=int, default=10, metavar='N',\n",
    "                    help='Number of training epochs')\n",
    "parser.add_argument('--save_path', type=str, default='', help='whether to save the model')\n",
    "parser.add_argument('--load_path', type=str, default='')\n",
    "parser.add_argument('--dataset_label', type=str, default='SST',choices=('SST', 'clickbait', 'toxic'))\n",
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.dataset_label == 'SST':\n",
    "    text = torchtext_data.Field()\n",
    "    label = torchtext_data.Field(sequential=False)\n",
    "    train_data, val_data, test_data = datasets.SST.splits(text, label, fine_grained=True, train_subtrees=True,\n",
    "                                                            # filter_pred=lambda ex: ex.label != 'neutral'\n",
    "                                                            )\n",
    "    d = {\"positive\": 0, \"negative\": 1, \"very positive\": 2, \"very negative\": 3, \"neutral\": 4}\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(len(train_data)):\n",
    "        seq = TreebankWordDetokenizer().detokenize(vars(train_data[i])[\"text\"])\n",
    "        seq = tokenizer.encode(seq)\n",
    "        x.append(seq)\n",
    "        y.append(d[vars(train_data[i])[\"label\"]])\n",
    "    train_dataset = myDataset(x,y).set_attrs(batch_size=args.batch_size,shuffle=True)\n",
    "\n",
    "    test_x = []\n",
    "    test_y = []\n",
    "    for i in range(len(test_data)):\n",
    "        seq = TreebankWordDetokenizer().detokenize(vars(test_data[i])[\"text\"])\n",
    "        seq = tokenizer.encode(seq)\n",
    "        seq = [50256] + seq\n",
    "        #seq = torch.tensor([50256] + seq, device=device, dtype=torch.long)\n",
    "        test_x.append(seq)\n",
    "        test_y.append(d[vars(test_data[i])[\"label\"]])\n",
    "    test_dataset = myDataset(test_x, test_y).set_attrs(batch_size=args.batch_size,shuffle=True)\n",
    "elif args.dataset_label == 'clickbait':\n",
    "    pass\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(data_loader, discriminator:Discriminator2mean, args=None):\n",
    "    optimizer = jt.optim.Adam(discriminator.get_classifier_param(), lr=0.0001)\n",
    "    for epoch in range(args.epochs):\n",
    "        for batch_idx, (data, target) in enumerate(data_loader):\n",
    "            print('Epoch: {}, batch: {}'.format(epoch,batch_idx))\n",
    "            start = time.time()\n",
    "            data, target = data, target.reshape(-1) # data is 2-d list [batch_size, length(after padding)], target is 1-d list [batch_size]\n",
    "            optimizer.zero_grad()\n",
    "            output = discriminator(data)\n",
    "            loss = jt.nn.nll_loss(output, target)\n",
    "            optimizer.step(loss)\n",
    "            print('batch time cost: {}'.format(time.time() - start))\n",
    "            if batch_idx % args.log_interval == 0:\n",
    "                print('Relu Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(data_loader),\n",
    "                        batch_idx * len(data) / len(data_loader), loss.item()))\n",
    "        head = discriminator.get_classifier()\n",
    "        head.save(args.dataset_label+'-'+str(epoch)+'.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch(data_loader, discriminator, args=None):\n",
    "    discriminator.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with jt.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            output = discriminator(data)\n",
    "            test_loss += jt.nn.nll_loss(output, target.reshape(-1)).item()  # sum up batch loss\n",
    "            pred,_ = output.argmax(dim=1, keepdims=True)  # get the index of the max log-probability\n",
    "            correct += pred.equal(target.reshape(pred.shape)).sum().item()\n",
    "\n",
    "    print('\\nRelu Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(data_loader),\n",
    "        100. * correct / len(data_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relu Test set: Average loss: 57.9225, Accuracy: 545/2210 (25%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, batch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fg/906sj12s2650mts7g69skdwc0000gn/T/ipykernel_2850/4016484757.py:31: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  x = torch.tensor(x.tolist(),dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss None\n",
      "batch time cost: 11.179395198822021\n",
      "Relu Train Epoch: 0 [0/318582 (0%)]\tLoss: 6.557239\n",
      "Epoch: 0, batch: 1\n",
      "loss None\n",
      "batch time cost: 5.505015850067139\n",
      "Epoch: 0, batch: 2\n",
      "loss None\n",
      "batch time cost: 5.310577154159546\n",
      "Epoch: 0, batch: 3\n",
      "loss None\n",
      "batch time cost: 5.27536416053772\n",
      "Epoch: 0, batch: 4\n",
      "loss None\n",
      "batch time cost: 5.247416734695435\n",
      "Epoch: 0, batch: 5\n",
      "loss None\n",
      "batch time cost: 8.259428977966309\n",
      "Epoch: 0, batch: 6\n",
      "loss None\n",
      "batch time cost: 8.46963381767273\n",
      "Epoch: 0, batch: 7\n",
      "loss None\n",
      "batch time cost: 8.646962881088257\n",
      "Epoch: 0, batch: 8\n",
      "loss None\n",
      "batch time cost: 8.833514928817749\n",
      "Epoch: 0, batch: 9\n",
      "loss None\n",
      "batch time cost: 5.352841138839722\n",
      "Epoch: 0, batch: 10\n",
      "loss None\n",
      "batch time cost: 5.294504880905151\n",
      "Relu Train Epoch: 0 [640/318582 (0%)]\tLoss: 5.426012\n",
      "Epoch: 0, batch: 11\n",
      "loss None\n",
      "batch time cost: 5.253703832626343\n",
      "Epoch: 0, batch: 12\n",
      "loss None\n",
      "batch time cost: 5.6236412525177\n",
      "Epoch: 0, batch: 13\n",
      "loss None\n",
      "batch time cost: 5.2580578327178955\n",
      "Epoch: 0, batch: 14\n",
      "loss None\n",
      "batch time cost: 5.26183295249939\n",
      "Epoch: 0, batch: 15\n",
      "loss None\n",
      "batch time cost: 7.521259069442749\n",
      "Epoch: 0, batch: 16\n",
      "loss None\n",
      "batch time cost: 5.881137847900391\n",
      "Epoch: 0, batch: 17\n",
      "loss None\n",
      "batch time cost: 8.026710033416748\n",
      "Epoch: 0, batch: 18\n",
      "loss None\n",
      "batch time cost: 8.191841125488281\n",
      "Epoch: 0, batch: 19\n",
      "loss None\n",
      "batch time cost: 5.6042640209198\n",
      "Epoch: 0, batch: 20\n",
      "loss None\n",
      "batch time cost: 5.28273606300354\n",
      "Relu Train Epoch: 0 [1280/318582 (0%)]\tLoss: 4.988530\n",
      "Epoch: 0, batch: 21\n",
      "loss None\n",
      "batch time cost: 5.233374834060669\n",
      "Epoch: 0, batch: 22\n",
      "loss None\n",
      "batch time cost: 5.259649991989136\n",
      "Epoch: 0, batch: 23\n",
      "loss None\n",
      "batch time cost: 5.232970952987671\n",
      "Epoch: 0, batch: 24\n",
      "loss None\n",
      "batch time cost: 5.267880201339722\n",
      "Epoch: 0, batch: 25\n",
      "loss None\n",
      "batch time cost: 5.282096862792969\n",
      "Epoch: 0, batch: 26\n",
      "loss None\n",
      "batch time cost: 5.6006999015808105\n",
      "Epoch: 0, batch: 27\n",
      "loss None\n",
      "batch time cost: 5.24992823600769\n",
      "Epoch: 0, batch: 28\n",
      "loss None\n",
      "batch time cost: 5.239974021911621\n",
      "Epoch: 0, batch: 29\n",
      "loss None\n",
      "batch time cost: 5.275087833404541\n",
      "Epoch: 0, batch: 30\n",
      "loss None\n",
      "batch time cost: 5.253041982650757\n",
      "Relu Train Epoch: 0 [1920/318582 (0%)]\tLoss: 4.299167\n",
      "Epoch: 0, batch: 31\n",
      "loss None\n",
      "batch time cost: 5.2140727043151855\n",
      "Epoch: 0, batch: 32\n",
      "loss None\n",
      "batch time cost: 5.248034954071045\n",
      "Epoch: 0, batch: 33\n",
      "loss None\n",
      "batch time cost: 5.288733243942261\n",
      "Epoch: 0, batch: 34\n",
      "loss None\n",
      "batch time cost: 5.609785795211792\n",
      "Epoch: 0, batch: 35\n",
      "loss None\n",
      "batch time cost: 6.176415920257568\n",
      "Epoch: 0, batch: 36\n",
      "loss None\n",
      "batch time cost: 8.348108053207397\n",
      "Epoch: 0, batch: 37\n",
      "loss None\n",
      "batch time cost: 5.279531002044678\n",
      "Epoch: 0, batch: 38\n",
      "loss None\n",
      "batch time cost: 5.214754819869995\n",
      "Epoch: 0, batch: 39\n",
      "loss None\n",
      "batch time cost: 5.248502969741821\n",
      "Epoch: 0, batch: 40\n",
      "loss None\n",
      "batch time cost: 5.269841909408569\n",
      "Relu Train Epoch: 0 [2560/318582 (0%)]\tLoss: 3.924530\n",
      "Epoch: 0, batch: 41\n",
      "loss None\n",
      "batch time cost: 5.7113611698150635\n",
      "Epoch: 0, batch: 42\n",
      "loss None\n",
      "batch time cost: 5.297151327133179\n",
      "Epoch: 0, batch: 43\n",
      "loss None\n",
      "batch time cost: 5.292831897735596\n",
      "Epoch: 0, batch: 44\n",
      "loss None\n",
      "batch time cost: 5.263806343078613\n",
      "Epoch: 0, batch: 45\n",
      "loss None\n",
      "batch time cost: 5.59522819519043\n",
      "Epoch: 0, batch: 46\n",
      "loss None\n",
      "batch time cost: 5.283582925796509\n",
      "Epoch: 0, batch: 47\n",
      "loss None\n",
      "batch time cost: 5.28004789352417\n",
      "Epoch: 0, batch: 48\n",
      "loss None\n",
      "batch time cost: 5.561652898788452\n",
      "Epoch: 0, batch: 49\n",
      "loss None\n",
      "batch time cost: 5.274637937545776\n",
      "Epoch: 0, batch: 50\n",
      "loss None\n",
      "batch time cost: 5.252709150314331\n",
      "Relu Train Epoch: 0 [3200/318582 (0%)]\tLoss: 3.509519\n",
      "Epoch: 0, batch: 51\n",
      "loss None\n",
      "batch time cost: 5.259476184844971\n",
      "Epoch: 0, batch: 52\n",
      "loss None\n",
      "batch time cost: 5.280719995498657\n",
      "Epoch: 0, batch: 53\n",
      "loss None\n",
      "batch time cost: 5.582690000534058\n",
      "Epoch: 0, batch: 54\n",
      "loss None\n",
      "batch time cost: 5.368520021438599\n",
      "Epoch: 0, batch: 55\n",
      "loss None\n",
      "batch time cost: 8.583783864974976\n",
      "Epoch: 0, batch: 56\n",
      "loss None\n",
      "batch time cost: 5.859204053878784\n",
      "Epoch: 0, batch: 57\n",
      "loss None\n",
      "batch time cost: 5.4013261795043945\n",
      "Epoch: 0, batch: 58\n",
      "loss None\n",
      "batch time cost: 5.640733957290649\n",
      "Epoch: 0, batch: 59\n",
      "loss None\n",
      "batch time cost: 8.514546155929565\n",
      "Epoch: 0, batch: 60\n",
      "loss None\n",
      "batch time cost: 5.330573797225952\n",
      "Relu Train Epoch: 0 [3840/318582 (0%)]\tLoss: 3.113945\n",
      "Epoch: 0, batch: 61\n",
      "loss None\n",
      "batch time cost: 5.3592140674591064\n",
      "Epoch: 0, batch: 62\n",
      "loss None\n",
      "batch time cost: 7.18376088142395\n",
      "Epoch: 0, batch: 63\n",
      "loss None\n",
      "batch time cost: 5.455369234085083\n",
      "Epoch: 0, batch: 64\n",
      "loss None\n",
      "batch time cost: 5.943474769592285\n",
      "Epoch: 0, batch: 65\n",
      "loss None\n",
      "batch time cost: 5.99465274810791\n",
      "Epoch: 0, batch: 66\n",
      "loss None\n",
      "batch time cost: 8.425155878067017\n",
      "Epoch: 0, batch: 67\n",
      "loss None\n",
      "batch time cost: 5.32016396522522\n",
      "Epoch: 0, batch: 68\n",
      "loss None\n",
      "batch time cost: 5.3311707973480225\n",
      "Epoch: 0, batch: 69\n",
      "loss None\n",
      "batch time cost: 6.230418920516968\n",
      "Epoch: 0, batch: 70\n",
      "loss None\n",
      "batch time cost: 8.302139043807983\n",
      "Relu Train Epoch: 0 [4480/318582 (0%)]\tLoss: 2.945053\n",
      "Epoch: 0, batch: 71\n",
      "loss None\n",
      "batch time cost: 5.269784927368164\n",
      "Epoch: 0, batch: 72\n",
      "loss None\n",
      "batch time cost: 5.215273857116699\n",
      "Epoch: 0, batch: 73\n",
      "loss None\n",
      "batch time cost: 5.26671290397644\n",
      "Epoch: 0, batch: 74\n",
      "loss None\n",
      "batch time cost: 5.265974044799805\n",
      "Epoch: 0, batch: 75\n",
      "loss None\n",
      "batch time cost: 5.246859073638916\n",
      "Epoch: 0, batch: 76\n",
      "loss None\n",
      "batch time cost: 5.551076889038086\n",
      "Epoch: 0, batch: 77\n",
      "loss None\n",
      "batch time cost: 5.277025938034058\n",
      "Epoch: 0, batch: 78\n",
      "loss None\n",
      "batch time cost: 5.240708112716675\n",
      "Epoch: 0, batch: 79\n",
      "loss None\n",
      "batch time cost: 5.275327205657959\n",
      "Epoch: 0, batch: 80\n",
      "loss None\n",
      "batch time cost: 5.238181114196777\n",
      "Relu Train Epoch: 0 [5120/318582 (0%)]\tLoss: 2.497622\n",
      "Epoch: 0, batch: 81\n",
      "loss None\n",
      "batch time cost: 5.3077051639556885\n",
      "Epoch: 0, batch: 82\n",
      "loss None\n",
      "batch time cost: 8.327100038528442\n",
      "Epoch: 0, batch: 83\n",
      "loss None\n",
      "batch time cost: 5.450329065322876\n",
      "Epoch: 0, batch: 84\n",
      "loss None\n",
      "batch time cost: 5.810559034347534\n",
      "Epoch: 0, batch: 85\n",
      "loss None\n",
      "batch time cost: 5.776625871658325\n",
      "Epoch: 0, batch: 86\n",
      "loss None\n",
      "batch time cost: 8.889127969741821\n",
      "Epoch: 0, batch: 87\n",
      "loss None\n",
      "batch time cost: 8.29223918914795\n",
      "Epoch: 0, batch: 88\n",
      "loss None\n",
      "batch time cost: 5.719831705093384\n",
      "Epoch: 0, batch: 89\n",
      "loss None\n",
      "batch time cost: 5.317791223526001\n",
      "Epoch: 0, batch: 90\n",
      "loss None\n",
      "batch time cost: 5.249614000320435\n",
      "Relu Train Epoch: 0 [5760/318582 (0%)]\tLoss: 2.059991\n",
      "Epoch: 0, batch: 91\n",
      "loss None\n",
      "batch time cost: 6.516080141067505\n",
      "Epoch: 0, batch: 92\n",
      "loss None\n",
      "batch time cost: 5.217678070068359\n",
      "Epoch: 0, batch: 93\n",
      "loss None\n",
      "batch time cost: 5.2393598556518555\n",
      "Epoch: 0, batch: 94\n",
      "loss None\n",
      "batch time cost: 5.2307047843933105\n",
      "Epoch: 0, batch: 95\n",
      "loss None\n",
      "batch time cost: 5.251344919204712\n",
      "Epoch: 0, batch: 96\n",
      "loss None\n",
      "batch time cost: 5.594900846481323\n",
      "Epoch: 0, batch: 97\n",
      "loss None\n",
      "batch time cost: 5.308106899261475\n",
      "Epoch: 0, batch: 98\n",
      "loss None\n",
      "batch time cost: 5.638063907623291\n",
      "Epoch: 0, batch: 99\n",
      "loss None\n",
      "batch time cost: 5.234858989715576\n",
      "Epoch: 0, batch: 100\n",
      "loss None\n",
      "batch time cost: 5.25322699546814\n",
      "Relu Train Epoch: 0 [6400/318582 (0%)]\tLoss: 1.627961\n",
      "Epoch: 0, batch: 101\n",
      "loss None\n",
      "batch time cost: 5.197108030319214\n",
      "Epoch: 0, batch: 102\n",
      "loss None\n",
      "batch time cost: 5.156412839889526\n",
      "Epoch: 0, batch: 103\n",
      "loss None\n",
      "batch time cost: 5.249734163284302\n",
      "Epoch: 0, batch: 104\n",
      "loss None\n",
      "batch time cost: 5.209161043167114\n",
      "Epoch: 0, batch: 105\n",
      "loss None\n",
      "batch time cost: 5.569758176803589\n",
      "Epoch: 0, batch: 106\n",
      "loss None\n",
      "batch time cost: 5.252929210662842\n",
      "Epoch: 0, batch: 107\n",
      "loss None\n",
      "batch time cost: 5.254987001419067\n",
      "Epoch: 0, batch: 108\n",
      "loss None\n",
      "batch time cost: 5.216865062713623\n",
      "Epoch: 0, batch: 109\n",
      "loss None\n",
      "batch time cost: 5.248706817626953\n",
      "Epoch: 0, batch: 110\n",
      "loss None\n",
      "batch time cost: 5.24199914932251\n",
      "Relu Train Epoch: 0 [7040/318582 (0%)]\tLoss: 1.481027\n",
      "Epoch: 0, batch: 111\n",
      "loss None\n",
      "batch time cost: 5.234964370727539\n",
      "Epoch: 0, batch: 112\n",
      "loss None\n",
      "batch time cost: 5.222867965698242\n",
      "Epoch: 0, batch: 113\n",
      "loss None\n",
      "batch time cost: 5.524195194244385\n",
      "Epoch: 0, batch: 114\n",
      "loss None\n",
      "batch time cost: 5.269272089004517\n",
      "Epoch: 0, batch: 115\n",
      "loss None\n",
      "batch time cost: 5.236130952835083\n",
      "Epoch: 0, batch: 116\n",
      "loss None\n",
      "batch time cost: 5.240396022796631\n",
      "Epoch: 0, batch: 117\n",
      "loss None\n",
      "batch time cost: 5.223374128341675\n",
      "Epoch: 0, batch: 118\n",
      "loss None\n",
      "batch time cost: 5.235034704208374\n",
      "Epoch: 0, batch: 119\n",
      "loss None\n",
      "batch time cost: 5.193041086196899\n",
      "Epoch: 0, batch: 120\n",
      "loss None\n",
      "batch time cost: 5.502578258514404\n",
      "Relu Train Epoch: 0 [7680/318582 (0%)]\tLoss: 1.322850\n",
      "Epoch: 0, batch: 121\n",
      "loss None\n",
      "batch time cost: 5.1395556926727295\n",
      "Epoch: 0, batch: 122\n",
      "loss None\n",
      "batch time cost: 5.205459117889404\n",
      "Epoch: 0, batch: 123\n",
      "loss None\n",
      "batch time cost: 5.2342000007629395\n",
      "Epoch: 0, batch: 124\n",
      "loss None\n",
      "batch time cost: 5.260883331298828\n",
      "Epoch: 0, batch: 125\n",
      "loss None\n",
      "batch time cost: 5.230782985687256\n",
      "Epoch: 0, batch: 126\n",
      "loss None\n",
      "batch time cost: 5.235826253890991\n",
      "Epoch: 0, batch: 127\n",
      "loss None\n",
      "batch time cost: 5.504462003707886\n",
      "Epoch: 0, batch: 128\n",
      "loss None\n",
      "batch time cost: 5.247387886047363\n",
      "Epoch: 0, batch: 129\n",
      "loss None\n",
      "batch time cost: 5.26111912727356\n",
      "Epoch: 0, batch: 130\n",
      "loss None\n",
      "batch time cost: 5.26625394821167\n",
      "Relu Train Epoch: 0 [8320/318582 (0%)]\tLoss: 1.233654\n",
      "Epoch: 0, batch: 131\n",
      "loss None\n",
      "batch time cost: 5.259094953536987\n",
      "Epoch: 0, batch: 132\n",
      "loss None\n",
      "batch time cost: 5.260155200958252\n",
      "Epoch: 0, batch: 133\n",
      "loss None\n",
      "batch time cost: 5.232795238494873\n",
      "Epoch: 0, batch: 134\n",
      "loss None\n",
      "batch time cost: 5.589935779571533\n",
      "Epoch: 0, batch: 135\n",
      "loss None\n",
      "batch time cost: 6.050137042999268\n",
      "Epoch: 0, batch: 136\n",
      "loss None\n",
      "batch time cost: 5.302731990814209\n",
      "Epoch: 0, batch: 137\n",
      "loss None\n",
      "batch time cost: 5.2865400314331055\n",
      "Epoch: 0, batch: 138\n",
      "loss None\n",
      "batch time cost: 5.2374231815338135\n",
      "Epoch: 0, batch: 139\n",
      "loss None\n",
      "batch time cost: 5.2711029052734375\n",
      "Epoch: 0, batch: 140\n",
      "loss None\n",
      "batch time cost: 5.235985040664673\n",
      "Relu Train Epoch: 0 [8960/318582 (0%)]\tLoss: 1.539851\n",
      "Epoch: 0, batch: 141\n",
      "loss None\n",
      "batch time cost: 5.528820037841797\n",
      "Epoch: 0, batch: 142\n",
      "loss None\n",
      "batch time cost: 5.22675895690918\n",
      "Epoch: 0, batch: 143\n",
      "loss None\n",
      "batch time cost: 5.180920839309692\n",
      "Epoch: 0, batch: 144\n",
      "loss None\n",
      "batch time cost: 5.272999048233032\n",
      "Epoch: 0, batch: 145\n",
      "loss None\n",
      "batch time cost: 5.28821587562561\n",
      "Epoch: 0, batch: 146\n",
      "loss None\n",
      "batch time cost: 5.216146230697632\n",
      "Epoch: 0, batch: 147\n",
      "loss None\n",
      "batch time cost: 5.188644170761108\n",
      "Epoch: 0, batch: 148\n",
      "loss None\n",
      "batch time cost: 5.238282918930054\n",
      "Epoch: 0, batch: 149\n",
      "loss None\n",
      "batch time cost: 5.533313989639282\n",
      "Epoch: 0, batch: 150\n",
      "loss None\n",
      "batch time cost: 5.251426935195923\n",
      "Relu Train Epoch: 0 [9600/318582 (0%)]\tLoss: 1.358319\n",
      "Epoch: 0, batch: 151\n",
      "loss None\n",
      "batch time cost: 5.236176252365112\n",
      "Epoch: 0, batch: 152\n",
      "loss None\n",
      "batch time cost: 5.21044397354126\n",
      "Epoch: 0, batch: 153\n",
      "loss None\n",
      "batch time cost: 5.242419004440308\n",
      "Epoch: 0, batch: 154\n",
      "loss None\n",
      "batch time cost: 5.319089889526367\n",
      "Epoch: 0, batch: 155\n",
      "loss None\n",
      "batch time cost: 5.259187936782837\n",
      "Epoch: 0, batch: 156\n",
      "loss None\n",
      "batch time cost: 5.616249084472656\n",
      "Epoch: 0, batch: 157\n",
      "loss None\n",
      "batch time cost: 5.241405010223389\n",
      "Epoch: 0, batch: 158\n",
      "loss None\n",
      "batch time cost: 5.159508943557739\n",
      "Epoch: 0, batch: 159\n",
      "loss None\n",
      "batch time cost: 5.115345001220703\n",
      "Epoch: 0, batch: 160\n",
      "loss None\n",
      "batch time cost: 5.192579030990601\n",
      "Relu Train Epoch: 0 [10240/318582 (0%)]\tLoss: 1.163128\n",
      "Epoch: 0, batch: 161\n",
      "loss None\n",
      "batch time cost: 5.178393840789795\n",
      "Epoch: 0, batch: 162\n",
      "loss None\n",
      "batch time cost: 5.122614145278931\n",
      "Epoch: 0, batch: 163\n",
      "loss None\n",
      "batch time cost: 5.4402618408203125\n",
      "Epoch: 0, batch: 164\n",
      "loss None\n",
      "batch time cost: 5.249948978424072\n",
      "Epoch: 0, batch: 165\n",
      "loss None\n",
      "batch time cost: 5.190624952316284\n",
      "Epoch: 0, batch: 166\n",
      "loss None\n",
      "batch time cost: 5.214974880218506\n",
      "Epoch: 0, batch: 167\n",
      "loss None\n",
      "batch time cost: 5.248896837234497\n",
      "Epoch: 0, batch: 168\n",
      "loss None\n",
      "batch time cost: 5.229394197463989\n",
      "Epoch: 0, batch: 169\n",
      "loss None\n",
      "batch time cost: 5.205064058303833\n",
      "Epoch: 0, batch: 170\n",
      "loss None\n",
      "batch time cost: 5.537640810012817\n",
      "Relu Train Epoch: 0 [10880/318582 (0%)]\tLoss: 1.197355\n",
      "Epoch: 0, batch: 171\n",
      "loss None\n",
      "batch time cost: 5.2055768966674805\n",
      "Epoch: 0, batch: 172\n",
      "loss None\n",
      "batch time cost: 5.219964981079102\n",
      "Epoch: 0, batch: 173\n",
      "loss None\n",
      "batch time cost: 5.201587915420532\n",
      "Epoch: 0, batch: 174\n",
      "loss None\n",
      "batch time cost: 5.199366807937622\n",
      "Epoch: 0, batch: 175\n",
      "loss None\n",
      "batch time cost: 5.229076385498047\n",
      "Epoch: 0, batch: 176\n",
      "loss None\n",
      "batch time cost: 5.232550144195557\n",
      "Epoch: 0, batch: 177\n",
      "loss None\n",
      "batch time cost: 5.231122016906738\n",
      "Epoch: 0, batch: 178\n",
      "loss None\n",
      "batch time cost: 5.514171123504639\n",
      "Epoch: 0, batch: 179\n",
      "loss None\n",
      "batch time cost: 8.449078798294067\n",
      "Epoch: 0, batch: 180\n",
      "loss None\n",
      "batch time cost: 8.858837127685547\n",
      "Relu Train Epoch: 0 [11520/318582 (0%)]\tLoss: 1.205600\n",
      "Epoch: 0, batch: 181\n",
      "loss None\n",
      "batch time cost: 8.159081935882568\n",
      "Epoch: 0, batch: 182\n",
      "loss None\n",
      "batch time cost: 5.209469795227051\n",
      "Epoch: 0, batch: 183\n",
      "loss None\n",
      "batch time cost: 5.126066207885742\n",
      "Epoch: 0, batch: 184\n",
      "loss None\n",
      "batch time cost: 5.1944739818573\n",
      "Epoch: 0, batch: 185\n",
      "loss None\n",
      "batch time cost: 5.575155019760132\n",
      "Epoch: 0, batch: 186\n",
      "loss None\n",
      "batch time cost: 5.185085773468018\n",
      "Epoch: 0, batch: 187\n",
      "loss None\n",
      "batch time cost: 5.143063068389893\n",
      "Epoch: 0, batch: 188\n",
      "loss None\n",
      "batch time cost: 5.212422847747803\n",
      "Epoch: 0, batch: 189\n",
      "loss None\n",
      "batch time cost: 5.230586767196655\n",
      "Epoch: 0, batch: 190\n",
      "loss None\n",
      "batch time cost: 5.266755104064941\n",
      "Relu Train Epoch: 0 [12160/318582 (0%)]\tLoss: 1.156921\n",
      "Epoch: 0, batch: 191\n",
      "loss None\n",
      "batch time cost: 5.2162580490112305\n",
      "Epoch: 0, batch: 192\n",
      "loss None\n",
      "batch time cost: 5.5165488719940186\n",
      "Epoch: 0, batch: 193\n",
      "loss None\n",
      "batch time cost: 5.245320081710815\n",
      "Epoch: 0, batch: 194\n",
      "loss None\n",
      "batch time cost: 5.2383739948272705\n",
      "Epoch: 0, batch: 195\n",
      "loss None\n",
      "batch time cost: 5.309806823730469\n",
      "Epoch: 0, batch: 196\n",
      "loss None\n",
      "batch time cost: 5.273228883743286\n",
      "Epoch: 0, batch: 197\n",
      "loss None\n",
      "batch time cost: 5.191463947296143\n",
      "Epoch: 0, batch: 198\n",
      "loss None\n",
      "batch time cost: 5.2237701416015625\n",
      "Epoch: 0, batch: 199\n",
      "loss None\n",
      "batch time cost: 5.541571140289307\n",
      "Epoch: 0, batch: 200\n",
      "loss None\n",
      "batch time cost: 5.228630065917969\n",
      "Relu Train Epoch: 0 [12800/318582 (0%)]\tLoss: 1.184785\n",
      "Epoch: 0, batch: 201\n",
      "loss None\n",
      "batch time cost: 5.244246006011963\n",
      "Epoch: 0, batch: 202\n",
      "loss None\n",
      "batch time cost: 5.211170673370361\n",
      "Epoch: 0, batch: 203\n",
      "loss None\n",
      "batch time cost: 5.205699920654297\n",
      "Epoch: 0, batch: 204\n",
      "loss None\n",
      "batch time cost: 5.216015100479126\n",
      "Epoch: 0, batch: 205\n",
      "loss None\n",
      "batch time cost: 5.204736948013306\n",
      "Epoch: 0, batch: 206\n",
      "loss None\n",
      "batch time cost: 5.498077154159546\n",
      "Epoch: 0, batch: 207\n",
      "loss None\n",
      "batch time cost: 5.21122407913208\n",
      "Epoch: 0, batch: 208\n",
      "loss None\n",
      "batch time cost: 5.231186151504517\n",
      "Epoch: 0, batch: 209\n",
      "loss None\n",
      "batch time cost: 5.185357093811035\n",
      "Epoch: 0, batch: 210\n",
      "loss None\n",
      "batch time cost: 5.212955713272095\n",
      "Relu Train Epoch: 0 [13440/318582 (0%)]\tLoss: 1.282429\n",
      "Epoch: 0, batch: 211\n",
      "loss None\n",
      "batch time cost: 5.244232892990112\n",
      "Epoch: 0, batch: 212\n",
      "loss None\n",
      "batch time cost: 5.256216049194336\n",
      "Epoch: 0, batch: 213\n",
      "loss None\n",
      "batch time cost: 5.2452569007873535\n",
      "Epoch: 0, batch: 214\n",
      "loss None\n",
      "batch time cost: 5.612450122833252\n",
      "Epoch: 0, batch: 215\n",
      "loss None\n",
      "batch time cost: 5.2649619579315186\n",
      "Epoch: 0, batch: 216\n",
      "loss None\n",
      "batch time cost: 5.23324728012085\n",
      "Epoch: 0, batch: 217\n",
      "loss None\n",
      "batch time cost: 5.237197160720825\n",
      "Epoch: 0, batch: 218\n",
      "loss None\n",
      "batch time cost: 5.216267108917236\n",
      "Epoch: 0, batch: 219\n",
      "loss None\n",
      "batch time cost: 5.222123146057129\n",
      "Epoch: 0, batch: 220\n",
      "loss None\n",
      "batch time cost: 5.268319129943848\n",
      "Relu Train Epoch: 0 [14080/318582 (0%)]\tLoss: 1.019982\n",
      "Epoch: 0, batch: 221\n",
      "loss None\n",
      "batch time cost: 5.57423996925354\n",
      "Epoch: 0, batch: 222\n",
      "loss None\n",
      "batch time cost: 5.2123589515686035\n",
      "Epoch: 0, batch: 223\n",
      "loss None\n",
      "batch time cost: 5.210066080093384\n",
      "Epoch: 0, batch: 224\n",
      "loss None\n",
      "batch time cost: 5.268216133117676\n",
      "Epoch: 0, batch: 225\n",
      "loss None\n",
      "batch time cost: 5.219960927963257\n",
      "Epoch: 0, batch: 226\n",
      "loss None\n",
      "batch time cost: 5.246377944946289\n",
      "Epoch: 0, batch: 227\n",
      "loss None\n",
      "batch time cost: 5.255211114883423\n",
      "Epoch: 0, batch: 228\n",
      "loss None\n",
      "batch time cost: 5.543389797210693\n",
      "Epoch: 0, batch: 229\n",
      "loss None\n",
      "batch time cost: 5.230705976486206\n",
      "Epoch: 0, batch: 230\n",
      "loss None\n",
      "batch time cost: 5.226104021072388\n",
      "Relu Train Epoch: 0 [14720/318582 (0%)]\tLoss: 1.162242\n",
      "Epoch: 0, batch: 231\n",
      "loss None\n",
      "batch time cost: 5.201947927474976\n",
      "Epoch: 0, batch: 232\n",
      "loss None\n",
      "batch time cost: 5.2656168937683105\n",
      "Epoch: 0, batch: 233\n",
      "loss None\n",
      "batch time cost: 5.238518714904785\n",
      "Epoch: 0, batch: 234\n",
      "loss None\n",
      "batch time cost: 5.308642864227295\n",
      "Epoch: 0, batch: 235\n",
      "loss None\n",
      "batch time cost: 5.602770090103149\n",
      "Epoch: 0, batch: 236\n",
      "loss None\n",
      "batch time cost: 5.272154092788696\n",
      "Epoch: 0, batch: 237\n",
      "loss None\n",
      "batch time cost: 5.244411945343018\n",
      "Epoch: 0, batch: 238\n",
      "loss None\n",
      "batch time cost: 5.290428161621094\n",
      "Epoch: 0, batch: 239\n",
      "loss None\n",
      "batch time cost: 5.3294148445129395\n",
      "Epoch: 0, batch: 240\n",
      "loss None\n",
      "batch time cost: 5.214149713516235\n",
      "Relu Train Epoch: 0 [15360/318582 (0%)]\tLoss: 1.107691\n",
      "Epoch: 0, batch: 241\n",
      "loss None\n",
      "batch time cost: 5.310304880142212\n",
      "Epoch: 0, batch: 242\n",
      "loss None\n",
      "batch time cost: 5.212553024291992\n",
      "Epoch: 0, batch: 243\n",
      "loss None\n",
      "batch time cost: 5.535223007202148\n",
      "Epoch: 0, batch: 244\n",
      "loss None\n",
      "batch time cost: 5.228445053100586\n",
      "Epoch: 0, batch: 245\n",
      "loss None\n",
      "batch time cost: 5.21857476234436\n",
      "Epoch: 0, batch: 246\n",
      "loss None\n",
      "batch time cost: 5.218867063522339\n",
      "Epoch: 0, batch: 247\n",
      "loss None\n",
      "batch time cost: 5.272125959396362\n",
      "Epoch: 0, batch: 248\n",
      "loss None\n",
      "batch time cost: 5.249575853347778\n",
      "Epoch: 0, batch: 249\n",
      "loss None\n",
      "batch time cost: 5.3024818897247314\n",
      "Epoch: 0, batch: 250\n",
      "loss None\n",
      "batch time cost: 5.521011829376221\n",
      "Relu Train Epoch: 0 [16000/318582 (0%)]\tLoss: 1.252588\n",
      "Epoch: 0, batch: 251\n",
      "loss None\n",
      "batch time cost: 5.2150468826293945\n",
      "Epoch: 0, batch: 252\n",
      "loss None\n",
      "batch time cost: 5.179167985916138\n",
      "Epoch: 0, batch: 253\n",
      "loss None\n",
      "batch time cost: 5.247281074523926\n",
      "Epoch: 0, batch: 254\n",
      "loss None\n",
      "batch time cost: 5.250659227371216\n",
      "Epoch: 0, batch: 255\n",
      "loss None\n",
      "batch time cost: 5.230167865753174\n",
      "Epoch: 0, batch: 256\n",
      "loss None\n",
      "batch time cost: 5.199843168258667\n",
      "Epoch: 0, batch: 257\n",
      "loss None\n",
      "batch time cost: 5.517788887023926\n",
      "Epoch: 0, batch: 258\n",
      "loss None\n",
      "batch time cost: 5.196143865585327\n",
      "Epoch: 0, batch: 259\n",
      "loss None\n",
      "batch time cost: 5.190510988235474\n",
      "Epoch: 0, batch: 260\n",
      "loss None\n",
      "batch time cost: 5.218177080154419\n",
      "Relu Train Epoch: 0 [16640/318582 (0%)]\tLoss: 1.046651\n",
      "Epoch: 0, batch: 261\n",
      "loss None\n",
      "batch time cost: 5.178591966629028\n",
      "Epoch: 0, batch: 262\n",
      "loss None\n",
      "batch time cost: 5.238109827041626\n",
      "Epoch: 0, batch: 263\n",
      "loss None\n",
      "batch time cost: 5.261736869812012\n",
      "Epoch: 0, batch: 264\n",
      "loss None\n",
      "batch time cost: 5.51605486869812\n",
      "Epoch: 0, batch: 265\n",
      "loss None\n",
      "batch time cost: 8.544296979904175\n",
      "Epoch: 0, batch: 266\n",
      "loss None\n",
      "batch time cost: 5.523163795471191\n",
      "Epoch: 0, batch: 267\n",
      "loss None\n",
      "batch time cost: 5.177462100982666\n",
      "Epoch: 0, batch: 268\n",
      "loss None\n",
      "batch time cost: 5.168528079986572\n",
      "Epoch: 0, batch: 269\n",
      "loss None\n",
      "batch time cost: 5.140249967575073\n",
      "Epoch: 0, batch: 270\n",
      "loss None\n",
      "batch time cost: 5.121633052825928\n",
      "Relu Train Epoch: 0 [17280/318582 (0%)]\tLoss: 1.126565\n",
      "Epoch: 0, batch: 271\n",
      "loss None\n",
      "batch time cost: 7.341799974441528\n",
      "Epoch: 0, batch: 272\n",
      "loss None\n",
      "batch time cost: 8.475796937942505\n",
      "Epoch: 0, batch: 273\n",
      "loss None\n",
      "batch time cost: 5.216563940048218\n",
      "Epoch: 0, batch: 274\n",
      "loss None\n",
      "batch time cost: 5.278393745422363\n",
      "Epoch: 0, batch: 275\n",
      "loss None\n",
      "batch time cost: 5.241788864135742\n",
      "Epoch: 0, batch: 276\n",
      "loss None\n",
      "batch time cost: 5.232028961181641\n",
      "Epoch: 0, batch: 277\n",
      "loss None\n",
      "batch time cost: 5.210279941558838\n",
      "Epoch: 0, batch: 278\n",
      "loss None\n",
      "batch time cost: 5.213665723800659\n",
      "Epoch: 0, batch: 279\n",
      "loss None\n",
      "batch time cost: 5.543031930923462\n",
      "Epoch: 0, batch: 280\n",
      "loss None\n",
      "batch time cost: 5.228617906570435\n",
      "Relu Train Epoch: 0 [17920/318582 (0%)]\tLoss: 1.170459\n",
      "Epoch: 0, batch: 281\n",
      "loss None\n",
      "batch time cost: 5.243415117263794\n",
      "Epoch: 0, batch: 282\n",
      "loss None\n",
      "batch time cost: 5.2348549365997314\n",
      "Epoch: 0, batch: 283\n",
      "loss None\n",
      "batch time cost: 5.211166858673096\n",
      "Epoch: 0, batch: 284\n",
      "loss None\n",
      "batch time cost: 5.166988134384155\n",
      "Epoch: 0, batch: 285\n",
      "loss None\n",
      "batch time cost: 5.210360050201416\n",
      "Epoch: 0, batch: 286\n",
      "loss None\n",
      "batch time cost: 5.513163089752197\n",
      "Epoch: 0, batch: 287\n",
      "loss None\n",
      "batch time cost: 5.254434108734131\n",
      "Epoch: 0, batch: 288\n",
      "loss None\n",
      "batch time cost: 5.2522382736206055\n",
      "Epoch: 0, batch: 289\n",
      "loss None\n",
      "batch time cost: 5.25553297996521\n",
      "Epoch: 0, batch: 290\n",
      "loss None\n",
      "batch time cost: 5.26390814781189\n",
      "Relu Train Epoch: 0 [18560/318582 (0%)]\tLoss: 1.228751\n",
      "Epoch: 0, batch: 291\n",
      "loss None\n",
      "batch time cost: 5.280797004699707\n",
      "Epoch: 0, batch: 292\n",
      "loss None\n",
      "batch time cost: 5.259868144989014\n",
      "Epoch: 0, batch: 293\n",
      "loss None\n",
      "batch time cost: 5.597654819488525\n",
      "Epoch: 0, batch: 294\n",
      "loss None\n",
      "batch time cost: 5.265451908111572\n",
      "Epoch: 0, batch: 295\n",
      "loss None\n",
      "batch time cost: 5.265369176864624\n",
      "Epoch: 0, batch: 296\n",
      "loss None\n",
      "batch time cost: 5.283128023147583\n",
      "Epoch: 0, batch: 297\n",
      "loss None\n",
      "batch time cost: 5.220625162124634\n",
      "Epoch: 0, batch: 298\n",
      "loss None\n",
      "batch time cost: 5.259104013442993\n",
      "Epoch: 0, batch: 299\n",
      "loss None\n",
      "batch time cost: 5.2215800285339355\n",
      "Epoch: 0, batch: 300\n",
      "loss None\n",
      "batch time cost: 5.582028150558472\n",
      "Relu Train Epoch: 0 [19200/318582 (0%)]\tLoss: 1.334229\n",
      "Epoch: 0, batch: 301\n",
      "loss None\n",
      "batch time cost: 5.261055946350098\n",
      "Epoch: 0, batch: 302\n",
      "loss None\n",
      "batch time cost: 5.226908922195435\n",
      "Epoch: 0, batch: 303\n",
      "loss None\n",
      "batch time cost: 5.2232346534729\n",
      "Epoch: 0, batch: 304\n",
      "loss None\n",
      "batch time cost: 5.265162944793701\n",
      "Epoch: 0, batch: 305\n",
      "loss None\n",
      "batch time cost: 5.24766206741333\n",
      "Epoch: 0, batch: 306\n",
      "loss None\n",
      "batch time cost: 5.209913015365601\n",
      "Epoch: 0, batch: 307\n",
      "loss None\n",
      "batch time cost: 5.235122919082642\n",
      "Epoch: 0, batch: 308\n",
      "loss None\n",
      "batch time cost: 5.552406072616577\n",
      "Epoch: 0, batch: 309\n",
      "loss None\n",
      "batch time cost: 5.20219087600708\n",
      "Epoch: 0, batch: 310\n",
      "loss None\n",
      "batch time cost: 6.833301067352295\n",
      "Relu Train Epoch: 0 [19840/318582 (0%)]\tLoss: 0.770690\n",
      "Epoch: 0, batch: 311\n",
      "loss None\n",
      "batch time cost: 5.53372597694397\n",
      "Epoch: 0, batch: 312\n",
      "loss None\n",
      "batch time cost: 5.266133069992065\n",
      "Epoch: 0, batch: 313\n",
      "loss None\n",
      "batch time cost: 5.260738849639893\n",
      "Epoch: 0, batch: 314\n",
      "loss None\n",
      "batch time cost: 5.204644680023193\n",
      "Epoch: 0, batch: 315\n",
      "loss None\n",
      "batch time cost: 5.527029991149902\n",
      "Epoch: 0, batch: 316\n",
      "loss None\n",
      "batch time cost: 5.224897146224976\n",
      "Epoch: 0, batch: 317\n",
      "loss None\n",
      "batch time cost: 5.297221899032593\n",
      "Epoch: 0, batch: 318\n",
      "loss None\n",
      "batch time cost: 5.343529939651489\n",
      "Epoch: 0, batch: 319\n",
      "loss None\n",
      "batch time cost: 5.2532639503479\n",
      "Epoch: 0, batch: 320\n",
      "loss None\n",
      "batch time cost: 8.034702062606812\n",
      "Relu Train Epoch: 0 [20480/318582 (0%)]\tLoss: 1.326043\n",
      "Epoch: 0, batch: 321\n",
      "loss None\n",
      "batch time cost: 7.581795930862427\n",
      "Epoch: 0, batch: 322\n",
      "loss None\n",
      "batch time cost: 8.168049097061157\n",
      "Epoch: 0, batch: 323\n",
      "loss None\n",
      "batch time cost: 6.621926784515381\n",
      "Epoch: 0, batch: 324\n",
      "loss None\n",
      "batch time cost: 5.42802095413208\n",
      "Epoch: 0, batch: 325\n",
      "loss None\n",
      "batch time cost: 5.3050408363342285\n",
      "Epoch: 0, batch: 326\n",
      "loss None\n",
      "batch time cost: 5.311305999755859\n",
      "Epoch: 0, batch: 327\n",
      "loss None\n",
      "batch time cost: 5.320203065872192\n",
      "Epoch: 0, batch: 328\n",
      "loss None\n",
      "batch time cost: 5.260354995727539\n",
      "Epoch: 0, batch: 329\n",
      "loss None\n",
      "batch time cost: 5.60796594619751\n",
      "Epoch: 0, batch: 330\n",
      "loss None\n",
      "batch time cost: 5.257030010223389\n",
      "Relu Train Epoch: 0 [21120/318582 (0%)]\tLoss: 0.989941\n",
      "Epoch: 0, batch: 331\n",
      "loss None\n",
      "batch time cost: 5.24309778213501\n",
      "Epoch: 0, batch: 332\n",
      "loss None\n",
      "batch time cost: 5.295774936676025\n",
      "Epoch: 0, batch: 333\n",
      "loss None\n",
      "batch time cost: 5.2317118644714355\n",
      "Epoch: 0, batch: 334\n",
      "loss None\n",
      "batch time cost: 5.256393909454346\n",
      "Epoch: 0, batch: 335\n",
      "loss None\n",
      "batch time cost: 5.25616717338562\n",
      "Epoch: 0, batch: 336\n",
      "loss None\n",
      "batch time cost: 5.555391788482666\n",
      "Epoch: 0, batch: 337\n",
      "loss None\n",
      "batch time cost: 5.26374888420105\n",
      "Epoch: 0, batch: 338\n",
      "loss None\n",
      "batch time cost: 5.310190200805664\n",
      "Epoch: 0, batch: 339\n",
      "loss None\n",
      "batch time cost: 5.301245927810669\n",
      "Epoch: 0, batch: 340\n",
      "loss None\n",
      "batch time cost: 5.351653099060059\n",
      "Relu Train Epoch: 0 [21760/318582 (0%)]\tLoss: 1.079928\n",
      "Epoch: 0, batch: 341\n",
      "loss None\n",
      "batch time cost: 5.246563911437988\n",
      "Epoch: 0, batch: 342\n",
      "loss None\n",
      "batch time cost: 5.283761978149414\n",
      "Epoch: 0, batch: 343\n",
      "loss None\n",
      "batch time cost: 5.33184289932251\n",
      "Epoch: 0, batch: 344\n",
      "loss None\n",
      "batch time cost: 5.614189863204956\n",
      "Epoch: 0, batch: 345\n",
      "loss None\n",
      "batch time cost: 5.2541608810424805\n",
      "Epoch: 0, batch: 346\n",
      "loss None\n",
      "batch time cost: 5.3043200969696045\n",
      "Epoch: 0, batch: 347\n",
      "loss None\n",
      "batch time cost: 5.2877678871154785\n",
      "Epoch: 0, batch: 348\n",
      "loss None\n",
      "batch time cost: 8.782446146011353\n",
      "Epoch: 0, batch: 349\n",
      "loss None\n",
      "batch time cost: 5.993542909622192\n",
      "Epoch: 0, batch: 350\n",
      "loss None\n",
      "batch time cost: 7.600076913833618\n",
      "Relu Train Epoch: 0 [22400/318582 (0%)]\tLoss: 1.138289\n",
      "Epoch: 0, batch: 351\n",
      "loss None\n",
      "batch time cost: 8.950832843780518\n",
      "Epoch: 0, batch: 352\n",
      "loss None\n",
      "batch time cost: 7.324190855026245\n",
      "Epoch: 0, batch: 353\n",
      "loss None\n",
      "batch time cost: 6.03957986831665\n",
      "Epoch: 0, batch: 354\n",
      "loss None\n",
      "batch time cost: 5.306704044342041\n",
      "Epoch: 0, batch: 355\n",
      "loss None\n",
      "batch time cost: 5.241758108139038\n",
      "Epoch: 0, batch: 356\n",
      "loss None\n",
      "batch time cost: 5.261926174163818\n",
      "Epoch: 0, batch: 357\n",
      "loss None\n",
      "batch time cost: 5.278378963470459\n",
      "Epoch: 0, batch: 358\n",
      "loss None\n",
      "batch time cost: 5.630676031112671\n",
      "Epoch: 0, batch: 359\n",
      "loss None\n",
      "batch time cost: 5.349132061004639\n",
      "Epoch: 0, batch: 360\n",
      "loss None\n",
      "batch time cost: 5.240876197814941\n",
      "Relu Train Epoch: 0 [23040/318582 (0%)]\tLoss: 1.213545\n",
      "Epoch: 0, batch: 361\n",
      "loss None\n",
      "batch time cost: 5.314172983169556\n",
      "Epoch: 0, batch: 362\n",
      "loss None\n",
      "batch time cost: 5.2340381145477295\n",
      "Epoch: 0, batch: 363\n",
      "loss None\n",
      "batch time cost: 5.318108081817627\n",
      "Epoch: 0, batch: 364\n",
      "loss None\n",
      "batch time cost: 5.2412028312683105\n",
      "Epoch: 0, batch: 365\n",
      "loss None\n",
      "batch time cost: 5.601547002792358\n",
      "Epoch: 0, batch: 366\n",
      "loss None\n",
      "batch time cost: 5.27400803565979\n",
      "Epoch: 0, batch: 367\n",
      "loss None\n",
      "batch time cost: 5.279742956161499\n",
      "Epoch: 0, batch: 368\n",
      "loss None\n",
      "batch time cost: 5.2701098918914795\n",
      "Epoch: 0, batch: 369\n",
      "loss None\n",
      "batch time cost: 5.272732973098755\n",
      "Epoch: 0, batch: 370\n",
      "loss None\n",
      "batch time cost: 5.246429920196533\n",
      "Relu Train Epoch: 0 [23680/318582 (0%)]\tLoss: 1.243388\n",
      "Epoch: 0, batch: 371\n",
      "loss None\n",
      "batch time cost: 5.234816074371338\n",
      "Epoch: 0, batch: 372\n",
      "loss None\n",
      "batch time cost: 5.243253946304321\n",
      "Epoch: 0, batch: 373\n",
      "loss None\n",
      "batch time cost: 5.588295936584473\n",
      "Epoch: 0, batch: 374\n",
      "loss None\n",
      "batch time cost: 5.552273988723755\n",
      "Epoch: 0, batch: 375\n",
      "loss None\n",
      "batch time cost: 5.295955181121826\n",
      "Epoch: 0, batch: 376\n",
      "loss None\n",
      "batch time cost: 5.3307578563690186\n",
      "Epoch: 0, batch: 377\n",
      "loss None\n",
      "batch time cost: 5.277190208435059\n",
      "Epoch: 0, batch: 378\n",
      "loss None\n",
      "batch time cost: 5.292042970657349\n",
      "Epoch: 0, batch: 379\n",
      "loss None\n",
      "batch time cost: 5.240538835525513\n",
      "Epoch: 0, batch: 380\n",
      "loss None\n",
      "batch time cost: 5.792352914810181\n",
      "Relu Train Epoch: 0 [24320/318582 (0%)]\tLoss: 0.946642\n",
      "Epoch: 0, batch: 381\n",
      "loss None\n",
      "batch time cost: 5.304594039916992\n",
      "Epoch: 0, batch: 382\n",
      "loss None\n",
      "batch time cost: 5.29789400100708\n",
      "Epoch: 0, batch: 383\n",
      "loss None\n",
      "batch time cost: 5.296811819076538\n",
      "Epoch: 0, batch: 384\n",
      "loss None\n",
      "batch time cost: 5.284772157669067\n",
      "Epoch: 0, batch: 385\n",
      "loss None\n",
      "batch time cost: 5.311880826950073\n",
      "Epoch: 0, batch: 386\n",
      "loss None\n",
      "batch time cost: 5.276656866073608\n",
      "Epoch: 0, batch: 387\n",
      "loss None\n",
      "batch time cost: 5.613982915878296\n",
      "Epoch: 0, batch: 388\n",
      "loss None\n",
      "batch time cost: 5.281703233718872\n",
      "Epoch: 0, batch: 389\n",
      "loss None\n",
      "batch time cost: 5.26169490814209\n",
      "Epoch: 0, batch: 390\n",
      "loss None\n",
      "batch time cost: 5.273222208023071\n",
      "Relu Train Epoch: 0 [24960/318582 (0%)]\tLoss: 1.276460\n",
      "Epoch: 0, batch: 391\n",
      "loss None\n",
      "batch time cost: 5.255659103393555\n",
      "Epoch: 0, batch: 392\n",
      "loss None\n",
      "batch time cost: 5.257108926773071\n",
      "Epoch: 0, batch: 393\n",
      "loss None\n",
      "batch time cost: 5.696735143661499\n",
      "Epoch: 0, batch: 394\n",
      "loss None\n",
      "batch time cost: 5.593273162841797\n",
      "Epoch: 0, batch: 395\n",
      "loss None\n",
      "batch time cost: 5.259891986846924\n",
      "Epoch: 0, batch: 396\n",
      "loss None\n",
      "batch time cost: 5.203106164932251\n",
      "Epoch: 0, batch: 397\n",
      "loss None\n",
      "batch time cost: 5.219164848327637\n",
      "Epoch: 0, batch: 398\n",
      "loss None\n",
      "batch time cost: 5.214458703994751\n",
      "Epoch: 0, batch: 399\n",
      "loss None\n",
      "batch time cost: 5.267400026321411\n",
      "Epoch: 0, batch: 400\n",
      "loss None\n",
      "batch time cost: 5.275659084320068\n",
      "Relu Train Epoch: 0 [25600/318582 (0%)]\tLoss: 0.979812\n",
      "Epoch: 0, batch: 401\n",
      "loss None\n",
      "batch time cost: 5.574913024902344\n",
      "Epoch: 0, batch: 402\n",
      "loss None\n",
      "batch time cost: 5.246203899383545\n",
      "Epoch: 0, batch: 403\n",
      "loss None\n",
      "batch time cost: 5.253777265548706\n",
      "Epoch: 0, batch: 404\n",
      "loss None\n",
      "batch time cost: 5.2867591381073\n",
      "Epoch: 0, batch: 405\n",
      "loss None\n",
      "batch time cost: 5.264463901519775\n",
      "Epoch: 0, batch: 406\n",
      "loss None\n",
      "batch time cost: 5.273629188537598\n",
      "Epoch: 0, batch: 407\n",
      "loss None\n",
      "batch time cost: 5.280319929122925\n",
      "Epoch: 0, batch: 408\n",
      "loss None\n",
      "batch time cost: 5.324097156524658\n",
      "Epoch: 0, batch: 409\n",
      "loss None\n",
      "batch time cost: 5.639290809631348\n",
      "Epoch: 0, batch: 410\n",
      "loss None\n",
      "batch time cost: 5.244539022445679\n",
      "Relu Train Epoch: 0 [26240/318582 (0%)]\tLoss: 1.070886\n",
      "Epoch: 0, batch: 411\n",
      "loss None\n",
      "batch time cost: 5.245639085769653\n",
      "Epoch: 0, batch: 412\n",
      "loss None\n",
      "batch time cost: 5.3390138149261475\n",
      "Epoch: 0, batch: 413\n",
      "loss None\n",
      "batch time cost: 5.358309268951416\n",
      "Epoch: 0, batch: 414\n",
      "loss None\n",
      "batch time cost: 5.295921325683594\n",
      "Epoch: 0, batch: 415\n",
      "loss None\n",
      "batch time cost: 5.265343904495239\n",
      "Epoch: 0, batch: 416\n",
      "loss None\n",
      "batch time cost: 5.596683979034424\n",
      "Epoch: 0, batch: 417\n",
      "loss None\n",
      "batch time cost: 5.278824329376221\n",
      "Epoch: 0, batch: 418\n",
      "loss None\n",
      "batch time cost: 5.277981281280518\n",
      "Epoch: 0, batch: 419\n",
      "loss None\n",
      "batch time cost: 5.263546705245972\n",
      "Epoch: 0, batch: 420\n",
      "loss None\n",
      "batch time cost: 5.286012887954712\n",
      "Relu Train Epoch: 0 [26880/318582 (0%)]\tLoss: 1.056716\n",
      "Epoch: 0, batch: 421\n",
      "loss None\n",
      "batch time cost: 5.32426381111145\n",
      "Epoch: 0, batch: 422\n",
      "loss None\n",
      "batch time cost: 5.319849014282227\n",
      "Epoch: 0, batch: 423\n",
      "loss None\n",
      "batch time cost: 5.5683557987213135\n",
      "Epoch: 0, batch: 424\n",
      "loss None\n",
      "batch time cost: 5.305872917175293\n",
      "Epoch: 0, batch: 425\n",
      "loss None\n",
      "batch time cost: 5.231904029846191\n",
      "Epoch: 0, batch: 426\n",
      "loss None\n",
      "batch time cost: 5.248509883880615\n",
      "Epoch: 0, batch: 427\n",
      "loss None\n",
      "batch time cost: 5.245387077331543\n",
      "Epoch: 0, batch: 428\n",
      "loss None\n",
      "batch time cost: 5.280364036560059\n",
      "Epoch: 0, batch: 429\n",
      "loss None\n",
      "batch time cost: 5.296126842498779\n",
      "Epoch: 0, batch: 430\n",
      "loss None\n",
      "batch time cost: 5.574986934661865\n",
      "Relu Train Epoch: 0 [27520/318582 (0%)]\tLoss: 1.129802\n",
      "Epoch: 0, batch: 431\n",
      "loss None\n",
      "batch time cost: 5.237998962402344\n",
      "Epoch: 0, batch: 432\n",
      "loss None\n",
      "batch time cost: 5.262804985046387\n",
      "Epoch: 0, batch: 433\n",
      "loss None\n",
      "batch time cost: 5.290258169174194\n",
      "Epoch: 0, batch: 434\n",
      "loss None\n",
      "batch time cost: 5.286761999130249\n",
      "Epoch: 0, batch: 435\n",
      "loss None\n",
      "batch time cost: 5.2974371910095215\n",
      "Epoch: 0, batch: 436\n",
      "loss None\n",
      "batch time cost: 5.240994930267334\n",
      "Epoch: 0, batch: 437\n",
      "loss None\n",
      "batch time cost: 5.271712064743042\n",
      "Epoch: 0, batch: 438\n",
      "loss None\n",
      "batch time cost: 6.449222087860107\n",
      "Epoch: 0, batch: 439\n",
      "loss None\n",
      "batch time cost: 5.973723888397217\n",
      "Epoch: 0, batch: 440\n",
      "loss None\n",
      "batch time cost: 5.344238996505737\n",
      "Relu Train Epoch: 0 [28160/318582 (0%)]\tLoss: 0.985176\n",
      "Epoch: 0, batch: 441\n",
      "loss None\n",
      "batch time cost: 5.257120847702026\n",
      "Epoch: 0, batch: 442\n",
      "loss None\n",
      "batch time cost: 5.2382118701934814\n",
      "Epoch: 0, batch: 443\n",
      "loss None\n",
      "batch time cost: 5.2260212898254395\n",
      "Epoch: 0, batch: 444\n",
      "loss None\n",
      "batch time cost: 5.297589063644409\n",
      "Epoch: 0, batch: 445\n",
      "loss None\n",
      "batch time cost: 8.25399398803711\n",
      "Epoch: 0, batch: 446\n",
      "loss None\n",
      "batch time cost: 5.557382822036743\n",
      "Epoch: 0, batch: 447\n",
      "loss None\n",
      "batch time cost: 5.377954959869385\n",
      "Epoch: 0, batch: 448\n",
      "loss None\n",
      "batch time cost: 5.269008159637451\n",
      "Epoch: 0, batch: 449\n",
      "loss None\n",
      "batch time cost: 5.253445148468018\n",
      "Epoch: 0, batch: 450\n",
      "loss None\n",
      "batch time cost: 5.234692096710205\n",
      "Relu Train Epoch: 0 [28800/318582 (0%)]\tLoss: 0.891605\n",
      "Epoch: 0, batch: 451\n",
      "loss None\n",
      "batch time cost: 5.266960859298706\n",
      "Epoch: 0, batch: 452\n",
      "loss None\n",
      "batch time cost: 5.589025974273682\n",
      "Epoch: 0, batch: 453\n",
      "loss None\n",
      "batch time cost: 5.337883234024048\n",
      "Epoch: 0, batch: 454\n",
      "loss None\n",
      "batch time cost: 5.313438892364502\n",
      "Epoch: 0, batch: 455\n",
      "loss None\n",
      "batch time cost: 5.288542985916138\n",
      "Epoch: 0, batch: 456\n",
      "loss None\n",
      "batch time cost: 5.232552766799927\n",
      "Epoch: 0, batch: 457\n",
      "loss None\n",
      "batch time cost: 5.292181015014648\n",
      "Epoch: 0, batch: 458\n",
      "loss None\n",
      "batch time cost: 5.233263969421387\n",
      "Epoch: 0, batch: 459\n",
      "loss None\n",
      "batch time cost: 5.551884174346924\n",
      "Epoch: 0, batch: 460\n",
      "loss None\n",
      "batch time cost: 5.2939581871032715\n",
      "Relu Train Epoch: 0 [29440/318582 (0%)]\tLoss: 0.971238\n",
      "Epoch: 0, batch: 461\n",
      "loss None\n",
      "batch time cost: 5.291535139083862\n",
      "Epoch: 0, batch: 462\n",
      "loss None\n",
      "batch time cost: 5.242284774780273\n",
      "Epoch: 0, batch: 463\n",
      "loss None\n",
      "batch time cost: 5.2727952003479\n",
      "Epoch: 0, batch: 464\n",
      "loss None\n",
      "batch time cost: 5.272443056106567\n",
      "Epoch: 0, batch: 465\n",
      "loss None\n",
      "batch time cost: 5.3889851570129395\n",
      "Epoch: 0, batch: 466\n",
      "loss None\n",
      "batch time cost: 5.69848895072937\n",
      "Epoch: 0, batch: 467\n",
      "loss None\n",
      "batch time cost: 5.889718055725098\n",
      "Epoch: 0, batch: 468\n",
      "loss None\n",
      "batch time cost: 5.624743938446045\n",
      "Epoch: 0, batch: 469\n",
      "loss None\n",
      "batch time cost: 5.286155939102173\n",
      "Epoch: 0, batch: 470\n",
      "loss None\n",
      "batch time cost: 5.221018075942993\n",
      "Relu Train Epoch: 0 [30080/318582 (0%)]\tLoss: 1.044122\n",
      "Epoch: 0, batch: 471\n",
      "loss None\n",
      "batch time cost: 5.286722898483276\n",
      "Epoch: 0, batch: 472\n",
      "loss None\n",
      "batch time cost: 5.230298042297363\n",
      "Epoch: 0, batch: 473\n",
      "loss None\n",
      "batch time cost: 5.272678852081299\n",
      "Epoch: 0, batch: 474\n",
      "loss None\n",
      "batch time cost: 5.8446900844573975\n",
      "Epoch: 0, batch: 475\n",
      "loss None\n",
      "batch time cost: 5.285616874694824\n",
      "Epoch: 0, batch: 476\n",
      "loss None\n",
      "batch time cost: 5.250272989273071\n",
      "Epoch: 0, batch: 477\n",
      "loss None\n",
      "batch time cost: 5.246552228927612\n",
      "Epoch: 0, batch: 478\n",
      "loss None\n",
      "batch time cost: 5.268547058105469\n",
      "Epoch: 0, batch: 479\n",
      "loss None\n",
      "batch time cost: 5.257893085479736\n",
      "Epoch: 0, batch: 480\n",
      "loss None\n",
      "batch time cost: 5.298927307128906\n",
      "Relu Train Epoch: 0 [30720/318582 (0%)]\tLoss: 0.701936\n",
      "Epoch: 0, batch: 481\n",
      "loss None\n",
      "batch time cost: 5.564742803573608\n",
      "Epoch: 0, batch: 482\n",
      "loss None\n",
      "batch time cost: 5.343314170837402\n",
      "Epoch: 0, batch: 483\n",
      "loss None\n",
      "batch time cost: 5.245759963989258\n",
      "Epoch: 0, batch: 484\n",
      "loss None\n",
      "batch time cost: 5.275292873382568\n",
      "Epoch: 0, batch: 485\n",
      "loss None\n",
      "batch time cost: 5.3443379402160645\n",
      "Epoch: 0, batch: 486\n",
      "loss None\n",
      "batch time cost: 5.31553316116333\n",
      "Epoch: 0, batch: 487\n",
      "loss None\n",
      "batch time cost: 5.229349136352539\n",
      "Epoch: 0, batch: 488\n",
      "loss None\n",
      "batch time cost: 5.623326778411865\n",
      "Epoch: 0, batch: 489\n",
      "loss None\n",
      "batch time cost: 5.269726991653442\n",
      "Epoch: 0, batch: 490\n",
      "loss None\n",
      "batch time cost: 5.263315916061401\n",
      "Relu Train Epoch: 0 [31360/318582 (0%)]\tLoss: 0.817047\n",
      "Epoch: 0, batch: 491\n",
      "loss None\n",
      "batch time cost: 5.280078172683716\n",
      "Epoch: 0, batch: 492\n",
      "loss None\n",
      "batch time cost: 5.285201787948608\n",
      "Epoch: 0, batch: 493\n",
      "loss None\n",
      "batch time cost: 5.354661226272583\n",
      "Epoch: 0, batch: 494\n",
      "loss None\n",
      "batch time cost: 5.358918905258179\n",
      "Epoch: 0, batch: 495\n",
      "loss None\n",
      "batch time cost: 5.580594778060913\n",
      "Epoch: 0, batch: 496\n",
      "loss None\n",
      "batch time cost: 5.28256893157959\n",
      "Epoch: 0, batch: 497\n",
      "loss None\n",
      "batch time cost: 5.259796142578125\n",
      "Epoch: 0, batch: 498\n",
      "loss None\n",
      "batch time cost: 5.301723957061768\n",
      "Epoch: 0, batch: 499\n",
      "loss None\n",
      "batch time cost: 5.269507884979248\n",
      "Epoch: 0, batch: 500\n",
      "loss None\n",
      "batch time cost: 5.293575763702393\n",
      "Relu Train Epoch: 0 [32000/318582 (0%)]\tLoss: 0.995345\n",
      "Epoch: 0, batch: 501\n",
      "loss None\n",
      "batch time cost: 5.298702239990234\n",
      "Epoch: 0, batch: 502\n",
      "loss None\n",
      "batch time cost: 5.313705921173096\n",
      "Epoch: 0, batch: 503\n",
      "loss None\n",
      "batch time cost: 5.585682153701782\n",
      "Epoch: 0, batch: 504\n",
      "loss None\n",
      "batch time cost: 5.282495975494385\n",
      "Epoch: 0, batch: 505\n",
      "loss None\n",
      "batch time cost: 5.3058717250823975\n",
      "Epoch: 0, batch: 506\n",
      "loss None\n",
      "batch time cost: 5.278099060058594\n",
      "Epoch: 0, batch: 507\n",
      "loss None\n",
      "batch time cost: 5.26085090637207\n",
      "Epoch: 0, batch: 508\n",
      "loss None\n",
      "batch time cost: 5.301987171173096\n",
      "Epoch: 0, batch: 509\n",
      "loss None\n",
      "batch time cost: 5.364753246307373\n",
      "Epoch: 0, batch: 510\n",
      "loss None\n",
      "batch time cost: 5.69913911819458\n",
      "Relu Train Epoch: 0 [32640/318582 (0%)]\tLoss: 1.017691\n",
      "Epoch: 0, batch: 511\n",
      "loss None\n",
      "batch time cost: 5.308706998825073\n",
      "Epoch: 0, batch: 512\n",
      "loss None\n",
      "batch time cost: 5.253031015396118\n",
      "Epoch: 0, batch: 513\n",
      "loss None\n",
      "batch time cost: 5.3522748947143555\n",
      "Epoch: 0, batch: 514\n",
      "loss None\n",
      "batch time cost: 5.296283006668091\n",
      "Epoch: 0, batch: 515\n",
      "loss None\n",
      "batch time cost: 5.265571117401123\n",
      "Epoch: 0, batch: 516\n",
      "loss None\n",
      "batch time cost: 5.298370122909546\n",
      "Epoch: 0, batch: 517\n",
      "loss None\n",
      "batch time cost: 5.646310091018677\n",
      "Epoch: 0, batch: 518\n",
      "loss None\n",
      "batch time cost: 5.2747111320495605\n",
      "Epoch: 0, batch: 519\n",
      "loss None\n",
      "batch time cost: 5.354426145553589\n",
      "Epoch: 0, batch: 520\n",
      "loss None\n",
      "batch time cost: 5.275593042373657\n",
      "Relu Train Epoch: 0 [33280/318582 (0%)]\tLoss: 0.848755\n",
      "Epoch: 0, batch: 521\n",
      "loss None\n",
      "batch time cost: 5.27817702293396\n",
      "Epoch: 0, batch: 522\n",
      "loss None\n",
      "batch time cost: 5.306354284286499\n",
      "Epoch: 0, batch: 523\n",
      "loss None\n",
      "batch time cost: 5.335034132003784\n",
      "Epoch: 0, batch: 524\n",
      "loss None\n",
      "batch time cost: 5.6237099170684814\n",
      "Epoch: 0, batch: 525\n",
      "loss None\n",
      "batch time cost: 5.373090028762817\n",
      "Epoch: 0, batch: 526\n",
      "loss None\n",
      "batch time cost: 5.328258037567139\n",
      "Epoch: 0, batch: 527\n",
      "loss None\n",
      "batch time cost: 5.24970006942749\n",
      "Epoch: 0, batch: 528\n",
      "loss None\n",
      "batch time cost: 5.263728141784668\n",
      "Epoch: 0, batch: 529\n",
      "loss None\n",
      "batch time cost: 5.291194915771484\n",
      "Epoch: 0, batch: 530\n",
      "loss None\n",
      "batch time cost: 5.283284902572632\n",
      "Relu Train Epoch: 0 [33920/318582 (0%)]\tLoss: 0.882502\n",
      "Epoch: 0, batch: 531\n",
      "loss None\n",
      "batch time cost: 5.609030723571777\n",
      "Epoch: 0, batch: 532\n",
      "loss None\n",
      "batch time cost: 5.290328025817871\n",
      "Epoch: 0, batch: 533\n",
      "loss None\n",
      "batch time cost: 5.2241740226745605\n",
      "Epoch: 0, batch: 534\n",
      "loss None\n",
      "batch time cost: 5.274539947509766\n",
      "Epoch: 0, batch: 535\n",
      "loss None\n",
      "batch time cost: 5.255167007446289\n",
      "Epoch: 0, batch: 536\n",
      "loss None\n",
      "batch time cost: 5.253127098083496\n",
      "Epoch: 0, batch: 537\n",
      "loss None\n",
      "batch time cost: 5.229020833969116\n",
      "Epoch: 0, batch: 538\n",
      "loss None\n",
      "batch time cost: 5.282922983169556\n",
      "Epoch: 0, batch: 539\n",
      "loss None\n",
      "batch time cost: 5.892084121704102\n",
      "Epoch: 0, batch: 540\n",
      "loss None\n",
      "batch time cost: 5.377901077270508\n",
      "Relu Train Epoch: 0 [34560/318582 (0%)]\tLoss: 1.099847\n",
      "Epoch: 0, batch: 541\n",
      "loss None\n",
      "batch time cost: 5.521071910858154\n",
      "Epoch: 0, batch: 542\n",
      "loss None\n",
      "batch time cost: 5.328848838806152\n",
      "Epoch: 0, batch: 543\n",
      "loss None\n",
      "batch time cost: 5.233795881271362\n",
      "Epoch: 0, batch: 544\n",
      "loss None\n",
      "batch time cost: 5.226637125015259\n",
      "Epoch: 0, batch: 545\n",
      "loss None\n",
      "batch time cost: 5.342051029205322\n",
      "Epoch: 0, batch: 546\n",
      "loss None\n",
      "batch time cost: 5.6922287940979\n",
      "Epoch: 0, batch: 547\n",
      "loss None\n",
      "batch time cost: 5.251239776611328\n",
      "Epoch: 0, batch: 548\n",
      "loss None\n",
      "batch time cost: 5.315237760543823\n",
      "Epoch: 0, batch: 549\n",
      "loss None\n",
      "batch time cost: 5.379796981811523\n",
      "Epoch: 0, batch: 550\n",
      "loss None\n",
      "batch time cost: 5.248579978942871\n",
      "Relu Train Epoch: 0 [35200/318582 (0%)]\tLoss: 1.298740\n",
      "Epoch: 0, batch: 551\n",
      "loss None\n",
      "batch time cost: 5.263231039047241\n",
      "Epoch: 0, batch: 552\n",
      "loss None\n",
      "batch time cost: 5.243214130401611\n",
      "Epoch: 0, batch: 553\n",
      "loss None\n",
      "batch time cost: 5.652647018432617\n",
      "Epoch: 0, batch: 554\n",
      "loss None\n",
      "batch time cost: 5.239542007446289\n",
      "Epoch: 0, batch: 555\n",
      "loss None\n",
      "batch time cost: 5.2575719356536865\n",
      "Epoch: 0, batch: 556\n",
      "loss None\n",
      "batch time cost: 5.289846897125244\n",
      "Epoch: 0, batch: 557\n",
      "loss None\n",
      "batch time cost: 5.274083137512207\n",
      "Epoch: 0, batch: 558\n",
      "loss None\n",
      "batch time cost: 5.278825044631958\n",
      "Epoch: 0, batch: 559\n",
      "loss None\n",
      "batch time cost: 5.292500972747803\n",
      "Epoch: 0, batch: 560\n",
      "loss None\n",
      "batch time cost: 5.553598880767822\n",
      "Relu Train Epoch: 0 [35840/318582 (0%)]\tLoss: 0.854524\n",
      "Epoch: 0, batch: 561\n",
      "loss None\n",
      "batch time cost: 5.246312856674194\n",
      "Epoch: 0, batch: 562\n",
      "loss None\n",
      "batch time cost: 5.352696895599365\n",
      "Epoch: 0, batch: 563\n",
      "loss None\n",
      "batch time cost: 5.274993896484375\n",
      "Epoch: 0, batch: 564\n",
      "loss None\n",
      "batch time cost: 5.8234639167785645\n",
      "Epoch: 0, batch: 565\n",
      "loss None\n",
      "batch time cost: 5.784732103347778\n",
      "Epoch: 0, batch: 566\n",
      "loss None\n",
      "batch time cost: 5.288805723190308\n",
      "Epoch: 0, batch: 567\n",
      "loss None\n",
      "batch time cost: 5.209994316101074\n",
      "Epoch: 0, batch: 568\n",
      "loss None\n",
      "batch time cost: 5.644863128662109\n",
      "Epoch: 0, batch: 569\n",
      "loss None\n",
      "batch time cost: 5.281062841415405\n",
      "Epoch: 0, batch: 570\n",
      "loss None\n",
      "batch time cost: 5.3108789920806885\n",
      "Relu Train Epoch: 0 [36480/318582 (0%)]\tLoss: 1.008867\n",
      "Epoch: 0, batch: 571\n",
      "loss None\n",
      "batch time cost: 5.23500919342041\n",
      "Epoch: 0, batch: 572\n",
      "loss None\n",
      "batch time cost: 5.270093679428101\n",
      "Epoch: 0, batch: 573\n",
      "loss None\n",
      "batch time cost: 5.28245210647583\n",
      "Epoch: 0, batch: 574\n",
      "loss None\n",
      "batch time cost: 5.307304859161377\n",
      "Epoch: 0, batch: 575\n",
      "loss None\n",
      "batch time cost: 5.510730981826782\n",
      "Epoch: 0, batch: 576\n",
      "loss None\n",
      "batch time cost: 5.354335069656372\n",
      "Epoch: 0, batch: 577\n",
      "loss None\n",
      "batch time cost: 5.324371814727783\n",
      "Epoch: 0, batch: 578\n",
      "loss None\n",
      "batch time cost: 5.263930082321167\n",
      "Epoch: 0, batch: 579\n",
      "loss None\n",
      "batch time cost: 5.240952968597412\n",
      "Epoch: 0, batch: 580\n",
      "loss None\n",
      "batch time cost: 5.278150796890259\n",
      "Relu Train Epoch: 0 [37120/318582 (0%)]\tLoss: 0.883596\n",
      "Epoch: 0, batch: 581\n",
      "loss None\n",
      "batch time cost: 5.26182222366333\n",
      "Epoch: 0, batch: 582\n",
      "loss None\n",
      "batch time cost: 5.573840141296387\n",
      "Epoch: 0, batch: 583\n",
      "loss None\n",
      "batch time cost: 5.672652006149292\n",
      "Epoch: 0, batch: 584\n",
      "loss None\n",
      "batch time cost: 5.353739023208618\n",
      "Epoch: 0, batch: 585\n",
      "loss None\n",
      "batch time cost: 5.215373992919922\n",
      "Epoch: 0, batch: 586\n",
      "loss None\n",
      "batch time cost: 5.243303060531616\n",
      "Epoch: 0, batch: 587\n",
      "loss None\n",
      "batch time cost: 5.222152948379517\n",
      "Epoch: 0, batch: 588\n",
      "loss None\n",
      "batch time cost: 5.219868898391724\n",
      "Epoch: 0, batch: 589\n",
      "loss None\n",
      "batch time cost: 5.548715829849243\n",
      "Epoch: 0, batch: 590\n",
      "loss None\n",
      "batch time cost: 5.268319129943848\n",
      "Relu Train Epoch: 0 [37760/318582 (0%)]\tLoss: 0.988486\n",
      "Epoch: 0, batch: 591\n",
      "loss None\n",
      "batch time cost: 5.274316072463989\n",
      "Epoch: 0, batch: 592\n",
      "loss None\n",
      "batch time cost: 5.275911092758179\n",
      "Epoch: 0, batch: 593\n",
      "loss None\n",
      "batch time cost: 5.345016956329346\n",
      "Epoch: 0, batch: 594\n",
      "loss None\n",
      "batch time cost: 5.36510705947876\n",
      "Epoch: 0, batch: 595\n",
      "loss None\n",
      "batch time cost: 5.320820093154907\n",
      "Epoch: 0, batch: 596\n",
      "loss None\n",
      "batch time cost: 5.647748947143555\n",
      "Epoch: 0, batch: 597\n",
      "loss None\n",
      "batch time cost: 5.352218151092529\n",
      "Epoch: 0, batch: 598\n",
      "loss None\n",
      "batch time cost: 5.268938064575195\n",
      "Epoch: 0, batch: 599\n",
      "loss None\n",
      "batch time cost: 5.319333076477051\n",
      "Epoch: 0, batch: 600\n",
      "loss None\n",
      "batch time cost: 5.296036243438721\n",
      "Relu Train Epoch: 0 [38400/318582 (0%)]\tLoss: 1.025322\n",
      "Epoch: 0, batch: 601\n",
      "loss None\n",
      "batch time cost: 5.290431976318359\n",
      "Epoch: 0, batch: 602\n",
      "loss None\n",
      "batch time cost: 5.250971078872681\n",
      "Epoch: 0, batch: 603\n",
      "loss None\n",
      "batch time cost: 5.2678751945495605\n",
      "Epoch: 0, batch: 604\n",
      "loss None\n",
      "batch time cost: 5.611453294754028\n",
      "Epoch: 0, batch: 605\n",
      "loss None\n",
      "batch time cost: 5.269912958145142\n",
      "Epoch: 0, batch: 606\n",
      "loss None\n",
      "batch time cost: 5.284003019332886\n",
      "Epoch: 0, batch: 607\n",
      "loss None\n",
      "batch time cost: 5.256371021270752\n",
      "Epoch: 0, batch: 608\n",
      "loss None\n",
      "batch time cost: 5.229680299758911\n",
      "Epoch: 0, batch: 609\n",
      "loss None\n",
      "batch time cost: 5.20389723777771\n",
      "Epoch: 0, batch: 610\n",
      "loss None\n",
      "batch time cost: 5.262998104095459\n",
      "Relu Train Epoch: 0 [39040/318582 (0%)]\tLoss: 0.933920\n",
      "Epoch: 0, batch: 611\n",
      "loss None\n",
      "batch time cost: 5.593371868133545\n",
      "Epoch: 0, batch: 612\n",
      "loss None\n",
      "batch time cost: 5.2581329345703125\n",
      "Epoch: 0, batch: 613\n",
      "loss None\n",
      "batch time cost: 5.307755947113037\n",
      "Epoch: 0, batch: 614\n",
      "loss None\n",
      "batch time cost: 5.297569990158081\n",
      "Epoch: 0, batch: 615\n",
      "loss None\n",
      "batch time cost: 5.267606019973755\n",
      "Epoch: 0, batch: 616\n",
      "loss None\n",
      "batch time cost: 5.292513847351074\n",
      "Epoch: 0, batch: 617\n",
      "loss None\n",
      "batch time cost: 5.281719923019409\n",
      "Epoch: 0, batch: 618\n",
      "loss None\n",
      "batch time cost: 5.621196031570435\n",
      "Epoch: 0, batch: 619\n",
      "loss None\n",
      "batch time cost: 5.297435998916626\n",
      "Epoch: 0, batch: 620\n",
      "loss None\n",
      "batch time cost: 5.263992071151733\n",
      "Relu Train Epoch: 0 [39680/318582 (0%)]\tLoss: 0.889193\n",
      "Epoch: 0, batch: 621\n",
      "loss None\n",
      "batch time cost: 5.243348836898804\n",
      "Epoch: 0, batch: 622\n",
      "loss None\n",
      "batch time cost: 5.280583381652832\n",
      "Epoch: 0, batch: 623\n",
      "loss None\n",
      "batch time cost: 5.3166351318359375\n",
      "Epoch: 0, batch: 624\n",
      "loss None\n",
      "batch time cost: 5.253488063812256\n",
      "Epoch: 0, batch: 625\n",
      "loss None\n",
      "batch time cost: 5.931460857391357\n",
      "Epoch: 0, batch: 626\n",
      "loss None\n",
      "batch time cost: 5.587821960449219\n",
      "Epoch: 0, batch: 627\n",
      "loss None\n",
      "batch time cost: 5.344590187072754\n",
      "Epoch: 0, batch: 628\n",
      "loss None\n",
      "batch time cost: 5.26392388343811\n",
      "Epoch: 0, batch: 629\n",
      "loss None\n",
      "batch time cost: 5.253454923629761\n",
      "Epoch: 0, batch: 630\n",
      "loss None\n",
      "batch time cost: 5.237975120544434\n",
      "Relu Train Epoch: 0 [40320/318582 (0%)]\tLoss: 0.976428\n",
      "Epoch: 0, batch: 631\n",
      "loss None\n",
      "batch time cost: 5.2579991817474365\n",
      "Epoch: 0, batch: 632\n",
      "loss None\n",
      "batch time cost: 5.285150051116943\n",
      "Epoch: 0, batch: 633\n",
      "loss None\n",
      "batch time cost: 5.822088003158569\n",
      "Epoch: 0, batch: 634\n",
      "loss None\n",
      "batch time cost: 5.890812158584595\n",
      "Epoch: 0, batch: 635\n",
      "loss None\n",
      "batch time cost: 5.5793609619140625\n",
      "Epoch: 0, batch: 636\n",
      "loss None\n",
      "batch time cost: 6.348367214202881\n",
      "Epoch: 0, batch: 637\n",
      "loss None\n",
      "batch time cost: 5.2807581424713135\n",
      "Epoch: 0, batch: 638\n",
      "loss None\n",
      "batch time cost: 5.262037992477417\n",
      "Epoch: 0, batch: 639\n",
      "loss None\n",
      "batch time cost: 5.284770965576172\n",
      "Epoch: 0, batch: 640\n",
      "loss None\n",
      "batch time cost: 5.571314096450806\n",
      "Relu Train Epoch: 0 [40960/318582 (0%)]\tLoss: 0.931497\n",
      "Epoch: 0, batch: 641\n",
      "loss None\n",
      "batch time cost: 5.258866786956787\n",
      "Epoch: 0, batch: 642\n",
      "loss None\n",
      "batch time cost: 5.300881862640381\n",
      "Epoch: 0, batch: 643\n",
      "loss None\n",
      "batch time cost: 5.293683052062988\n",
      "Epoch: 0, batch: 644\n",
      "loss None\n",
      "batch time cost: 5.286926031112671\n",
      "Epoch: 0, batch: 645\n",
      "loss None\n",
      "batch time cost: 5.241863965988159\n",
      "Epoch: 0, batch: 646\n",
      "loss None\n",
      "batch time cost: 5.2425007820129395\n",
      "Epoch: 0, batch: 647\n",
      "loss None\n",
      "batch time cost: 5.580106019973755\n",
      "Epoch: 0, batch: 648\n",
      "loss None\n",
      "batch time cost: 5.287880897521973\n",
      "Epoch: 0, batch: 649\n",
      "loss None\n",
      "batch time cost: 5.2513532638549805\n",
      "Epoch: 0, batch: 650\n",
      "loss None\n",
      "batch time cost: 5.3489367961883545\n",
      "Relu Train Epoch: 0 [41600/318582 (0%)]\tLoss: 0.917958\n",
      "Epoch: 0, batch: 651\n",
      "loss None\n",
      "batch time cost: 5.223475217819214\n",
      "Epoch: 0, batch: 652\n",
      "loss None\n",
      "batch time cost: 5.269355773925781\n",
      "Epoch: 0, batch: 653\n",
      "loss None\n",
      "batch time cost: 5.259161949157715\n",
      "Epoch: 0, batch: 654\n",
      "loss None\n",
      "batch time cost: 5.749369144439697\n",
      "Epoch: 0, batch: 655\n",
      "loss None\n",
      "batch time cost: 5.2757251262664795\n",
      "Epoch: 0, batch: 656\n",
      "loss None\n",
      "batch time cost: 5.291685104370117\n",
      "Epoch: 0, batch: 657\n",
      "loss None\n",
      "batch time cost: 5.255948066711426\n",
      "Epoch: 0, batch: 658\n",
      "loss None\n",
      "batch time cost: 5.286364793777466\n",
      "Epoch: 0, batch: 659\n",
      "loss None\n",
      "batch time cost: 5.303222179412842\n",
      "Epoch: 0, batch: 660\n",
      "loss None\n",
      "batch time cost: 5.257427930831909\n",
      "Relu Train Epoch: 0 [42240/318582 (0%)]\tLoss: 0.736252\n",
      "Epoch: 0, batch: 661\n",
      "loss None\n",
      "batch time cost: 6.100470066070557\n",
      "Epoch: 0, batch: 662\n",
      "loss None\n",
      "batch time cost: 5.337425947189331\n",
      "Epoch: 0, batch: 663\n",
      "loss None\n",
      "batch time cost: 5.240865230560303\n",
      "Epoch: 0, batch: 664\n",
      "loss None\n",
      "batch time cost: 5.270651817321777\n",
      "Epoch: 0, batch: 665\n",
      "loss None\n",
      "batch time cost: 5.25342321395874\n",
      "Epoch: 0, batch: 666\n",
      "loss None\n",
      "batch time cost: 5.236569881439209\n",
      "Epoch: 0, batch: 667\n",
      "loss None\n",
      "batch time cost: 5.245443820953369\n",
      "Epoch: 0, batch: 668\n",
      "loss None\n",
      "batch time cost: 5.257133960723877\n",
      "Epoch: 0, batch: 669\n",
      "loss None\n",
      "batch time cost: 5.6305091381073\n",
      "Epoch: 0, batch: 670\n",
      "loss None\n",
      "batch time cost: 6.228318929672241\n",
      "Relu Train Epoch: 0 [42880/318582 (0%)]\tLoss: 0.998403\n",
      "Epoch: 0, batch: 671\n",
      "loss None\n",
      "batch time cost: 5.411523818969727\n",
      "Epoch: 0, batch: 672\n",
      "loss None\n",
      "batch time cost: 5.3018317222595215\n",
      "Epoch: 0, batch: 673\n",
      "loss None\n",
      "batch time cost: 5.292435884475708\n",
      "Epoch: 0, batch: 674\n",
      "loss None\n",
      "batch time cost: 5.2543439865112305\n",
      "Epoch: 0, batch: 675\n",
      "loss None\n",
      "batch time cost: 5.280410289764404\n",
      "Epoch: 0, batch: 676\n",
      "loss None\n",
      "batch time cost: 6.218760967254639\n",
      "Epoch: 0, batch: 677\n",
      "loss None\n",
      "batch time cost: 5.428235769271851\n",
      "Epoch: 0, batch: 678\n",
      "loss None\n",
      "batch time cost: 5.425660848617554\n",
      "Epoch: 0, batch: 679\n",
      "loss None\n",
      "batch time cost: 5.314831256866455\n",
      "Epoch: 0, batch: 680\n",
      "loss None\n",
      "batch time cost: 5.772677183151245\n",
      "Relu Train Epoch: 0 [43520/318582 (0%)]\tLoss: 1.002501\n",
      "Epoch: 0, batch: 681\n",
      "loss None\n",
      "batch time cost: 5.318737745285034\n",
      "Epoch: 0, batch: 682\n",
      "loss None\n",
      "batch time cost: 5.288739204406738\n",
      "Epoch: 0, batch: 683\n",
      "loss None\n",
      "batch time cost: 5.628993988037109\n",
      "Epoch: 0, batch: 684\n",
      "loss None\n",
      "batch time cost: 5.27245020866394\n",
      "Epoch: 0, batch: 685\n",
      "loss None\n",
      "batch time cost: 5.287107944488525\n",
      "Epoch: 0, batch: 686\n",
      "loss None\n",
      "batch time cost: 5.269371032714844\n",
      "Epoch: 0, batch: 687\n",
      "loss None\n",
      "batch time cost: 5.271523952484131\n",
      "Epoch: 0, batch: 688\n",
      "loss None\n",
      "batch time cost: 5.274801254272461\n",
      "Epoch: 0, batch: 689\n",
      "loss None\n",
      "batch time cost: 5.29244589805603\n",
      "Epoch: 0, batch: 690\n",
      "loss None\n",
      "batch time cost: 5.591418027877808\n",
      "Relu Train Epoch: 0 [44160/318582 (0%)]\tLoss: 1.183140\n",
      "Epoch: 0, batch: 691\n",
      "loss None\n",
      "batch time cost: 5.196800947189331\n",
      "Epoch: 0, batch: 692\n",
      "loss None\n",
      "batch time cost: 5.2078022956848145\n",
      "Epoch: 0, batch: 693\n",
      "loss None\n",
      "batch time cost: 5.362690210342407\n",
      "Epoch: 0, batch: 694\n",
      "loss None\n",
      "batch time cost: 5.358229875564575\n",
      "Epoch: 0, batch: 695\n",
      "loss None\n",
      "batch time cost: 6.823123931884766\n",
      "Epoch: 0, batch: 696\n",
      "loss None\n",
      "batch time cost: 5.89296293258667\n",
      "Epoch: 0, batch: 697\n",
      "loss None\n",
      "batch time cost: 5.771359920501709\n",
      "Epoch: 0, batch: 698\n",
      "loss None\n",
      "batch time cost: 6.211038112640381\n",
      "Epoch: 0, batch: 699\n",
      "loss None\n",
      "batch time cost: 5.3059587478637695\n",
      "Epoch: 0, batch: 700\n",
      "loss None\n",
      "batch time cost: 5.281406879425049\n",
      "Relu Train Epoch: 0 [44800/318582 (0%)]\tLoss: 1.010583\n",
      "Epoch: 0, batch: 701\n",
      "loss None\n",
      "batch time cost: 5.248155117034912\n",
      "Epoch: 0, batch: 702\n",
      "loss None\n",
      "batch time cost: 5.287660837173462\n",
      "Epoch: 0, batch: 703\n",
      "loss None\n",
      "batch time cost: 5.240074872970581\n",
      "Epoch: 0, batch: 704\n",
      "loss None\n",
      "batch time cost: 5.233526945114136\n",
      "Epoch: 0, batch: 705\n",
      "loss None\n",
      "batch time cost: 5.975221872329712\n",
      "Epoch: 0, batch: 706\n",
      "loss None\n",
      "batch time cost: 5.320448875427246\n",
      "Epoch: 0, batch: 707\n",
      "loss None\n",
      "batch time cost: 5.263317108154297\n",
      "Epoch: 0, batch: 708\n",
      "loss None\n",
      "batch time cost: 5.230705261230469\n",
      "Epoch: 0, batch: 709\n",
      "loss None\n",
      "batch time cost: 5.262608051300049\n",
      "Epoch: 0, batch: 710\n",
      "loss None\n",
      "batch time cost: 5.241347789764404\n",
      "Relu Train Epoch: 0 [45440/318582 (0%)]\tLoss: 1.067466\n",
      "Epoch: 0, batch: 711\n",
      "loss None\n",
      "batch time cost: 5.273119926452637\n",
      "Epoch: 0, batch: 712\n",
      "loss None\n",
      "batch time cost: 5.608781814575195\n",
      "Epoch: 0, batch: 713\n",
      "loss None\n",
      "batch time cost: 5.237385272979736\n",
      "Epoch: 0, batch: 714\n",
      "loss None\n",
      "batch time cost: 5.300329923629761\n",
      "Epoch: 0, batch: 715\n",
      "loss None\n",
      "batch time cost: 5.2766783237457275\n",
      "Epoch: 0, batch: 716\n",
      "loss None\n",
      "batch time cost: 5.701102018356323\n",
      "Epoch: 0, batch: 717\n",
      "loss None\n",
      "batch time cost: 6.109028100967407\n",
      "Epoch: 0, batch: 718\n",
      "loss None\n",
      "batch time cost: 5.904863119125366\n",
      "Epoch: 0, batch: 719\n",
      "loss None\n",
      "batch time cost: 6.100470066070557\n",
      "Epoch: 0, batch: 720\n",
      "loss None\n",
      "batch time cost: 5.316574811935425\n",
      "Relu Train Epoch: 0 [46080/318582 (0%)]\tLoss: 0.779098\n",
      "Epoch: 0, batch: 721\n",
      "loss None\n",
      "batch time cost: 5.289912223815918\n",
      "Epoch: 0, batch: 722\n",
      "loss None\n",
      "batch time cost: 5.258220195770264\n",
      "Epoch: 0, batch: 723\n",
      "loss None\n",
      "batch time cost: 5.192850828170776\n",
      "Epoch: 0, batch: 724\n",
      "loss None\n",
      "batch time cost: 5.224493026733398\n",
      "Epoch: 0, batch: 725\n",
      "loss None\n",
      "batch time cost: 5.229582071304321\n",
      "Epoch: 0, batch: 726\n",
      "loss None\n",
      "batch time cost: 6.653581142425537\n",
      "Epoch: 0, batch: 727\n",
      "loss None\n",
      "batch time cost: 7.157382011413574\n",
      "Epoch: 0, batch: 728\n",
      "loss None\n",
      "batch time cost: 5.715524911880493\n",
      "Epoch: 0, batch: 729\n",
      "loss None\n",
      "batch time cost: 5.352171897888184\n",
      "Epoch: 0, batch: 730\n",
      "loss None\n",
      "batch time cost: 5.258681774139404\n",
      "Relu Train Epoch: 0 [46720/318582 (0%)]\tLoss: 0.953698\n",
      "Epoch: 0, batch: 731\n",
      "loss None\n",
      "batch time cost: 5.29138708114624\n",
      "Epoch: 0, batch: 732\n",
      "loss None\n",
      "batch time cost: 5.29686713218689\n",
      "Epoch: 0, batch: 733\n",
      "loss None\n",
      "batch time cost: 5.683497190475464\n",
      "Epoch: 0, batch: 734\n",
      "loss None\n",
      "batch time cost: 5.77836799621582\n",
      "Epoch: 0, batch: 735\n",
      "loss None\n",
      "batch time cost: 7.493868112564087\n",
      "Epoch: 0, batch: 736\n",
      "loss None\n",
      "batch time cost: 5.261396884918213\n",
      "Epoch: 0, batch: 737\n",
      "loss None\n",
      "batch time cost: 5.301590919494629\n",
      "Epoch: 0, batch: 738\n",
      "loss None\n",
      "batch time cost: 5.222859859466553\n",
      "Epoch: 0, batch: 739\n",
      "loss None\n",
      "batch time cost: 5.226327657699585\n",
      "Epoch: 0, batch: 740\n",
      "loss None\n",
      "batch time cost: 5.252779006958008\n",
      "Relu Train Epoch: 0 [47360/318582 (0%)]\tLoss: 0.811277\n",
      "Epoch: 0, batch: 741\n",
      "loss None\n",
      "batch time cost: 8.136997699737549\n",
      "Epoch: 0, batch: 742\n",
      "loss None\n",
      "batch time cost: 6.6384828090667725\n",
      "Epoch: 0, batch: 743\n",
      "loss None\n",
      "batch time cost: 6.707274913787842\n",
      "Epoch: 0, batch: 744\n",
      "loss None\n",
      "batch time cost: 6.084213972091675\n",
      "Epoch: 0, batch: 745\n",
      "loss None\n",
      "batch time cost: 5.506160020828247\n",
      "Epoch: 0, batch: 746\n",
      "loss None\n",
      "batch time cost: 5.301301956176758\n",
      "Epoch: 0, batch: 747\n",
      "loss None\n",
      "batch time cost: 5.282638072967529\n",
      "Epoch: 0, batch: 748\n",
      "loss None\n",
      "batch time cost: 5.892390012741089\n",
      "Epoch: 0, batch: 749\n",
      "loss None\n",
      "batch time cost: 5.405199289321899\n",
      "Epoch: 0, batch: 750\n",
      "loss None\n",
      "batch time cost: 5.2947587966918945\n",
      "Relu Train Epoch: 0 [48000/318582 (0%)]\tLoss: 1.040688\n",
      "Epoch: 0, batch: 751\n",
      "loss None\n",
      "batch time cost: 5.246190071105957\n",
      "Epoch: 0, batch: 752\n",
      "loss None\n",
      "batch time cost: 5.286365032196045\n",
      "Epoch: 0, batch: 753\n",
      "loss None\n",
      "batch time cost: 5.245394229888916\n",
      "Epoch: 0, batch: 754\n",
      "loss None\n",
      "batch time cost: 5.314393043518066\n",
      "Epoch: 0, batch: 755\n",
      "loss None\n",
      "batch time cost: 6.121898889541626\n",
      "Epoch: 0, batch: 756\n",
      "loss None\n",
      "batch time cost: 5.239259958267212\n",
      "Epoch: 0, batch: 757\n",
      "loss None\n",
      "batch time cost: 5.314942121505737\n",
      "Epoch: 0, batch: 758\n",
      "loss None\n",
      "batch time cost: 5.29978084564209\n",
      "Epoch: 0, batch: 759\n",
      "loss None\n",
      "batch time cost: 5.2524120807647705\n",
      "Epoch: 0, batch: 760\n",
      "loss None\n",
      "batch time cost: 5.326984882354736\n",
      "Relu Train Epoch: 0 [48640/318582 (0%)]\tLoss: 0.856319\n",
      "Epoch: 0, batch: 761\n",
      "loss None\n",
      "batch time cost: 5.287879943847656\n",
      "Epoch: 0, batch: 762\n",
      "loss None\n",
      "batch time cost: 5.3226470947265625\n",
      "Epoch: 0, batch: 763\n",
      "loss None\n",
      "batch time cost: 6.1050708293914795\n",
      "Epoch: 0, batch: 764\n",
      "loss None\n",
      "batch time cost: 5.594892978668213\n",
      "Epoch: 0, batch: 765\n",
      "loss None\n",
      "batch time cost: 5.313121795654297\n",
      "Epoch: 0, batch: 766\n",
      "loss None\n",
      "batch time cost: 5.234454870223999\n",
      "Epoch: 0, batch: 767\n",
      "loss None\n",
      "batch time cost: 5.262336015701294\n",
      "Epoch: 0, batch: 768\n",
      "loss None\n",
      "batch time cost: 5.2978761196136475\n",
      "Epoch: 0, batch: 769\n",
      "loss None\n",
      "batch time cost: 5.270420074462891\n",
      "Epoch: 0, batch: 770\n",
      "loss None\n",
      "batch time cost: 6.160629034042358\n",
      "Relu Train Epoch: 0 [49280/318582 (0%)]\tLoss: 0.693865\n",
      "Epoch: 0, batch: 771\n",
      "loss None\n",
      "batch time cost: 5.3454577922821045\n",
      "Epoch: 0, batch: 772\n",
      "loss None\n",
      "batch time cost: 5.2830400466918945\n",
      "Epoch: 0, batch: 773\n",
      "loss None\n",
      "batch time cost: 5.2854979038238525\n",
      "Epoch: 0, batch: 774\n",
      "loss None\n",
      "batch time cost: 5.230002164840698\n",
      "Epoch: 0, batch: 775\n",
      "loss None\n",
      "batch time cost: 5.314083099365234\n",
      "Epoch: 0, batch: 776\n",
      "loss None\n",
      "batch time cost: 5.270301103591919\n",
      "Epoch: 0, batch: 777\n",
      "loss None\n",
      "batch time cost: 5.8610920906066895\n",
      "Epoch: 0, batch: 778\n",
      "loss None\n",
      "batch time cost: 5.377562046051025\n",
      "Epoch: 0, batch: 779\n",
      "loss None\n",
      "batch time cost: 5.435198783874512\n",
      "Epoch: 0, batch: 780\n",
      "loss None\n",
      "batch time cost: 5.312371015548706\n",
      "Relu Train Epoch: 0 [49920/318582 (0%)]\tLoss: 1.115796\n",
      "Epoch: 0, batch: 781\n",
      "loss None\n",
      "batch time cost: 5.332641124725342\n",
      "Epoch: 0, batch: 782\n",
      "loss None\n",
      "batch time cost: 5.258363962173462\n",
      "Epoch: 0, batch: 783\n",
      "loss None\n",
      "batch time cost: 5.285178899765015\n",
      "Epoch: 0, batch: 784\n",
      "loss None\n",
      "batch time cost: 5.938894033432007\n",
      "Epoch: 0, batch: 785\n",
      "loss None\n",
      "batch time cost: 5.30499792098999\n",
      "Epoch: 0, batch: 786\n",
      "loss None\n",
      "batch time cost: 5.25671911239624\n",
      "Epoch: 0, batch: 787\n",
      "loss None\n",
      "batch time cost: 5.30282998085022\n",
      "Epoch: 0, batch: 788\n",
      "loss None\n",
      "batch time cost: 5.264665842056274\n",
      "Epoch: 0, batch: 789\n",
      "loss None\n",
      "batch time cost: 5.238353729248047\n",
      "Epoch: 0, batch: 790\n",
      "loss None\n",
      "batch time cost: 5.238360166549683\n",
      "Relu Train Epoch: 0 [50560/318582 (0%)]\tLoss: 0.926882\n",
      "Epoch: 0, batch: 791\n",
      "loss None\n",
      "batch time cost: 5.684317111968994\n",
      "Epoch: 0, batch: 792\n",
      "loss None\n",
      "batch time cost: 5.321894884109497\n",
      "Epoch: 0, batch: 793\n",
      "loss None\n",
      "batch time cost: 5.270556926727295\n",
      "Epoch: 0, batch: 794\n",
      "loss None\n",
      "batch time cost: 5.2135679721832275\n",
      "Epoch: 0, batch: 795\n",
      "loss None\n",
      "batch time cost: 5.23747992515564\n",
      "Epoch: 0, batch: 796\n",
      "loss None\n",
      "batch time cost: 5.265773057937622\n",
      "Epoch: 0, batch: 797\n",
      "loss None\n",
      "batch time cost: 5.26695704460144\n",
      "Epoch: 0, batch: 798\n",
      "loss None\n",
      "batch time cost: 5.22228217124939\n",
      "Epoch: 0, batch: 799\n",
      "loss None\n",
      "batch time cost: 6.207370042800903\n",
      "Epoch: 0, batch: 800\n",
      "loss None\n",
      "batch time cost: 5.960852861404419\n",
      "Relu Train Epoch: 0 [51200/318582 (0%)]\tLoss: 0.827267\n",
      "Epoch: 0, batch: 801\n",
      "loss None\n",
      "batch time cost: 7.512149095535278\n",
      "Epoch: 0, batch: 802\n",
      "loss None\n",
      "batch time cost: 7.5793023109436035\n",
      "Epoch: 0, batch: 803\n",
      "loss None\n",
      "batch time cost: 5.94501805305481\n",
      "Epoch: 0, batch: 804\n",
      "loss None\n",
      "batch time cost: 5.857170820236206\n",
      "Epoch: 0, batch: 805\n",
      "loss None\n",
      "batch time cost: 5.349686145782471\n",
      "Epoch: 0, batch: 806\n",
      "loss None\n",
      "batch time cost: 5.626722812652588\n",
      "Epoch: 0, batch: 807\n",
      "loss None\n",
      "batch time cost: 5.280921936035156\n",
      "Epoch: 0, batch: 808\n",
      "loss None\n",
      "batch time cost: 5.234141111373901\n",
      "Epoch: 0, batch: 809\n",
      "loss None\n",
      "batch time cost: 5.225183963775635\n",
      "Epoch: 0, batch: 810\n",
      "loss None\n",
      "batch time cost: 5.21812105178833\n",
      "Relu Train Epoch: 0 [51840/318582 (0%)]\tLoss: 1.138620\n",
      "Epoch: 0, batch: 811\n",
      "loss None\n",
      "batch time cost: 5.243865251541138\n",
      "Epoch: 0, batch: 812\n",
      "loss None\n",
      "batch time cost: 5.260290145874023\n",
      "Epoch: 0, batch: 813\n",
      "loss None\n",
      "batch time cost: 7.7850329875946045\n",
      "Epoch: 0, batch: 814\n",
      "loss None\n",
      "batch time cost: 5.698184967041016\n",
      "Epoch: 0, batch: 815\n",
      "loss None\n",
      "batch time cost: 5.347671747207642\n",
      "Epoch: 0, batch: 816\n",
      "loss None\n",
      "batch time cost: 5.468448877334595\n",
      "Epoch: 0, batch: 817\n",
      "loss None\n",
      "batch time cost: 5.339761018753052\n",
      "Epoch: 0, batch: 818\n",
      "loss None\n",
      "batch time cost: 5.31227707862854\n",
      "Epoch: 0, batch: 819\n",
      "loss None\n",
      "batch time cost: 5.287943124771118\n",
      "Epoch: 0, batch: 820\n",
      "loss None\n",
      "batch time cost: 5.610071182250977\n",
      "Relu Train Epoch: 0 [52480/318582 (0%)]\tLoss: 0.979762\n",
      "Epoch: 0, batch: 821\n",
      "loss None\n",
      "batch time cost: 5.298778772354126\n",
      "Epoch: 0, batch: 822\n",
      "loss None\n",
      "batch time cost: 5.275034189224243\n",
      "Epoch: 0, batch: 823\n",
      "loss None\n",
      "batch time cost: 5.3033857345581055\n",
      "Epoch: 0, batch: 824\n",
      "loss None\n",
      "batch time cost: 5.326021194458008\n",
      "Epoch: 0, batch: 825\n",
      "loss None\n",
      "batch time cost: 5.261924982070923\n",
      "Epoch: 0, batch: 826\n",
      "loss None\n",
      "batch time cost: 5.282833814620972\n",
      "Epoch: 0, batch: 827\n",
      "loss None\n",
      "batch time cost: 5.240225076675415\n",
      "Epoch: 0, batch: 828\n",
      "loss None\n",
      "batch time cost: 5.851047039031982\n",
      "Epoch: 0, batch: 829\n",
      "loss None\n",
      "batch time cost: 5.295740842819214\n",
      "Epoch: 0, batch: 830\n",
      "loss None\n",
      "batch time cost: 5.2658302783966064\n",
      "Relu Train Epoch: 0 [53120/318582 (0%)]\tLoss: 0.921783\n",
      "Epoch: 0, batch: 831\n",
      "loss None\n",
      "batch time cost: 5.238036870956421\n",
      "Epoch: 0, batch: 832\n",
      "loss None\n",
      "batch time cost: 5.315230846405029\n",
      "Epoch: 0, batch: 833\n",
      "loss None\n",
      "batch time cost: 5.585397958755493\n",
      "Epoch: 0, batch: 834\n",
      "loss None\n",
      "batch time cost: 5.217730760574341\n",
      "Epoch: 0, batch: 835\n",
      "loss None\n",
      "batch time cost: 7.299520015716553\n",
      "Epoch: 0, batch: 836\n",
      "loss None\n",
      "batch time cost: 7.1441850662231445\n",
      "Epoch: 0, batch: 837\n",
      "loss None\n",
      "batch time cost: 7.418978929519653\n",
      "Epoch: 0, batch: 838\n",
      "loss None\n",
      "batch time cost: 7.656852960586548\n",
      "Epoch: 0, batch: 839\n",
      "loss None\n",
      "batch time cost: 7.376507043838501\n",
      "Epoch: 0, batch: 840\n",
      "loss None\n",
      "batch time cost: 5.264309883117676\n",
      "Relu Train Epoch: 0 [53760/318582 (0%)]\tLoss: 1.050551\n",
      "Epoch: 0, batch: 841\n",
      "loss None\n",
      "batch time cost: 5.23143196105957\n",
      "Epoch: 0, batch: 842\n",
      "loss None\n",
      "batch time cost: 5.716914176940918\n",
      "Epoch: 0, batch: 843\n",
      "loss None\n",
      "batch time cost: 5.268125057220459\n",
      "Epoch: 0, batch: 844\n",
      "loss None\n",
      "batch time cost: 5.290338039398193\n",
      "Epoch: 0, batch: 845\n",
      "loss None\n",
      "batch time cost: 5.320066213607788\n",
      "Epoch: 0, batch: 846\n",
      "loss None\n",
      "batch time cost: 5.229706048965454\n",
      "Epoch: 0, batch: 847\n",
      "loss None\n",
      "batch time cost: 5.22380518913269\n",
      "Epoch: 0, batch: 848\n",
      "loss None\n",
      "batch time cost: 5.384608030319214\n",
      "Epoch: 0, batch: 849\n",
      "loss None\n",
      "batch time cost: 6.20048713684082\n",
      "Epoch: 0, batch: 850\n",
      "loss None\n",
      "batch time cost: 5.913140058517456\n",
      "Relu Train Epoch: 0 [54400/318582 (0%)]\tLoss: 0.916103\n",
      "Epoch: 0, batch: 851\n",
      "loss None\n",
      "batch time cost: 5.591102838516235\n",
      "Epoch: 0, batch: 852\n",
      "loss None\n",
      "batch time cost: 5.378116846084595\n",
      "Epoch: 0, batch: 853\n",
      "loss None\n",
      "batch time cost: 5.268203973770142\n",
      "Epoch: 0, batch: 854\n",
      "loss None\n",
      "batch time cost: 5.247424125671387\n",
      "Epoch: 0, batch: 855\n",
      "loss None\n",
      "batch time cost: 5.265417814254761\n",
      "Epoch: 0, batch: 856\n",
      "loss None\n",
      "batch time cost: 5.642527103424072\n",
      "Epoch: 0, batch: 857\n",
      "loss None\n",
      "batch time cost: 5.3480918407440186\n",
      "Epoch: 0, batch: 858\n",
      "loss None\n",
      "batch time cost: 5.2839438915252686\n",
      "Epoch: 0, batch: 859\n",
      "loss None\n",
      "batch time cost: 5.287118911743164\n",
      "Epoch: 0, batch: 860\n",
      "loss None\n",
      "batch time cost: 5.275735139846802\n",
      "Relu Train Epoch: 0 [55040/318582 (0%)]\tLoss: 0.892816\n",
      "Epoch: 0, batch: 861\n",
      "loss None\n",
      "batch time cost: 5.274860143661499\n",
      "Epoch: 0, batch: 862\n",
      "loss None\n",
      "batch time cost: 5.2410430908203125\n",
      "Epoch: 0, batch: 863\n",
      "loss None\n",
      "batch time cost: 5.232799053192139\n",
      "Epoch: 0, batch: 864\n",
      "loss None\n",
      "batch time cost: 5.6129279136657715\n",
      "Epoch: 0, batch: 865\n",
      "loss None\n",
      "batch time cost: 5.2599310874938965\n",
      "Epoch: 0, batch: 866\n",
      "loss None\n",
      "batch time cost: 5.271789789199829\n",
      "Epoch: 0, batch: 867\n",
      "loss None\n",
      "batch time cost: 5.453369140625\n",
      "Epoch: 0, batch: 868\n",
      "loss None\n",
      "batch time cost: 5.509175062179565\n",
      "Epoch: 0, batch: 869\n",
      "loss None\n",
      "batch time cost: 5.307455062866211\n",
      "Epoch: 0, batch: 870\n",
      "loss None\n",
      "batch time cost: 5.238058090209961\n",
      "Relu Train Epoch: 0 [55680/318582 (0%)]\tLoss: 0.843952\n",
      "Epoch: 0, batch: 871\n",
      "loss None\n",
      "batch time cost: 5.619489908218384\n",
      "Epoch: 0, batch: 872\n",
      "loss None\n",
      "batch time cost: 5.319370985031128\n",
      "Epoch: 0, batch: 873\n",
      "loss None\n",
      "batch time cost: 5.876276016235352\n",
      "Epoch: 0, batch: 874\n",
      "loss None\n",
      "batch time cost: 5.3479249477386475\n",
      "Epoch: 0, batch: 875\n",
      "loss None\n",
      "batch time cost: 5.267247915267944\n",
      "Epoch: 0, batch: 876\n",
      "loss None\n",
      "batch time cost: 5.235716104507446\n",
      "Epoch: 0, batch: 877\n",
      "loss None\n",
      "batch time cost: 5.230123043060303\n",
      "Epoch: 0, batch: 878\n",
      "loss None\n",
      "batch time cost: 5.674681663513184\n",
      "Epoch: 0, batch: 879\n",
      "loss None\n",
      "batch time cost: 5.4710540771484375\n",
      "Epoch: 0, batch: 880\n",
      "loss None\n",
      "batch time cost: 5.384227752685547\n",
      "Relu Train Epoch: 0 [56320/318582 (0%)]\tLoss: 0.856518\n",
      "Epoch: 0, batch: 881\n",
      "loss None\n",
      "batch time cost: 5.271580934524536\n",
      "Epoch: 0, batch: 882\n",
      "loss None\n",
      "batch time cost: 5.246560096740723\n",
      "Epoch: 0, batch: 883\n",
      "loss None\n",
      "batch time cost: 5.238445043563843\n",
      "Epoch: 0, batch: 884\n",
      "loss None\n",
      "batch time cost: 5.268327951431274\n",
      "Epoch: 0, batch: 885\n",
      "loss None\n",
      "batch time cost: 5.620328903198242\n",
      "Epoch: 0, batch: 886\n",
      "loss None\n",
      "batch time cost: 5.256123304367065\n",
      "Epoch: 0, batch: 887\n",
      "loss None\n",
      "batch time cost: 5.304993152618408\n",
      "Epoch: 0, batch: 888\n",
      "loss None\n",
      "batch time cost: 5.344879865646362\n",
      "Epoch: 0, batch: 889\n",
      "loss None\n",
      "batch time cost: 5.323360919952393\n",
      "Epoch: 0, batch: 890\n",
      "loss None\n",
      "batch time cost: 5.316004753112793\n",
      "Relu Train Epoch: 0 [56960/318582 (0%)]\tLoss: 0.874033\n",
      "Epoch: 0, batch: 891\n",
      "loss None\n",
      "batch time cost: 5.2964091300964355\n",
      "Epoch: 0, batch: 892\n",
      "loss None\n",
      "batch time cost: 5.26598596572876\n",
      "Epoch: 0, batch: 893\n",
      "loss None\n",
      "batch time cost: 5.866864919662476\n",
      "Epoch: 0, batch: 894\n",
      "loss None\n",
      "batch time cost: 5.422098875045776\n",
      "Epoch: 0, batch: 895\n",
      "loss None\n",
      "batch time cost: 5.487605810165405\n",
      "Epoch: 0, batch: 896\n",
      "loss None\n",
      "batch time cost: 5.34361720085144\n",
      "Epoch: 0, batch: 897\n",
      "loss None\n",
      "batch time cost: 5.349308013916016\n",
      "Epoch: 0, batch: 898\n",
      "loss None\n",
      "batch time cost: 5.287024736404419\n",
      "Epoch: 0, batch: 899\n",
      "loss None\n",
      "batch time cost: 5.224446058273315\n",
      "Epoch: 0, batch: 900\n",
      "loss None\n",
      "batch time cost: 7.108861923217773\n",
      "Relu Train Epoch: 0 [57600/318582 (0%)]\tLoss: 0.947274\n",
      "Epoch: 0, batch: 901\n",
      "loss None\n",
      "batch time cost: 5.322427272796631\n",
      "Epoch: 0, batch: 902\n",
      "loss None\n",
      "batch time cost: 5.310420036315918\n",
      "Epoch: 0, batch: 903\n",
      "loss None\n",
      "batch time cost: 5.232372045516968\n",
      "Epoch: 0, batch: 904\n",
      "loss None\n",
      "batch time cost: 5.280881881713867\n",
      "Epoch: 0, batch: 905\n",
      "loss None\n",
      "batch time cost: 5.256324768066406\n",
      "Epoch: 0, batch: 906\n",
      "loss None\n",
      "batch time cost: 5.263737916946411\n",
      "Epoch: 0, batch: 907\n",
      "loss None\n",
      "batch time cost: 5.545004844665527\n",
      "Epoch: 0, batch: 908\n",
      "loss None\n",
      "batch time cost: 5.255246162414551\n",
      "Epoch: 0, batch: 909\n",
      "loss None\n",
      "batch time cost: 5.2445762157440186\n",
      "Epoch: 0, batch: 910\n",
      "loss None\n",
      "batch time cost: 5.357939004898071\n",
      "Relu Train Epoch: 0 [58240/318582 (0%)]\tLoss: 0.711546\n",
      "Epoch: 0, batch: 911\n",
      "loss None\n",
      "batch time cost: 5.638753890991211\n",
      "Epoch: 0, batch: 912\n",
      "loss None\n",
      "batch time cost: 5.347130060195923\n",
      "Epoch: 0, batch: 913\n",
      "loss None\n",
      "batch time cost: 5.289930820465088\n",
      "Epoch: 0, batch: 914\n",
      "loss None\n",
      "batch time cost: 6.005957841873169\n",
      "Epoch: 0, batch: 915\n",
      "loss None\n",
      "batch time cost: 5.4215168952941895\n",
      "Epoch: 0, batch: 916\n",
      "loss None\n",
      "batch time cost: 5.258572101593018\n",
      "Epoch: 0, batch: 917\n",
      "loss None\n",
      "batch time cost: 5.237897872924805\n",
      "Epoch: 0, batch: 918\n",
      "loss None\n",
      "batch time cost: 5.2305827140808105\n",
      "Epoch: 0, batch: 919\n",
      "loss None\n",
      "batch time cost: 5.196501016616821\n",
      "Epoch: 0, batch: 920\n",
      "loss None\n",
      "batch time cost: 5.3087170124053955\n",
      "Relu Train Epoch: 0 [58880/318582 (0%)]\tLoss: 0.927916\n",
      "Epoch: 0, batch: 921\n",
      "loss None\n",
      "batch time cost: 5.620760917663574\n",
      "Epoch: 0, batch: 922\n",
      "loss None\n",
      "batch time cost: 5.745585203170776\n",
      "Epoch: 0, batch: 923\n",
      "loss None\n",
      "batch time cost: 5.660357236862183\n",
      "Epoch: 0, batch: 924\n",
      "loss None\n",
      "batch time cost: 5.301292181015015\n",
      "Epoch: 0, batch: 925\n",
      "loss None\n",
      "batch time cost: 5.29302191734314\n",
      "Epoch: 0, batch: 926\n",
      "loss None\n",
      "batch time cost: 5.264793157577515\n",
      "Epoch: 0, batch: 927\n",
      "loss None\n",
      "batch time cost: 5.269374847412109\n",
      "Epoch: 0, batch: 928\n",
      "loss None\n",
      "batch time cost: 5.258465051651001\n",
      "Epoch: 0, batch: 929\n",
      "loss None\n",
      "batch time cost: 5.619038105010986\n",
      "Epoch: 0, batch: 930\n",
      "loss None\n",
      "batch time cost: 5.226854085922241\n",
      "Relu Train Epoch: 0 [59520/318582 (0%)]\tLoss: 0.736763\n",
      "Epoch: 0, batch: 931\n",
      "loss None\n",
      "batch time cost: 5.270659923553467\n",
      "Epoch: 0, batch: 932\n",
      "loss None\n",
      "batch time cost: 5.274943113327026\n",
      "Epoch: 0, batch: 933\n",
      "loss None\n",
      "batch time cost: 5.791602373123169\n",
      "Epoch: 0, batch: 934\n",
      "loss None\n",
      "batch time cost: 6.581449031829834\n",
      "Epoch: 0, batch: 935\n",
      "loss None\n",
      "batch time cost: 5.888315916061401\n",
      "Epoch: 0, batch: 936\n",
      "loss None\n",
      "batch time cost: 6.5135838985443115\n",
      "Epoch: 0, batch: 937\n",
      "loss None\n",
      "batch time cost: 5.6824140548706055\n",
      "Epoch: 0, batch: 938\n",
      "loss None\n",
      "batch time cost: 5.329089879989624\n",
      "Epoch: 0, batch: 939\n",
      "loss None\n",
      "batch time cost: 5.3552069664001465\n",
      "Epoch: 0, batch: 940\n",
      "loss None\n",
      "batch time cost: 5.281245946884155\n",
      "Relu Train Epoch: 0 [60160/318582 (0%)]\tLoss: 0.869067\n",
      "Epoch: 0, batch: 941\n",
      "loss None\n",
      "batch time cost: 5.257269859313965\n",
      "Epoch: 0, batch: 942\n",
      "loss None\n",
      "batch time cost: 5.236652135848999\n",
      "Epoch: 0, batch: 943\n",
      "loss None\n",
      "batch time cost: 5.8060832023620605\n",
      "Epoch: 0, batch: 944\n",
      "loss None\n",
      "batch time cost: 5.435266971588135\n",
      "Epoch: 0, batch: 945\n",
      "loss None\n",
      "batch time cost: 7.148705959320068\n",
      "Epoch: 0, batch: 946\n",
      "loss None\n",
      "batch time cost: 5.304091691970825\n",
      "Epoch: 0, batch: 947\n",
      "loss None\n",
      "batch time cost: 5.2507569789886475\n",
      "Epoch: 0, batch: 948\n",
      "loss None\n",
      "batch time cost: 5.251942157745361\n",
      "Epoch: 0, batch: 949\n",
      "loss None\n",
      "batch time cost: 5.231312036514282\n",
      "Epoch: 0, batch: 950\n",
      "loss None\n",
      "batch time cost: 5.544624090194702\n",
      "Relu Train Epoch: 0 [60800/318582 (0%)]\tLoss: 0.928957\n",
      "Epoch: 0, batch: 951\n",
      "loss None\n",
      "batch time cost: 5.288367986679077\n",
      "Epoch: 0, batch: 952\n",
      "loss None\n",
      "batch time cost: 5.744415998458862\n",
      "Epoch: 0, batch: 953\n",
      "loss None\n",
      "batch time cost: 5.883573055267334\n",
      "Epoch: 0, batch: 954\n",
      "loss None\n",
      "batch time cost: 5.752727031707764\n",
      "Epoch: 0, batch: 955\n",
      "loss None\n",
      "batch time cost: 5.454082012176514\n",
      "Epoch: 0, batch: 956\n",
      "loss None\n",
      "batch time cost: 5.325250864028931\n",
      "Epoch: 0, batch: 957\n",
      "loss None\n",
      "batch time cost: 5.317990064620972\n",
      "Epoch: 0, batch: 958\n",
      "loss None\n",
      "batch time cost: 8.661210060119629\n",
      "Epoch: 0, batch: 959\n",
      "loss None\n",
      "batch time cost: 7.923261880874634\n",
      "Epoch: 0, batch: 960\n",
      "loss None\n",
      "batch time cost: 5.498208999633789\n",
      "Relu Train Epoch: 0 [61440/318582 (0%)]\tLoss: 0.855325\n",
      "Epoch: 0, batch: 961\n",
      "loss None\n",
      "batch time cost: 5.34292197227478\n",
      "Epoch: 0, batch: 962\n",
      "loss None\n",
      "batch time cost: 5.331610202789307\n",
      "Epoch: 0, batch: 963\n",
      "loss None\n",
      "batch time cost: 6.772978782653809\n",
      "Epoch: 0, batch: 964\n",
      "loss None\n",
      "batch time cost: 5.3933329582214355\n",
      "Epoch: 0, batch: 965\n",
      "loss None\n",
      "batch time cost: 5.58324408531189\n",
      "Epoch: 0, batch: 966\n",
      "loss None\n",
      "batch time cost: 5.41461706161499\n",
      "Epoch: 0, batch: 967\n",
      "loss None\n",
      "batch time cost: 5.236847162246704\n",
      "Epoch: 0, batch: 968\n",
      "loss None\n",
      "batch time cost: 5.2993950843811035\n",
      "Epoch: 0, batch: 969\n",
      "loss None\n",
      "batch time cost: 5.247676372528076\n",
      "Epoch: 0, batch: 970\n",
      "loss None\n",
      "batch time cost: 5.270835876464844\n",
      "Relu Train Epoch: 0 [62080/318582 (0%)]\tLoss: 0.827679\n",
      "Epoch: 0, batch: 971\n",
      "loss None\n",
      "batch time cost: 5.249168157577515\n",
      "Epoch: 0, batch: 972\n",
      "loss None\n",
      "batch time cost: 6.359396696090698\n",
      "Epoch: 0, batch: 973\n",
      "loss None\n",
      "batch time cost: 5.80677604675293\n",
      "Epoch: 0, batch: 974\n",
      "loss None\n",
      "batch time cost: 6.179147958755493\n",
      "Epoch: 0, batch: 975\n",
      "loss None\n",
      "batch time cost: 6.140953779220581\n",
      "Epoch: 0, batch: 976\n",
      "loss None\n",
      "batch time cost: 6.10955286026001\n",
      "Epoch: 0, batch: 977\n",
      "loss None\n",
      "batch time cost: 5.3035900592803955\n",
      "Epoch: 0, batch: 978\n",
      "loss None\n",
      "batch time cost: 5.308206081390381\n",
      "Epoch: 0, batch: 979\n",
      "loss None\n",
      "batch time cost: 5.5750391483306885\n",
      "Epoch: 0, batch: 980\n",
      "loss None\n",
      "batch time cost: 5.2762367725372314\n",
      "Relu Train Epoch: 0 [62720/318582 (0%)]\tLoss: 0.963724\n",
      "Epoch: 0, batch: 981\n",
      "loss None\n",
      "batch time cost: 5.2441699504852295\n",
      "Epoch: 0, batch: 982\n",
      "loss None\n",
      "batch time cost: 5.278151035308838\n",
      "Epoch: 0, batch: 983\n",
      "loss None\n",
      "batch time cost: 5.306213855743408\n",
      "Epoch: 0, batch: 984\n",
      "loss None\n",
      "batch time cost: 5.581570863723755\n",
      "Epoch: 0, batch: 985\n",
      "loss None\n",
      "batch time cost: 5.292381763458252\n",
      "Epoch: 0, batch: 986\n",
      "loss None\n",
      "batch time cost: 5.711095094680786\n",
      "Epoch: 0, batch: 987\n",
      "loss None\n",
      "batch time cost: 5.3288328647613525\n",
      "Epoch: 0, batch: 988\n",
      "loss None\n",
      "batch time cost: 5.200827121734619\n",
      "Epoch: 0, batch: 989\n",
      "loss None\n",
      "batch time cost: 5.2488250732421875\n",
      "Epoch: 0, batch: 990\n",
      "loss None\n",
      "batch time cost: 5.24873685836792\n",
      "Relu Train Epoch: 0 [63360/318582 (0%)]\tLoss: 0.872484\n",
      "Epoch: 0, batch: 991\n",
      "loss None\n",
      "batch time cost: 5.168498992919922\n",
      "Epoch: 0, batch: 992\n",
      "loss None\n",
      "batch time cost: 5.235631942749023\n",
      "Epoch: 0, batch: 993\n",
      "loss None\n",
      "batch time cost: 5.27845573425293\n",
      "Epoch: 0, batch: 994\n",
      "loss None\n",
      "batch time cost: 5.943571090698242\n",
      "Epoch: 0, batch: 995\n",
      "loss None\n",
      "batch time cost: 5.464179754257202\n",
      "Epoch: 0, batch: 996\n",
      "loss None\n",
      "batch time cost: 5.78559684753418\n",
      "Epoch: 0, batch: 997\n",
      "loss None\n",
      "batch time cost: 5.9112019538879395\n",
      "Epoch: 0, batch: 998\n",
      "loss None\n",
      "batch time cost: 5.675310850143433\n",
      "Epoch: 0, batch: 999\n",
      "loss None\n",
      "batch time cost: 5.276514053344727\n",
      "Epoch: 0, batch: 1000\n",
      "loss None\n",
      "batch time cost: 5.246208906173706\n",
      "Relu Train Epoch: 0 [64000/318582 (0%)]\tLoss: 0.847448\n",
      "Epoch: 0, batch: 1001\n",
      "loss None\n",
      "batch time cost: 5.566367149353027\n",
      "Epoch: 0, batch: 1002\n",
      "loss None\n",
      "batch time cost: 5.219931125640869\n",
      "Epoch: 0, batch: 1003\n",
      "loss None\n",
      "batch time cost: 5.31161093711853\n",
      "Epoch: 0, batch: 1004\n",
      "loss None\n",
      "batch time cost: 5.269964933395386\n",
      "Epoch: 0, batch: 1005\n",
      "loss None\n",
      "batch time cost: 5.589848756790161\n",
      "Epoch: 0, batch: 1006\n",
      "loss None\n",
      "batch time cost: 5.297695159912109\n",
      "Epoch: 0, batch: 1007\n",
      "loss None\n",
      "batch time cost: 5.258264780044556\n",
      "Epoch: 0, batch: 1008\n",
      "loss None\n",
      "batch time cost: 5.6659018993377686\n",
      "Epoch: 0, batch: 1009\n",
      "loss None\n",
      "batch time cost: 5.319900751113892\n",
      "Epoch: 0, batch: 1010\n",
      "loss None\n",
      "batch time cost: 5.2889180183410645\n",
      "Relu Train Epoch: 0 [64640/318582 (0%)]\tLoss: 0.935796\n",
      "Epoch: 0, batch: 1011\n",
      "loss None\n",
      "batch time cost: 5.246608018875122\n",
      "Epoch: 0, batch: 1012\n",
      "loss None\n",
      "batch time cost: 5.28609299659729\n",
      "Epoch: 0, batch: 1013\n",
      "loss None\n",
      "batch time cost: 5.314334154129028\n",
      "Epoch: 0, batch: 1014\n",
      "loss None\n",
      "batch time cost: 5.2543768882751465\n",
      "Epoch: 0, batch: 1015\n",
      "loss None\n",
      "batch time cost: 5.870703220367432\n",
      "Epoch: 0, batch: 1016\n",
      "loss None\n",
      "batch time cost: 5.501265048980713\n",
      "Epoch: 0, batch: 1017\n",
      "loss None\n",
      "batch time cost: 5.468438148498535\n",
      "Epoch: 0, batch: 1018\n",
      "loss None\n",
      "batch time cost: 5.516599893569946\n",
      "Epoch: 0, batch: 1019\n",
      "loss None\n",
      "batch time cost: 5.674038887023926\n",
      "Epoch: 0, batch: 1020\n",
      "loss None\n",
      "batch time cost: 5.2945380210876465\n",
      "Relu Train Epoch: 0 [65280/318582 (0%)]\tLoss: 0.943235\n",
      "Epoch: 0, batch: 1021\n",
      "loss None\n",
      "batch time cost: 5.297752857208252\n",
      "Epoch: 0, batch: 1022\n",
      "loss None\n",
      "batch time cost: 5.288123846054077\n",
      "Epoch: 0, batch: 1023\n",
      "loss None\n",
      "batch time cost: 5.620661020278931\n",
      "Epoch: 0, batch: 1024\n",
      "loss None\n",
      "batch time cost: 5.27800178527832\n",
      "Epoch: 0, batch: 1025\n",
      "loss None\n",
      "batch time cost: 5.254364967346191\n",
      "Epoch: 0, batch: 1026\n",
      "loss None\n",
      "batch time cost: 5.329210996627808\n",
      "Epoch: 0, batch: 1027\n",
      "loss None\n",
      "batch time cost: 5.255922794342041\n",
      "Epoch: 0, batch: 1028\n",
      "loss None\n",
      "batch time cost: 5.262317657470703\n",
      "Epoch: 0, batch: 1029\n",
      "loss None\n",
      "batch time cost: 5.243095874786377\n",
      "Epoch: 0, batch: 1030\n",
      "loss None\n",
      "batch time cost: 5.8778510093688965\n",
      "Relu Train Epoch: 0 [65920/318582 (0%)]\tLoss: 1.003009\n",
      "Epoch: 0, batch: 1031\n",
      "loss None\n",
      "batch time cost: 5.661465167999268\n",
      "Epoch: 0, batch: 1032\n",
      "loss None\n",
      "batch time cost: 5.578716993331909\n",
      "Epoch: 0, batch: 1033\n",
      "loss None\n",
      "batch time cost: 5.47623085975647\n",
      "Epoch: 0, batch: 1034\n",
      "loss None\n",
      "batch time cost: 5.338614225387573\n",
      "Epoch: 0, batch: 1035\n",
      "loss None\n",
      "batch time cost: 5.228032112121582\n",
      "Epoch: 0, batch: 1036\n",
      "loss None\n",
      "batch time cost: 5.297324180603027\n",
      "Epoch: 0, batch: 1037\n",
      "loss None\n",
      "batch time cost: 5.593938827514648\n",
      "Epoch: 0, batch: 1038\n",
      "loss None\n",
      "batch time cost: 5.233884811401367\n",
      "Epoch: 0, batch: 1039\n",
      "loss None\n",
      "batch time cost: 5.260762691497803\n",
      "Epoch: 0, batch: 1040\n",
      "loss None\n",
      "batch time cost: 5.299619197845459\n",
      "Relu Train Epoch: 0 [66560/318582 (0%)]\tLoss: 0.832245\n",
      "Epoch: 0, batch: 1041\n",
      "loss None\n",
      "batch time cost: 5.298836946487427\n",
      "Epoch: 0, batch: 1042\n",
      "loss None\n",
      "batch time cost: 5.358830690383911\n",
      "Epoch: 0, batch: 1043\n",
      "loss None\n",
      "batch time cost: 5.327103853225708\n",
      "Epoch: 0, batch: 1044\n",
      "loss None\n",
      "batch time cost: 5.602740049362183\n",
      "Epoch: 0, batch: 1045\n",
      "loss None\n",
      "batch time cost: 5.299370288848877\n",
      "Epoch: 0, batch: 1046\n",
      "loss None\n",
      "batch time cost: 5.278333902359009\n",
      "Epoch: 0, batch: 1047\n",
      "loss None\n",
      "batch time cost: 5.215307950973511\n",
      "Epoch: 0, batch: 1048\n",
      "loss None\n",
      "batch time cost: 5.272258043289185\n",
      "Epoch: 0, batch: 1049\n",
      "loss None\n",
      "batch time cost: 5.269935131072998\n",
      "Epoch: 0, batch: 1050\n",
      "loss None\n",
      "batch time cost: 5.301821947097778\n",
      "Relu Train Epoch: 0 [67200/318582 (0%)]\tLoss: 0.826612\n",
      "Epoch: 0, batch: 1051\n",
      "loss None\n",
      "batch time cost: 5.814700126647949\n",
      "Epoch: 0, batch: 1052\n",
      "loss None\n",
      "batch time cost: 5.348365068435669\n",
      "Epoch: 0, batch: 1053\n",
      "loss None\n",
      "batch time cost: 6.401517868041992\n",
      "Epoch: 0, batch: 1054\n",
      "loss None\n",
      "batch time cost: 5.659411907196045\n",
      "Epoch: 0, batch: 1055\n",
      "loss None\n",
      "batch time cost: 5.865895986557007\n",
      "Epoch: 0, batch: 1056\n",
      "loss None\n",
      "batch time cost: 5.295539140701294\n",
      "Epoch: 0, batch: 1057\n",
      "loss None\n",
      "batch time cost: 5.285901069641113\n",
      "Epoch: 0, batch: 1058\n",
      "loss None\n",
      "batch time cost: 5.243503093719482\n",
      "Epoch: 0, batch: 1059\n",
      "loss None\n",
      "batch time cost: 5.598664045333862\n",
      "Epoch: 0, batch: 1060\n",
      "loss None\n",
      "batch time cost: 5.2352588176727295\n",
      "Relu Train Epoch: 0 [67840/318582 (0%)]\tLoss: 0.861513\n",
      "Epoch: 0, batch: 1061\n",
      "loss None\n",
      "batch time cost: 5.369945049285889\n",
      "Epoch: 0, batch: 1062\n",
      "loss None\n",
      "batch time cost: 5.400263786315918\n",
      "Epoch: 0, batch: 1063\n",
      "loss None\n",
      "batch time cost: 5.253676891326904\n",
      "Epoch: 0, batch: 1064\n",
      "loss None\n",
      "batch time cost: 5.238980770111084\n",
      "Epoch: 0, batch: 1065\n",
      "loss None\n",
      "batch time cost: 5.233083963394165\n",
      "Epoch: 0, batch: 1066\n",
      "loss None\n",
      "batch time cost: 5.649338722229004\n",
      "Epoch: 0, batch: 1067\n",
      "loss None\n",
      "batch time cost: 5.31787109375\n",
      "Epoch: 0, batch: 1068\n",
      "loss None\n",
      "batch time cost: 5.2765398025512695\n",
      "Epoch: 0, batch: 1069\n",
      "loss None\n",
      "batch time cost: 5.309190034866333\n",
      "Epoch: 0, batch: 1070\n",
      "loss None\n",
      "batch time cost: 5.340384006500244\n",
      "Relu Train Epoch: 0 [68480/318582 (0%)]\tLoss: 0.989791\n",
      "Epoch: 0, batch: 1071\n",
      "loss None\n",
      "batch time cost: 5.371521949768066\n",
      "Epoch: 0, batch: 1072\n",
      "loss None\n",
      "batch time cost: 5.368681907653809\n",
      "Epoch: 0, batch: 1073\n",
      "loss None\n",
      "batch time cost: 5.630724906921387\n",
      "Epoch: 0, batch: 1074\n",
      "loss None\n",
      "batch time cost: 5.24432897567749\n",
      "Epoch: 0, batch: 1075\n",
      "loss None\n",
      "batch time cost: 5.283556938171387\n",
      "Epoch: 0, batch: 1076\n",
      "loss None\n",
      "batch time cost: 5.263918876647949\n",
      "Epoch: 0, batch: 1077\n",
      "loss None\n",
      "batch time cost: 5.276843786239624\n",
      "Epoch: 0, batch: 1078\n",
      "loss None\n",
      "batch time cost: 5.260864734649658\n",
      "Epoch: 0, batch: 1079\n",
      "loss None\n",
      "batch time cost: 5.316140174865723\n",
      "Epoch: 0, batch: 1080\n",
      "loss None\n",
      "batch time cost: 5.617063045501709\n",
      "Relu Train Epoch: 0 [69120/318582 (0%)]\tLoss: 1.006617\n",
      "Epoch: 0, batch: 1081\n",
      "loss None\n",
      "batch time cost: 5.30168890953064\n",
      "Epoch: 0, batch: 1082\n",
      "loss None\n",
      "batch time cost: 5.243127107620239\n",
      "Epoch: 0, batch: 1083\n",
      "loss None\n",
      "batch time cost: 5.263258934020996\n",
      "Epoch: 0, batch: 1084\n",
      "loss None\n",
      "batch time cost: 5.259570837020874\n",
      "Epoch: 0, batch: 1085\n",
      "loss None\n",
      "batch time cost: 5.275092124938965\n",
      "Epoch: 0, batch: 1086\n",
      "loss None\n",
      "batch time cost: 5.652857065200806\n",
      "Epoch: 0, batch: 1087\n",
      "loss None\n",
      "batch time cost: 5.4026219844818115\n",
      "Epoch: 0, batch: 1088\n",
      "loss None\n",
      "batch time cost: 5.607577085494995\n",
      "Epoch: 0, batch: 1089\n",
      "loss None\n",
      "batch time cost: 5.309930086135864\n",
      "Epoch: 0, batch: 1090\n",
      "loss None\n",
      "batch time cost: 5.256296157836914\n",
      "Relu Train Epoch: 0 [69760/318582 (0%)]\tLoss: 0.994298\n",
      "Epoch: 0, batch: 1091\n",
      "loss None\n",
      "batch time cost: 5.220854997634888\n",
      "Epoch: 0, batch: 1092\n",
      "loss None\n",
      "batch time cost: 5.274438858032227\n",
      "Epoch: 0, batch: 1093\n",
      "loss None\n",
      "batch time cost: 5.255389213562012\n",
      "Epoch: 0, batch: 1094\n",
      "loss None\n",
      "batch time cost: 5.290765047073364\n",
      "Epoch: 0, batch: 1095\n",
      "loss None\n",
      "batch time cost: 5.7139060497283936\n",
      "Epoch: 0, batch: 1096\n",
      "loss None\n",
      "batch time cost: 5.633861780166626\n",
      "Epoch: 0, batch: 1097\n",
      "loss None\n",
      "batch time cost: 6.6199951171875\n",
      "Epoch: 0, batch: 1098\n",
      "loss None\n",
      "batch time cost: 5.708430051803589\n",
      "Epoch: 0, batch: 1099\n",
      "loss None\n",
      "batch time cost: 5.328863143920898\n",
      "Epoch: 0, batch: 1100\n",
      "loss None\n",
      "batch time cost: 5.29069709777832\n",
      "Relu Train Epoch: 0 [70400/318582 (0%)]\tLoss: 0.855232\n",
      "Epoch: 0, batch: 1101\n",
      "loss None\n",
      "batch time cost: 5.245390176773071\n",
      "Epoch: 0, batch: 1102\n",
      "loss None\n",
      "batch time cost: 5.744348049163818\n",
      "Epoch: 0, batch: 1103\n",
      "loss None\n",
      "batch time cost: 5.302651882171631\n",
      "Epoch: 0, batch: 1104\n",
      "loss None\n",
      "batch time cost: 5.424804210662842\n",
      "Epoch: 0, batch: 1105\n",
      "loss None\n",
      "batch time cost: 5.551215171813965\n",
      "Epoch: 0, batch: 1106\n",
      "loss None\n",
      "batch time cost: 5.345078706741333\n",
      "Epoch: 0, batch: 1107\n",
      "loss None\n",
      "batch time cost: 5.270562171936035\n",
      "Epoch: 0, batch: 1108\n",
      "loss None\n",
      "batch time cost: 5.307039976119995\n",
      "Epoch: 0, batch: 1109\n",
      "loss None\n",
      "batch time cost: 5.610645055770874\n",
      "Epoch: 0, batch: 1110\n",
      "loss None\n",
      "batch time cost: 5.308624982833862\n",
      "Relu Train Epoch: 0 [71040/318582 (0%)]\tLoss: 0.970396\n",
      "Epoch: 0, batch: 1111\n",
      "loss None\n",
      "batch time cost: 5.2506701946258545\n",
      "Epoch: 0, batch: 1112\n",
      "loss None\n",
      "batch time cost: 5.265585899353027\n",
      "Epoch: 0, batch: 1113\n",
      "loss None\n",
      "batch time cost: 5.268840074539185\n",
      "Epoch: 0, batch: 1114\n",
      "loss None\n",
      "batch time cost: 5.261392831802368\n",
      "Epoch: 0, batch: 1115\n",
      "loss None\n",
      "batch time cost: 5.280400276184082\n",
      "Epoch: 0, batch: 1116\n",
      "loss None\n",
      "batch time cost: 5.637174129486084\n",
      "Epoch: 0, batch: 1117\n",
      "loss None\n",
      "batch time cost: 5.337419033050537\n",
      "Epoch: 0, batch: 1118\n",
      "loss None\n",
      "batch time cost: 5.2961180210113525\n",
      "Epoch: 0, batch: 1119\n",
      "loss None\n",
      "batch time cost: 5.294080018997192\n",
      "Epoch: 0, batch: 1120\n",
      "loss None\n",
      "batch time cost: 5.287932872772217\n",
      "Relu Train Epoch: 0 [71680/318582 (0%)]\tLoss: 0.822331\n",
      "Epoch: 0, batch: 1121\n",
      "loss None\n",
      "batch time cost: 5.256055116653442\n",
      "Epoch: 0, batch: 1122\n",
      "loss None\n",
      "batch time cost: 5.299642086029053\n",
      "Epoch: 0, batch: 1123\n",
      "loss None\n",
      "batch time cost: 5.310008764266968\n",
      "Epoch: 0, batch: 1124\n",
      "loss None\n",
      "batch time cost: 5.906774997711182\n",
      "Epoch: 0, batch: 1125\n",
      "loss None\n",
      "batch time cost: 5.433297157287598\n",
      "Epoch: 0, batch: 1126\n",
      "loss None\n",
      "batch time cost: 5.290450096130371\n",
      "Epoch: 0, batch: 1127\n",
      "loss None\n",
      "batch time cost: 5.262140989303589\n",
      "Epoch: 0, batch: 1128\n",
      "loss None\n",
      "batch time cost: 5.28098201751709\n",
      "Epoch: 0, batch: 1129\n",
      "loss None\n",
      "batch time cost: 5.242973804473877\n",
      "Epoch: 0, batch: 1130\n",
      "loss None\n",
      "batch time cost: 5.298205137252808\n",
      "Relu Train Epoch: 0 [72320/318582 (0%)]\tLoss: 0.763033\n",
      "Epoch: 0, batch: 1131\n",
      "loss None\n",
      "batch time cost: 7.932873010635376\n",
      "Epoch: 0, batch: 1132\n",
      "loss None\n",
      "batch time cost: 7.534671068191528\n",
      "Epoch: 0, batch: 1133\n",
      "loss None\n",
      "batch time cost: 6.5962090492248535\n",
      "Epoch: 0, batch: 1134\n",
      "loss None\n",
      "batch time cost: 5.661226987838745\n",
      "Epoch: 0, batch: 1135\n",
      "loss None\n",
      "batch time cost: 5.382724761962891\n",
      "Epoch: 0, batch: 1136\n",
      "loss None\n",
      "batch time cost: 5.272400140762329\n",
      "Epoch: 0, batch: 1137\n",
      "loss None\n",
      "batch time cost: 5.265942096710205\n",
      "Epoch: 0, batch: 1138\n",
      "loss None\n",
      "batch time cost: 5.671194314956665\n",
      "Epoch: 0, batch: 1139\n",
      "loss None\n",
      "batch time cost: 7.96563982963562\n",
      "Epoch: 0, batch: 1140\n",
      "loss None\n",
      "batch time cost: 5.33744478225708\n",
      "Relu Train Epoch: 0 [72960/318582 (0%)]\tLoss: 0.754090\n",
      "Epoch: 0, batch: 1141\n",
      "loss None\n",
      "batch time cost: 5.245585918426514\n",
      "Epoch: 0, batch: 1142\n",
      "loss None\n",
      "batch time cost: 5.224866151809692\n",
      "Epoch: 0, batch: 1143\n",
      "loss None\n",
      "batch time cost: 5.301760911941528\n",
      "Epoch: 0, batch: 1144\n",
      "loss None\n",
      "batch time cost: 5.31003212928772\n",
      "Epoch: 0, batch: 1145\n",
      "loss None\n",
      "batch time cost: 5.63304591178894\n",
      "Epoch: 0, batch: 1146\n",
      "loss None\n",
      "batch time cost: 5.263818025588989\n",
      "Epoch: 0, batch: 1147\n",
      "loss None\n",
      "batch time cost: 5.307252883911133\n",
      "Epoch: 0, batch: 1148\n",
      "loss None\n",
      "batch time cost: 5.305891990661621\n",
      "Epoch: 0, batch: 1149\n",
      "loss None\n",
      "batch time cost: 5.3344950675964355\n",
      "Epoch: 0, batch: 1150\n",
      "loss None\n",
      "batch time cost: 5.358584642410278\n",
      "Relu Train Epoch: 0 [73600/318582 (0%)]\tLoss: 0.929349\n",
      "Epoch: 0, batch: 1151\n",
      "loss None\n",
      "batch time cost: 5.944383859634399\n",
      "Epoch: 0, batch: 1152\n",
      "loss None\n",
      "batch time cost: 5.765854835510254\n",
      "Epoch: 0, batch: 1153\n",
      "loss None\n",
      "batch time cost: 5.638311147689819\n",
      "Epoch: 0, batch: 1154\n",
      "loss None\n",
      "batch time cost: 5.318648099899292\n",
      "Epoch: 0, batch: 1155\n",
      "loss None\n",
      "batch time cost: 5.359387159347534\n",
      "Epoch: 0, batch: 1156\n",
      "loss None\n",
      "batch time cost: 5.298046350479126\n",
      "Epoch: 0, batch: 1157\n",
      "loss None\n",
      "batch time cost: 5.2425243854522705\n",
      "Epoch: 0, batch: 1158\n",
      "loss None\n",
      "batch time cost: 5.2273478507995605\n",
      "Epoch: 0, batch: 1159\n",
      "loss None\n",
      "batch time cost: 5.286731958389282\n",
      "Epoch: 0, batch: 1160\n",
      "loss None\n",
      "batch time cost: 5.589191913604736\n",
      "Relu Train Epoch: 0 [74240/318582 (0%)]\tLoss: 0.756553\n",
      "Epoch: 0, batch: 1161\n",
      "loss None\n",
      "batch time cost: 5.450389862060547\n",
      "Epoch: 0, batch: 1162\n",
      "loss None\n",
      "batch time cost: 5.322051048278809\n",
      "Epoch: 0, batch: 1163\n",
      "loss None\n",
      "batch time cost: 5.389708042144775\n",
      "Epoch: 0, batch: 1164\n",
      "loss None\n",
      "batch time cost: 5.29861307144165\n",
      "Epoch: 0, batch: 1165\n",
      "loss None\n",
      "batch time cost: 5.2941999435424805\n",
      "Epoch: 0, batch: 1166\n",
      "loss None\n",
      "batch time cost: 5.305430889129639\n",
      "Epoch: 0, batch: 1167\n",
      "loss None\n",
      "batch time cost: 5.602262020111084\n",
      "Epoch: 0, batch: 1168\n",
      "loss None\n",
      "batch time cost: 5.301920175552368\n",
      "Epoch: 0, batch: 1169\n",
      "loss None\n",
      "batch time cost: 5.257403135299683\n",
      "Epoch: 0, batch: 1170\n",
      "loss None\n",
      "batch time cost: 7.708311080932617\n",
      "Relu Train Epoch: 0 [74880/318582 (0%)]\tLoss: 0.805883\n",
      "Epoch: 0, batch: 1171\n",
      "loss None\n",
      "batch time cost: 5.323242902755737\n",
      "Epoch: 0, batch: 1172\n",
      "loss None\n",
      "batch time cost: 5.3306334018707275\n",
      "Epoch: 0, batch: 1173\n",
      "loss None\n",
      "batch time cost: 5.294423818588257\n",
      "Epoch: 0, batch: 1174\n",
      "loss None\n",
      "batch time cost: 5.691666841506958\n",
      "Epoch: 0, batch: 1175\n",
      "loss None\n",
      "batch time cost: 5.357105016708374\n",
      "Epoch: 0, batch: 1176\n",
      "loss None\n",
      "batch time cost: 5.3580851554870605\n",
      "Epoch: 0, batch: 1177\n",
      "loss None\n",
      "batch time cost: 5.260390996932983\n",
      "Epoch: 0, batch: 1178\n",
      "loss None\n",
      "batch time cost: 5.259344816207886\n",
      "Epoch: 0, batch: 1179\n",
      "loss None\n",
      "batch time cost: 5.2649688720703125\n",
      "Epoch: 0, batch: 1180\n",
      "loss None\n",
      "batch time cost: 5.251157999038696\n",
      "Relu Train Epoch: 0 [75520/318582 (0%)]\tLoss: 0.736239\n",
      "Epoch: 0, batch: 1181\n",
      "loss None\n",
      "batch time cost: 5.695874929428101\n",
      "Epoch: 0, batch: 1182\n",
      "loss None\n",
      "batch time cost: 5.28113317489624\n",
      "Epoch: 0, batch: 1183\n",
      "loss None\n",
      "batch time cost: 5.290693998336792\n",
      "Epoch: 0, batch: 1184\n",
      "loss None\n",
      "batch time cost: 5.6777637004852295\n",
      "Epoch: 0, batch: 1185\n",
      "loss None\n",
      "batch time cost: 5.27791690826416\n",
      "Epoch: 0, batch: 1186\n",
      "loss None\n",
      "batch time cost: 5.257974147796631\n",
      "Epoch: 0, batch: 1187\n",
      "loss None\n",
      "batch time cost: 5.2643280029296875\n",
      "Epoch: 0, batch: 1188\n",
      "loss None\n",
      "batch time cost: 5.240994930267334\n",
      "Epoch: 0, batch: 1189\n",
      "loss None\n",
      "batch time cost: 5.900328874588013\n",
      "Epoch: 0, batch: 1190\n",
      "loss None\n",
      "batch time cost: 5.304041862487793\n",
      "Relu Train Epoch: 0 [76160/318582 (0%)]\tLoss: 0.667858\n",
      "Epoch: 0, batch: 1191\n",
      "loss None\n",
      "batch time cost: 5.3102991580963135\n",
      "Epoch: 0, batch: 1192\n",
      "loss None\n",
      "batch time cost: 5.310226917266846\n",
      "Epoch: 0, batch: 1193\n",
      "loss None\n",
      "batch time cost: 5.2639899253845215\n",
      "Epoch: 0, batch: 1194\n",
      "loss None\n",
      "batch time cost: 5.2863688468933105\n",
      "Epoch: 0, batch: 1195\n",
      "loss None\n",
      "batch time cost: 5.298591136932373\n",
      "Epoch: 0, batch: 1196\n",
      "loss None\n",
      "batch time cost: 6.226988077163696\n",
      "Epoch: 0, batch: 1197\n",
      "loss None\n",
      "batch time cost: 5.821313142776489\n",
      "Epoch: 0, batch: 1198\n",
      "loss None\n",
      "batch time cost: 5.237545013427734\n",
      "Epoch: 0, batch: 1199\n",
      "loss None\n",
      "batch time cost: 5.3465869426727295\n",
      "Epoch: 0, batch: 1200\n",
      "loss None\n",
      "batch time cost: 5.323336362838745\n",
      "Relu Train Epoch: 0 [76800/318582 (0%)]\tLoss: 0.915015\n",
      "Epoch: 0, batch: 1201\n",
      "loss None\n",
      "batch time cost: 5.274914026260376\n",
      "Epoch: 0, batch: 1202\n",
      "loss None\n",
      "batch time cost: 5.279124975204468\n",
      "Epoch: 0, batch: 1203\n",
      "loss None\n",
      "batch time cost: 5.625789165496826\n",
      "Epoch: 0, batch: 1204\n",
      "loss None\n",
      "batch time cost: 5.277456760406494\n",
      "Epoch: 0, batch: 1205\n",
      "loss None\n",
      "batch time cost: 5.370029926300049\n",
      "Epoch: 0, batch: 1206\n",
      "loss None\n",
      "batch time cost: 5.325316905975342\n",
      "Epoch: 0, batch: 1207\n",
      "loss None\n",
      "batch time cost: 5.3084681034088135\n",
      "Epoch: 0, batch: 1208\n",
      "loss None\n",
      "batch time cost: 5.233994960784912\n",
      "Epoch: 0, batch: 1209\n",
      "loss None\n",
      "batch time cost: 5.259204864501953\n",
      "Epoch: 0, batch: 1210\n",
      "loss None\n",
      "batch time cost: 6.379992961883545\n",
      "Relu Train Epoch: 0 [77440/318582 (0%)]\tLoss: 0.795778\n",
      "Epoch: 0, batch: 1211\n",
      "loss None\n",
      "batch time cost: 5.301711082458496\n",
      "Epoch: 0, batch: 1212\n",
      "loss None\n",
      "batch time cost: 5.289546966552734\n",
      "Epoch: 0, batch: 1213\n",
      "loss None\n",
      "batch time cost: 5.2214272022247314\n",
      "Epoch: 0, batch: 1214\n",
      "loss None\n",
      "batch time cost: 5.233868837356567\n",
      "Epoch: 0, batch: 1215\n",
      "loss None\n",
      "batch time cost: 5.2637939453125\n",
      "Epoch: 0, batch: 1216\n",
      "loss None\n",
      "batch time cost: 5.297325134277344\n",
      "Epoch: 0, batch: 1217\n",
      "loss None\n",
      "batch time cost: 5.295686960220337\n",
      "Epoch: 0, batch: 1218\n",
      "loss None\n",
      "batch time cost: 6.921281099319458\n",
      "Epoch: 0, batch: 1219\n",
      "loss None\n",
      "batch time cost: 6.171241044998169\n",
      "Epoch: 0, batch: 1220\n",
      "loss None\n",
      "batch time cost: 5.299050807952881\n",
      "Relu Train Epoch: 0 [78080/318582 (0%)]\tLoss: 0.824142\n",
      "Epoch: 0, batch: 1221\n",
      "loss None\n",
      "batch time cost: 5.256260871887207\n",
      "Epoch: 0, batch: 1222\n",
      "loss None\n",
      "batch time cost: 5.213807106018066\n",
      "Epoch: 0, batch: 1223\n",
      "loss None\n",
      "batch time cost: 5.279859781265259\n",
      "Epoch: 0, batch: 1224\n",
      "loss None\n",
      "batch time cost: 5.2369630336761475\n",
      "Epoch: 0, batch: 1225\n",
      "loss None\n",
      "batch time cost: 5.731871128082275\n",
      "Epoch: 0, batch: 1226\n",
      "loss None\n",
      "batch time cost: 6.198522090911865\n",
      "Epoch: 0, batch: 1227\n",
      "loss None\n",
      "batch time cost: 5.339863061904907\n",
      "Epoch: 0, batch: 1228\n",
      "loss None\n",
      "batch time cost: 5.28096079826355\n",
      "Epoch: 0, batch: 1229\n",
      "loss None\n",
      "batch time cost: 5.277907848358154\n",
      "Epoch: 0, batch: 1230\n",
      "loss None\n",
      "batch time cost: 5.320262908935547\n",
      "Relu Train Epoch: 0 [78720/318582 (0%)]\tLoss: 0.753062\n",
      "Epoch: 0, batch: 1231\n",
      "loss None\n",
      "batch time cost: 5.281278848648071\n",
      "Epoch: 0, batch: 1232\n",
      "loss None\n",
      "batch time cost: 5.761457204818726\n",
      "Epoch: 0, batch: 1233\n",
      "loss None\n",
      "batch time cost: 5.5492799282073975\n",
      "Epoch: 0, batch: 1234\n",
      "loss None\n",
      "batch time cost: 5.438791036605835\n",
      "Epoch: 0, batch: 1235\n",
      "loss None\n",
      "batch time cost: 5.364311218261719\n",
      "Epoch: 0, batch: 1236\n",
      "loss None\n",
      "batch time cost: 5.272295951843262\n",
      "Epoch: 0, batch: 1237\n",
      "loss None\n",
      "batch time cost: 5.282541751861572\n",
      "Epoch: 0, batch: 1238\n",
      "loss None\n",
      "batch time cost: 5.259996175765991\n",
      "Epoch: 0, batch: 1239\n",
      "loss None\n",
      "batch time cost: 6.3987061977386475\n",
      "Epoch: 0, batch: 1240\n",
      "loss None\n",
      "batch time cost: 5.324296951293945\n",
      "Relu Train Epoch: 0 [79360/318582 (0%)]\tLoss: 0.916125\n",
      "Epoch: 0, batch: 1241\n",
      "loss None\n",
      "batch time cost: 5.344772815704346\n",
      "Epoch: 0, batch: 1242\n",
      "loss None\n",
      "batch time cost: 5.3171610832214355\n",
      "Epoch: 0, batch: 1243\n",
      "loss None\n",
      "batch time cost: 5.266370058059692\n",
      "Epoch: 0, batch: 1244\n",
      "loss None\n",
      "batch time cost: 5.318038702011108\n",
      "Epoch: 0, batch: 1245\n",
      "loss None\n",
      "batch time cost: 5.291879177093506\n",
      "Epoch: 0, batch: 1246\n",
      "loss None\n",
      "batch time cost: 5.585818767547607\n",
      "Epoch: 0, batch: 1247\n",
      "loss None\n",
      "batch time cost: 5.3287999629974365\n",
      "Epoch: 0, batch: 1248\n",
      "loss None\n",
      "batch time cost: 5.299075126647949\n",
      "Epoch: 0, batch: 1249\n",
      "loss None\n",
      "batch time cost: 5.28287410736084\n",
      "Epoch: 0, batch: 1250\n",
      "loss None\n",
      "batch time cost: 5.306718826293945\n",
      "Relu Train Epoch: 0 [80000/318582 (0%)]\tLoss: 0.830978\n",
      "Epoch: 0, batch: 1251\n",
      "loss None\n",
      "batch time cost: 5.3269970417022705\n",
      "Epoch: 0, batch: 1252\n",
      "loss None\n",
      "batch time cost: 5.289765119552612\n",
      "Epoch: 0, batch: 1253\n",
      "loss None\n",
      "batch time cost: 5.337263107299805\n",
      "Epoch: 0, batch: 1254\n",
      "loss None\n",
      "batch time cost: 6.964834213256836\n",
      "Epoch: 0, batch: 1255\n",
      "loss None\n",
      "batch time cost: 5.8711371421813965\n",
      "Epoch: 0, batch: 1256\n",
      "loss None\n",
      "batch time cost: 7.922447681427002\n",
      "Epoch: 0, batch: 1257\n",
      "loss None\n",
      "batch time cost: 5.3377931118011475\n",
      "Epoch: 0, batch: 1258\n",
      "loss None\n",
      "batch time cost: 5.3686559200286865\n",
      "Epoch: 0, batch: 1259\n",
      "loss None\n",
      "batch time cost: 5.316062927246094\n",
      "Epoch: 0, batch: 1260\n",
      "loss None\n",
      "batch time cost: 5.2817747592926025\n",
      "Relu Train Epoch: 0 [80640/318582 (0%)]\tLoss: 0.846536\n",
      "Epoch: 0, batch: 1261\n",
      "loss None\n",
      "batch time cost: 6.213932991027832\n",
      "Epoch: 0, batch: 1262\n",
      "loss None\n",
      "batch time cost: 6.816622018814087\n",
      "Epoch: 0, batch: 1263\n",
      "loss None\n",
      "batch time cost: 5.837926149368286\n",
      "Epoch: 0, batch: 1264\n",
      "loss None\n",
      "batch time cost: 5.28272271156311\n",
      "Epoch: 0, batch: 1265\n",
      "loss None\n",
      "batch time cost: 5.246267080307007\n",
      "Epoch: 0, batch: 1266\n",
      "loss None\n",
      "batch time cost: 5.276134967803955\n",
      "Epoch: 0, batch: 1267\n",
      "loss None\n",
      "batch time cost: 5.257893085479736\n",
      "Epoch: 0, batch: 1268\n",
      "loss None\n",
      "batch time cost: 5.710235834121704\n",
      "Epoch: 0, batch: 1269\n",
      "loss None\n",
      "batch time cost: 5.376639127731323\n",
      "Epoch: 0, batch: 1270\n",
      "loss None\n",
      "batch time cost: 5.755345106124878\n",
      "Relu Train Epoch: 0 [81280/318582 (0%)]\tLoss: 0.813145\n",
      "Epoch: 0, batch: 1271\n",
      "loss None\n",
      "batch time cost: 5.948675870895386\n",
      "Epoch: 0, batch: 1272\n",
      "loss None\n",
      "batch time cost: 5.310910224914551\n",
      "Epoch: 0, batch: 1273\n",
      "loss None\n",
      "batch time cost: 5.252054929733276\n",
      "Epoch: 0, batch: 1274\n",
      "loss None\n",
      "batch time cost: 5.27847695350647\n",
      "Epoch: 0, batch: 1275\n",
      "loss None\n",
      "batch time cost: 5.647719144821167\n",
      "Epoch: 0, batch: 1276\n",
      "loss None\n",
      "batch time cost: 5.431383848190308\n",
      "Epoch: 0, batch: 1277\n",
      "loss None\n",
      "batch time cost: 5.305903196334839\n",
      "Epoch: 0, batch: 1278\n",
      "loss None\n",
      "batch time cost: 5.328600645065308\n",
      "Epoch: 0, batch: 1279\n",
      "loss None\n",
      "batch time cost: 5.253005743026733\n",
      "Epoch: 0, batch: 1280\n",
      "loss None\n",
      "batch time cost: 5.328256845474243\n",
      "Relu Train Epoch: 0 [81920/318582 (0%)]\tLoss: 0.779403\n",
      "Epoch: 0, batch: 1281\n",
      "loss None\n",
      "batch time cost: 5.231599807739258\n",
      "Epoch: 0, batch: 1282\n",
      "loss None\n",
      "batch time cost: 5.335798978805542\n",
      "Epoch: 0, batch: 1283\n",
      "loss None\n",
      "batch time cost: 7.10110068321228\n",
      "Epoch: 0, batch: 1284\n",
      "loss None\n",
      "batch time cost: 6.686707258224487\n",
      "Epoch: 0, batch: 1285\n",
      "loss None\n",
      "batch time cost: 6.103985786437988\n",
      "Epoch: 0, batch: 1286\n",
      "loss None\n",
      "batch time cost: 5.53144907951355\n",
      "Epoch: 0, batch: 1287\n",
      "loss None\n",
      "batch time cost: 5.322373151779175\n",
      "Epoch: 0, batch: 1288\n",
      "loss None\n",
      "batch time cost: 5.308158874511719\n",
      "Epoch: 0, batch: 1289\n",
      "loss None\n",
      "batch time cost: 5.255490064620972\n",
      "Epoch: 0, batch: 1290\n",
      "loss None\n",
      "batch time cost: 6.421268939971924\n",
      "Relu Train Epoch: 0 [82560/318582 (0%)]\tLoss: 1.026992\n",
      "Epoch: 0, batch: 1291\n",
      "loss None\n",
      "batch time cost: 6.228884935379028\n",
      "Epoch: 0, batch: 1292\n",
      "loss None\n",
      "batch time cost: 6.710766792297363\n",
      "Epoch: 0, batch: 1293\n",
      "loss None\n",
      "batch time cost: 5.3346312046051025\n",
      "Epoch: 0, batch: 1294\n",
      "loss None\n",
      "batch time cost: 5.279262065887451\n",
      "Epoch: 0, batch: 1295\n",
      "loss None\n",
      "batch time cost: 5.25300407409668\n",
      "Epoch: 0, batch: 1296\n",
      "loss None\n",
      "batch time cost: 5.294856071472168\n",
      "Epoch: 0, batch: 1297\n",
      "loss None\n",
      "batch time cost: 7.483232021331787\n",
      "Epoch: 0, batch: 1298\n",
      "loss None\n",
      "batch time cost: 5.876559019088745\n",
      "Epoch: 0, batch: 1299\n",
      "loss None\n",
      "batch time cost: 7.273457765579224\n",
      "Epoch: 0, batch: 1300\n",
      "loss None\n",
      "batch time cost: 6.16858172416687\n",
      "Relu Train Epoch: 0 [83200/318582 (0%)]\tLoss: 0.950938\n",
      "Epoch: 0, batch: 1301\n",
      "loss None\n",
      "batch time cost: 5.3176069259643555\n",
      "Epoch: 0, batch: 1302\n",
      "loss None\n",
      "batch time cost: 5.3055830001831055\n",
      "Epoch: 0, batch: 1303\n",
      "loss None\n",
      "batch time cost: 5.305002927780151\n",
      "Epoch: 0, batch: 1304\n",
      "loss None\n",
      "batch time cost: 5.839386224746704\n",
      "Epoch: 0, batch: 1305\n",
      "loss None\n",
      "batch time cost: 5.305025577545166\n",
      "Epoch: 0, batch: 1306\n",
      "loss None\n",
      "batch time cost: 5.29226016998291\n",
      "Epoch: 0, batch: 1307\n",
      "loss None\n",
      "batch time cost: 5.273296117782593\n",
      "Epoch: 0, batch: 1308\n",
      "loss None\n",
      "batch time cost: 5.248455286026001\n",
      "Epoch: 0, batch: 1309\n",
      "loss None\n",
      "batch time cost: 5.247745990753174\n",
      "Epoch: 0, batch: 1310\n",
      "loss None\n",
      "batch time cost: 5.311105966567993\n",
      "Relu Train Epoch: 0 [83840/318582 (0%)]\tLoss: 0.979585\n",
      "Epoch: 0, batch: 1311\n",
      "loss None\n",
      "batch time cost: 5.622152805328369\n",
      "Epoch: 0, batch: 1312\n",
      "loss None\n",
      "batch time cost: 5.431481838226318\n",
      "Epoch: 0, batch: 1313\n",
      "loss None\n",
      "batch time cost: 5.5856242179870605\n",
      "Epoch: 0, batch: 1314\n",
      "loss None\n",
      "batch time cost: 5.888131856918335\n",
      "Epoch: 0, batch: 1315\n",
      "loss None\n",
      "batch time cost: 6.038619041442871\n",
      "Epoch: 0, batch: 1316\n",
      "loss None\n",
      "batch time cost: 5.3920252323150635\n",
      "Epoch: 0, batch: 1317\n",
      "loss None\n",
      "batch time cost: 5.335579872131348\n",
      "Epoch: 0, batch: 1318\n",
      "loss None\n",
      "batch time cost: 5.304717063903809\n",
      "Epoch: 0, batch: 1319\n",
      "loss None\n",
      "batch time cost: 5.706193923950195\n",
      "Epoch: 0, batch: 1320\n",
      "loss None\n",
      "batch time cost: 5.298774003982544\n",
      "Relu Train Epoch: 0 [84480/318582 (0%)]\tLoss: 0.851074\n",
      "Epoch: 0, batch: 1321\n",
      "loss None\n",
      "batch time cost: 5.287055730819702\n",
      "Epoch: 0, batch: 1322\n",
      "loss None\n",
      "batch time cost: 5.242794036865234\n",
      "Epoch: 0, batch: 1323\n",
      "loss None\n",
      "batch time cost: 5.281513214111328\n",
      "Epoch: 0, batch: 1324\n",
      "loss None\n",
      "batch time cost: 5.295037031173706\n",
      "Epoch: 0, batch: 1325\n",
      "loss None\n",
      "batch time cost: 5.214456081390381\n",
      "Epoch: 0, batch: 1326\n",
      "loss None\n",
      "batch time cost: 5.718385934829712\n",
      "Epoch: 0, batch: 1327\n",
      "loss None\n",
      "batch time cost: 5.356389999389648\n",
      "Epoch: 0, batch: 1328\n",
      "loss None\n",
      "batch time cost: 5.348818063735962\n",
      "Epoch: 0, batch: 1329\n",
      "loss None\n",
      "batch time cost: 5.372222900390625\n",
      "Epoch: 0, batch: 1330\n",
      "loss None\n",
      "batch time cost: 5.328705072402954\n",
      "Relu Train Epoch: 0 [85120/318582 (0%)]\tLoss: 0.964156\n",
      "Epoch: 0, batch: 1331\n",
      "loss None\n",
      "batch time cost: 5.361264228820801\n",
      "Epoch: 0, batch: 1332\n",
      "loss None\n",
      "batch time cost: 5.313652992248535\n",
      "Epoch: 0, batch: 1333\n",
      "loss None\n",
      "batch time cost: 5.747478008270264\n",
      "Epoch: 0, batch: 1334\n",
      "loss None\n",
      "batch time cost: 5.896635055541992\n",
      "Epoch: 0, batch: 1335\n",
      "loss None\n",
      "batch time cost: 5.310715198516846\n",
      "Epoch: 0, batch: 1336\n",
      "loss None\n",
      "batch time cost: 5.2850661277771\n",
      "Epoch: 0, batch: 1337\n",
      "loss None\n",
      "batch time cost: 5.2556798458099365\n",
      "Epoch: 0, batch: 1338\n",
      "loss None\n",
      "batch time cost: 5.265496015548706\n",
      "Epoch: 0, batch: 1339\n",
      "loss None\n",
      "batch time cost: 5.305306911468506\n",
      "Epoch: 0, batch: 1340\n",
      "loss None\n",
      "batch time cost: 6.4502949714660645\n",
      "Relu Train Epoch: 0 [85760/318582 (0%)]\tLoss: 0.949306\n",
      "Epoch: 0, batch: 1341\n",
      "loss None\n",
      "batch time cost: 5.986314058303833\n",
      "Epoch: 0, batch: 1342\n",
      "loss None\n",
      "batch time cost: 5.691521644592285\n",
      "Epoch: 0, batch: 1343\n",
      "loss None\n",
      "batch time cost: 5.552306890487671\n",
      "Epoch: 0, batch: 1344\n",
      "loss None\n",
      "batch time cost: 5.709884166717529\n",
      "Epoch: 0, batch: 1345\n",
      "loss None\n",
      "batch time cost: 5.311337947845459\n",
      "Epoch: 0, batch: 1346\n",
      "loss None\n",
      "batch time cost: 5.328537940979004\n",
      "Epoch: 0, batch: 1347\n",
      "loss None\n",
      "batch time cost: 5.28424072265625\n",
      "Epoch: 0, batch: 1348\n",
      "loss None\n",
      "batch time cost: 6.983863115310669\n",
      "Epoch: 0, batch: 1349\n",
      "loss None\n",
      "batch time cost: 5.346102952957153\n",
      "Epoch: 0, batch: 1350\n",
      "loss None\n",
      "batch time cost: 5.258124113082886\n",
      "Relu Train Epoch: 0 [86400/318582 (0%)]\tLoss: 0.956954\n",
      "Epoch: 0, batch: 1351\n",
      "loss None\n",
      "batch time cost: 5.2560389041900635\n",
      "Epoch: 0, batch: 1352\n",
      "loss None\n",
      "batch time cost: 5.24015998840332\n",
      "Epoch: 0, batch: 1353\n",
      "loss None\n",
      "batch time cost: 5.250298976898193\n",
      "Epoch: 0, batch: 1354\n",
      "loss None\n",
      "batch time cost: 5.318300247192383\n",
      "Epoch: 0, batch: 1355\n",
      "loss None\n",
      "batch time cost: 6.155197858810425\n",
      "Epoch: 0, batch: 1356\n",
      "loss None\n",
      "batch time cost: 5.395936012268066\n",
      "Epoch: 0, batch: 1357\n",
      "loss None\n",
      "batch time cost: 6.725844860076904\n",
      "Epoch: 0, batch: 1358\n",
      "loss None\n",
      "batch time cost: 6.31554102897644\n",
      "Epoch: 0, batch: 1359\n",
      "loss None\n",
      "batch time cost: 6.031808137893677\n",
      "Epoch: 0, batch: 1360\n",
      "loss None\n",
      "batch time cost: 5.6604859828948975\n",
      "Relu Train Epoch: 0 [87040/318582 (0%)]\tLoss: 0.883019\n",
      "Epoch: 0, batch: 1361\n",
      "loss None\n",
      "batch time cost: 5.373328924179077\n",
      "Epoch: 0, batch: 1362\n",
      "loss None\n",
      "batch time cost: 5.659362077713013\n",
      "Epoch: 0, batch: 1363\n",
      "loss None\n",
      "batch time cost: 5.302172899246216\n",
      "Epoch: 0, batch: 1364\n",
      "loss None\n",
      "batch time cost: 5.277491807937622\n",
      "Epoch: 0, batch: 1365\n",
      "loss None\n",
      "batch time cost: 5.326745986938477\n",
      "Epoch: 0, batch: 1366\n",
      "loss None\n",
      "batch time cost: 5.302491188049316\n",
      "Epoch: 0, batch: 1367\n",
      "loss None\n",
      "batch time cost: 5.293774843215942\n",
      "Epoch: 0, batch: 1368\n",
      "loss None\n",
      "batch time cost: 5.311046123504639\n",
      "Epoch: 0, batch: 1369\n",
      "loss None\n",
      "batch time cost: 6.238538026809692\n",
      "Epoch: 0, batch: 1370\n",
      "loss None\n",
      "batch time cost: 5.500493049621582\n",
      "Relu Train Epoch: 0 [87680/318582 (0%)]\tLoss: 1.120555\n",
      "Epoch: 0, batch: 1371\n",
      "loss None\n",
      "batch time cost: 6.788862943649292\n",
      "Epoch: 0, batch: 1372\n",
      "loss None\n",
      "batch time cost: 6.1228227615356445\n",
      "Epoch: 0, batch: 1373\n",
      "loss None\n",
      "batch time cost: 5.920116901397705\n",
      "Epoch: 0, batch: 1374\n",
      "loss None\n",
      "batch time cost: 5.491830110549927\n",
      "Epoch: 0, batch: 1375\n",
      "loss None\n",
      "batch time cost: 5.395506143569946\n",
      "Epoch: 0, batch: 1376\n",
      "loss None\n",
      "batch time cost: 5.721343994140625\n",
      "Epoch: 0, batch: 1377\n",
      "loss None\n",
      "batch time cost: 5.375266075134277\n",
      "Epoch: 0, batch: 1378\n",
      "loss None\n",
      "batch time cost: 5.345246076583862\n",
      "Epoch: 0, batch: 1379\n",
      "loss None\n",
      "batch time cost: 5.273015022277832\n",
      "Epoch: 0, batch: 1380\n",
      "loss None\n",
      "batch time cost: 5.27221417427063\n",
      "Relu Train Epoch: 0 [88320/318582 (0%)]\tLoss: 1.270692\n",
      "Epoch: 0, batch: 1381\n",
      "loss None\n",
      "batch time cost: 5.29787015914917\n",
      "Epoch: 0, batch: 1382\n",
      "loss None\n",
      "batch time cost: 5.27905797958374\n",
      "Epoch: 0, batch: 1383\n",
      "loss None\n",
      "batch time cost: 5.276409864425659\n",
      "Epoch: 0, batch: 1384\n",
      "loss None\n",
      "batch time cost: 8.097208023071289\n",
      "Epoch: 0, batch: 1385\n",
      "loss None\n",
      "batch time cost: 7.945098876953125\n",
      "Epoch: 0, batch: 1386\n",
      "loss None\n",
      "batch time cost: 7.54925537109375\n",
      "Epoch: 0, batch: 1387\n",
      "loss None\n",
      "batch time cost: 7.937264919281006\n",
      "Epoch: 0, batch: 1388\n",
      "loss None\n",
      "batch time cost: 6.843523979187012\n",
      "Epoch: 0, batch: 1389\n",
      "loss None\n",
      "batch time cost: 5.293379306793213\n",
      "Epoch: 0, batch: 1390\n",
      "loss None\n",
      "batch time cost: 5.2654500007629395\n",
      "Relu Train Epoch: 0 [88960/318582 (0%)]\tLoss: 0.950893\n",
      "Epoch: 0, batch: 1391\n",
      "loss None\n",
      "batch time cost: 5.625582933425903\n",
      "Epoch: 0, batch: 1392\n",
      "loss None\n",
      "batch time cost: 5.292341947555542\n",
      "Epoch: 0, batch: 1393\n",
      "loss None\n",
      "batch time cost: 5.305216073989868\n",
      "Epoch: 0, batch: 1394\n",
      "loss None\n",
      "batch time cost: 5.317847013473511\n",
      "Epoch: 0, batch: 1395\n",
      "loss None\n",
      "batch time cost: 5.2610697746276855\n",
      "Epoch: 0, batch: 1396\n",
      "loss None\n",
      "batch time cost: 5.261652946472168\n",
      "Epoch: 0, batch: 1397\n",
      "loss None\n",
      "batch time cost: 5.21464204788208\n",
      "Epoch: 0, batch: 1398\n",
      "loss None\n",
      "batch time cost: 6.347964763641357\n",
      "Epoch: 0, batch: 1399\n",
      "loss None\n",
      "batch time cost: 6.3075032234191895\n",
      "Epoch: 0, batch: 1400\n",
      "loss None\n",
      "batch time cost: 6.715263843536377\n",
      "Relu Train Epoch: 0 [89600/318582 (0%)]\tLoss: 0.881980\n",
      "Epoch: 0, batch: 1401\n",
      "loss None\n",
      "batch time cost: 7.094449758529663\n",
      "Epoch: 0, batch: 1402\n",
      "loss None\n",
      "batch time cost: 6.669092178344727\n",
      "Epoch: 0, batch: 1403\n",
      "loss None\n",
      "batch time cost: 5.9843668937683105\n",
      "Epoch: 0, batch: 1404\n",
      "loss None\n",
      "batch time cost: 5.349648714065552\n",
      "Epoch: 0, batch: 1405\n",
      "loss None\n",
      "batch time cost: 5.640538215637207\n",
      "Epoch: 0, batch: 1406\n",
      "loss None\n",
      "batch time cost: 5.244285821914673\n",
      "Epoch: 0, batch: 1407\n",
      "loss None\n",
      "batch time cost: 5.259159088134766\n",
      "Epoch: 0, batch: 1408\n",
      "loss None\n",
      "batch time cost: 5.283203840255737\n",
      "Epoch: 0, batch: 1409\n",
      "loss None\n",
      "batch time cost: 5.254244804382324\n",
      "Epoch: 0, batch: 1410\n",
      "loss None\n",
      "batch time cost: 5.253530979156494\n",
      "Relu Train Epoch: 0 [90240/318582 (0%)]\tLoss: 0.812562\n",
      "Epoch: 0, batch: 1411\n",
      "loss None\n",
      "batch time cost: 5.300774097442627\n",
      "Epoch: 0, batch: 1412\n",
      "loss None\n",
      "batch time cost: 5.302716970443726\n",
      "Epoch: 0, batch: 1413\n",
      "loss None\n",
      "batch time cost: 5.880531072616577\n",
      "Epoch: 0, batch: 1414\n",
      "loss None\n",
      "batch time cost: 5.31413197517395\n",
      "Epoch: 0, batch: 1415\n",
      "loss None\n",
      "batch time cost: 5.260538101196289\n",
      "Epoch: 0, batch: 1416\n",
      "loss None\n",
      "batch time cost: 5.281524896621704\n",
      "Epoch: 0, batch: 1417\n",
      "loss None\n",
      "batch time cost: 5.243896722793579\n",
      "Epoch: 0, batch: 1418\n",
      "loss None\n",
      "batch time cost: 5.254037857055664\n",
      "Epoch: 0, batch: 1419\n",
      "loss None\n",
      "batch time cost: 5.242133855819702\n",
      "Epoch: 0, batch: 1420\n",
      "loss None\n",
      "batch time cost: 6.208437919616699\n",
      "Relu Train Epoch: 0 [90880/318582 (0%)]\tLoss: 0.913223\n",
      "Epoch: 0, batch: 1421\n",
      "loss None\n",
      "batch time cost: 5.689355134963989\n",
      "Epoch: 0, batch: 1422\n",
      "loss None\n",
      "batch time cost: 6.581498146057129\n",
      "Epoch: 0, batch: 1423\n",
      "loss None\n",
      "batch time cost: 6.776057958602905\n",
      "Epoch: 0, batch: 1424\n",
      "loss None\n",
      "batch time cost: 6.089967966079712\n",
      "Epoch: 0, batch: 1425\n",
      "loss None\n",
      "batch time cost: 6.100942134857178\n",
      "Epoch: 0, batch: 1426\n",
      "loss None\n",
      "batch time cost: 5.383167028427124\n",
      "Epoch: 0, batch: 1427\n",
      "loss None\n",
      "batch time cost: 5.668062210083008\n",
      "Epoch: 0, batch: 1428\n",
      "loss None\n",
      "batch time cost: 5.315479040145874\n",
      "Epoch: 0, batch: 1429\n",
      "loss None\n",
      "batch time cost: 5.32266902923584\n",
      "Epoch: 0, batch: 1430\n",
      "loss None\n",
      "batch time cost: 5.305052995681763\n",
      "Relu Train Epoch: 0 [91520/318582 (0%)]\tLoss: 0.640062\n",
      "Epoch: 0, batch: 1431\n",
      "loss None\n",
      "batch time cost: 5.275197267532349\n",
      "Epoch: 0, batch: 1432\n",
      "loss None\n",
      "batch time cost: 5.238270998001099\n",
      "Epoch: 0, batch: 1433\n",
      "loss None\n",
      "batch time cost: 5.260375022888184\n",
      "Epoch: 0, batch: 1434\n",
      "loss None\n",
      "batch time cost: 6.103303909301758\n",
      "Epoch: 0, batch: 1435\n",
      "loss None\n",
      "batch time cost: 5.475935935974121\n",
      "Epoch: 0, batch: 1436\n",
      "loss None\n",
      "batch time cost: 5.4361889362335205\n",
      "Epoch: 0, batch: 1437\n",
      "loss None\n",
      "batch time cost: 5.680761814117432\n",
      "Epoch: 0, batch: 1438\n",
      "loss None\n",
      "batch time cost: 5.769795179367065\n",
      "Epoch: 0, batch: 1439\n",
      "loss None\n",
      "batch time cost: 6.730902910232544\n",
      "Epoch: 0, batch: 1440\n",
      "loss None\n",
      "batch time cost: 5.352771997451782\n",
      "Relu Train Epoch: 0 [92160/318582 (0%)]\tLoss: 0.937170\n",
      "Epoch: 0, batch: 1441\n",
      "loss None\n",
      "batch time cost: 5.634544134140015\n",
      "Epoch: 0, batch: 1442\n",
      "loss None\n",
      "batch time cost: 5.289363861083984\n",
      "Epoch: 0, batch: 1443\n",
      "loss None\n",
      "batch time cost: 5.2639830112457275\n",
      "Epoch: 0, batch: 1444\n",
      "loss None\n",
      "batch time cost: 5.332718133926392\n",
      "Epoch: 0, batch: 1445\n",
      "loss None\n",
      "batch time cost: 5.2746500968933105\n",
      "Epoch: 0, batch: 1446\n",
      "loss None\n",
      "batch time cost: 5.298616886138916\n",
      "Epoch: 0, batch: 1447\n",
      "loss None\n",
      "batch time cost: 5.261223077774048\n",
      "Epoch: 0, batch: 1448\n",
      "loss None\n",
      "batch time cost: 5.477550745010376\n",
      "Epoch: 0, batch: 1449\n",
      "loss None\n",
      "batch time cost: 7.335879802703857\n",
      "Epoch: 0, batch: 1450\n",
      "loss None\n",
      "batch time cost: 7.623795032501221\n",
      "Relu Train Epoch: 0 [92800/318582 (0%)]\tLoss: 1.019764\n",
      "Epoch: 0, batch: 1451\n",
      "loss None\n",
      "batch time cost: 8.420335292816162\n",
      "Epoch: 0, batch: 1452\n",
      "loss None\n",
      "batch time cost: 8.792731046676636\n",
      "Epoch: 0, batch: 1453\n",
      "loss None\n",
      "batch time cost: 8.564094066619873\n",
      "Epoch: 0, batch: 1454\n",
      "loss None\n",
      "batch time cost: 6.0541980266571045\n",
      "Epoch: 0, batch: 1455\n",
      "loss None\n",
      "batch time cost: 5.302515983581543\n",
      "Epoch: 0, batch: 1456\n",
      "loss None\n",
      "batch time cost: 8.508120059967041\n",
      "Epoch: 0, batch: 1457\n",
      "loss None\n",
      "batch time cost: 8.755928039550781\n",
      "Epoch: 0, batch: 1458\n",
      "loss None\n",
      "batch time cost: 7.785279035568237\n",
      "Epoch: 0, batch: 1459\n",
      "loss None\n",
      "batch time cost: 6.60625696182251\n",
      "Epoch: 0, batch: 1460\n",
      "loss None\n",
      "batch time cost: 5.944134950637817\n",
      "Relu Train Epoch: 0 [93440/318582 (0%)]\tLoss: 0.687511\n",
      "Epoch: 0, batch: 1461\n",
      "loss None\n",
      "batch time cost: 5.4325480461120605\n",
      "Epoch: 0, batch: 1462\n",
      "loss None\n",
      "batch time cost: 5.322926044464111\n",
      "Epoch: 0, batch: 1463\n",
      "loss None\n",
      "batch time cost: 5.573371887207031\n",
      "Epoch: 0, batch: 1464\n",
      "loss None\n",
      "batch time cost: 5.3059656620025635\n",
      "Epoch: 0, batch: 1465\n",
      "loss None\n",
      "batch time cost: 5.287063121795654\n",
      "Epoch: 0, batch: 1466\n",
      "loss None\n",
      "batch time cost: 5.3354268074035645\n",
      "Epoch: 0, batch: 1467\n",
      "loss None\n",
      "batch time cost: 5.274965763092041\n",
      "Epoch: 0, batch: 1468\n",
      "loss None\n",
      "batch time cost: 5.335072994232178\n",
      "Epoch: 0, batch: 1469\n",
      "loss None\n",
      "batch time cost: 5.293085098266602\n",
      "Epoch: 0, batch: 1470\n",
      "loss None\n",
      "batch time cost: 7.5551371574401855\n",
      "Relu Train Epoch: 0 [94080/318582 (0%)]\tLoss: 0.931143\n",
      "Epoch: 0, batch: 1471\n",
      "loss None\n",
      "batch time cost: 6.2900590896606445\n",
      "Epoch: 0, batch: 1472\n",
      "loss None\n",
      "batch time cost: 5.496933937072754\n",
      "Epoch: 0, batch: 1473\n",
      "loss None\n",
      "batch time cost: 5.332578182220459\n",
      "Epoch: 0, batch: 1474\n",
      "loss None\n",
      "batch time cost: 5.266650676727295\n",
      "Epoch: 0, batch: 1475\n",
      "loss None\n",
      "batch time cost: 5.366687059402466\n",
      "Epoch: 0, batch: 1476\n",
      "loss None\n",
      "batch time cost: 5.264607906341553\n",
      "Epoch: 0, batch: 1477\n",
      "loss None\n",
      "batch time cost: 5.413075923919678\n",
      "Epoch: 0, batch: 1478\n",
      "loss None\n",
      "batch time cost: 5.904167890548706\n",
      "Epoch: 0, batch: 1479\n",
      "loss None\n",
      "batch time cost: 5.400259971618652\n",
      "Epoch: 0, batch: 1480\n",
      "loss None\n",
      "batch time cost: 5.3151631355285645\n",
      "Relu Train Epoch: 0 [94720/318582 (0%)]\tLoss: 1.007518\n",
      "Epoch: 0, batch: 1481\n",
      "loss None\n",
      "batch time cost: 5.29344367980957\n",
      "Epoch: 0, batch: 1482\n",
      "loss None\n",
      "batch time cost: 5.192072868347168\n",
      "Epoch: 0, batch: 1483\n",
      "loss None\n",
      "batch time cost: 5.297317028045654\n",
      "Epoch: 0, batch: 1484\n",
      "loss None\n",
      "batch time cost: 5.330030202865601\n",
      "Epoch: 0, batch: 1485\n",
      "loss None\n",
      "batch time cost: 8.11153793334961\n",
      "Epoch: 0, batch: 1486\n",
      "loss None\n",
      "batch time cost: 7.9117350578308105\n",
      "Epoch: 0, batch: 1487\n",
      "loss None\n",
      "batch time cost: 7.706376791000366\n",
      "Epoch: 0, batch: 1488\n",
      "loss None\n",
      "batch time cost: 7.460204124450684\n",
      "Epoch: 0, batch: 1489\n",
      "loss None\n",
      "batch time cost: 7.980463743209839\n",
      "Epoch: 0, batch: 1490\n",
      "loss None\n",
      "batch time cost: 7.691540956497192\n",
      "Relu Train Epoch: 0 [95360/318582 (0%)]\tLoss: 0.598003\n",
      "Epoch: 0, batch: 1491\n",
      "loss None\n",
      "batch time cost: 5.6580657958984375\n",
      "Epoch: 0, batch: 1492\n",
      "loss None\n",
      "batch time cost: 5.593448162078857\n",
      "Epoch: 0, batch: 1493\n",
      "loss None\n",
      "batch time cost: 5.213028907775879\n",
      "Epoch: 0, batch: 1494\n",
      "loss None\n",
      "batch time cost: 5.303005933761597\n",
      "Epoch: 0, batch: 1495\n",
      "loss None\n",
      "batch time cost: 5.384163856506348\n",
      "Epoch: 0, batch: 1496\n",
      "loss None\n",
      "batch time cost: 5.292795896530151\n",
      "Epoch: 0, batch: 1497\n",
      "loss None\n",
      "batch time cost: 5.331821918487549\n",
      "Epoch: 0, batch: 1498\n",
      "loss None\n",
      "batch time cost: 5.2636189460754395\n",
      "Epoch: 0, batch: 1499\n",
      "loss None\n",
      "batch time cost: 6.0823540687561035\n",
      "Epoch: 0, batch: 1500\n",
      "loss None\n",
      "batch time cost: 7.3791680335998535\n",
      "Relu Train Epoch: 0 [96000/318582 (0%)]\tLoss: 0.879295\n",
      "Epoch: 0, batch: 1501\n",
      "loss None\n",
      "batch time cost: 5.929491996765137\n",
      "Epoch: 0, batch: 1502\n",
      "loss None\n",
      "batch time cost: 5.452956914901733\n",
      "Epoch: 0, batch: 1503\n",
      "loss None\n",
      "batch time cost: 5.285523891448975\n",
      "Epoch: 0, batch: 1504\n",
      "loss None\n",
      "batch time cost: 5.2465128898620605\n",
      "Epoch: 0, batch: 1505\n",
      "loss None\n",
      "batch time cost: 5.26997184753418\n",
      "Epoch: 0, batch: 1506\n",
      "loss None\n",
      "batch time cost: 5.668925046920776\n",
      "Epoch: 0, batch: 1507\n",
      "loss None\n",
      "batch time cost: 5.990355014801025\n",
      "Epoch: 0, batch: 1508\n",
      "loss None\n",
      "batch time cost: 5.39208197593689\n",
      "Epoch: 0, batch: 1509\n",
      "loss None\n",
      "batch time cost: 5.295058965682983\n",
      "Epoch: 0, batch: 1510\n",
      "loss None\n",
      "batch time cost: 5.312401056289673\n",
      "Relu Train Epoch: 0 [96640/318582 (0%)]\tLoss: 0.786939\n",
      "Epoch: 0, batch: 1511\n",
      "loss None\n",
      "batch time cost: 5.290287017822266\n",
      "Epoch: 0, batch: 1512\n",
      "loss None\n",
      "batch time cost: 5.351657152175903\n",
      "Epoch: 0, batch: 1513\n",
      "loss None\n",
      "batch time cost: 5.321789979934692\n",
      "Epoch: 0, batch: 1514\n",
      "loss None\n",
      "batch time cost: 5.669335842132568\n",
      "Epoch: 0, batch: 1515\n",
      "loss None\n",
      "batch time cost: 5.299612045288086\n",
      "Epoch: 0, batch: 1516\n",
      "loss None\n",
      "batch time cost: 5.205399990081787\n",
      "Epoch: 0, batch: 1517\n",
      "loss None\n",
      "batch time cost: 5.298671007156372\n",
      "Epoch: 0, batch: 1518\n",
      "loss None\n",
      "batch time cost: 5.209202766418457\n",
      "Epoch: 0, batch: 1519\n",
      "loss None\n",
      "batch time cost: 5.224419832229614\n",
      "Epoch: 0, batch: 1520\n",
      "loss None\n",
      "batch time cost: 5.2650110721588135\n",
      "Relu Train Epoch: 0 [97280/318582 (0%)]\tLoss: 0.749355\n",
      "Epoch: 0, batch: 1521\n",
      "loss None\n",
      "batch time cost: 5.718122959136963\n",
      "Epoch: 0, batch: 1522\n",
      "loss None\n",
      "batch time cost: 5.369729042053223\n",
      "Epoch: 0, batch: 1523\n",
      "loss None\n",
      "batch time cost: 5.408517122268677\n",
      "Epoch: 0, batch: 1524\n",
      "loss None\n",
      "batch time cost: 5.4997336864471436\n",
      "Epoch: 0, batch: 1525\n",
      "loss None\n",
      "batch time cost: 5.343725204467773\n",
      "Epoch: 0, batch: 1526\n",
      "loss None\n",
      "batch time cost: 5.337076902389526\n",
      "Epoch: 0, batch: 1527\n",
      "loss None\n",
      "batch time cost: 5.298899173736572\n",
      "Epoch: 0, batch: 1528\n",
      "loss None\n",
      "batch time cost: 5.531955003738403\n",
      "Epoch: 0, batch: 1529\n",
      "loss None\n",
      "batch time cost: 5.272662162780762\n",
      "Epoch: 0, batch: 1530\n",
      "loss None\n",
      "batch time cost: 5.296113967895508\n",
      "Relu Train Epoch: 0 [97920/318582 (0%)]\tLoss: 0.822571\n",
      "Epoch: 0, batch: 1531\n",
      "loss None\n",
      "batch time cost: 5.371258974075317\n",
      "Epoch: 0, batch: 1532\n",
      "loss None\n",
      "batch time cost: 5.482172966003418\n",
      "Epoch: 0, batch: 1533\n",
      "loss None\n",
      "batch time cost: 5.311160087585449\n",
      "Epoch: 0, batch: 1534\n",
      "loss None\n",
      "batch time cost: 5.278790712356567\n",
      "Epoch: 0, batch: 1535\n",
      "loss None\n",
      "batch time cost: 5.607160806655884\n",
      "Epoch: 0, batch: 1536\n",
      "loss None\n",
      "batch time cost: 5.335242986679077\n",
      "Epoch: 0, batch: 1537\n",
      "loss None\n",
      "batch time cost: 5.280578851699829\n",
      "Epoch: 0, batch: 1538\n",
      "loss None\n",
      "batch time cost: 5.308634281158447\n",
      "Epoch: 0, batch: 1539\n",
      "loss None\n",
      "batch time cost: 5.33673620223999\n",
      "Epoch: 0, batch: 1540\n",
      "loss None\n",
      "batch time cost: 5.280311822891235\n",
      "Relu Train Epoch: 0 [98560/318582 (0%)]\tLoss: 0.693410\n",
      "Epoch: 0, batch: 1541\n",
      "loss None\n",
      "batch time cost: 5.316157341003418\n",
      "Epoch: 0, batch: 1542\n",
      "loss None\n",
      "batch time cost: 5.358307123184204\n",
      "Epoch: 0, batch: 1543\n",
      "loss None\n",
      "batch time cost: 5.773622035980225\n",
      "Epoch: 0, batch: 1544\n",
      "loss None\n",
      "batch time cost: 5.343885660171509\n",
      "Epoch: 0, batch: 1545\n",
      "loss None\n",
      "batch time cost: 5.344220876693726\n",
      "Epoch: 0, batch: 1546\n",
      "loss None\n",
      "batch time cost: 5.29637885093689\n",
      "Epoch: 0, batch: 1547\n",
      "loss None\n",
      "batch time cost: 5.292052984237671\n",
      "Epoch: 0, batch: 1548\n",
      "loss None\n",
      "batch time cost: 5.276329040527344\n",
      "Epoch: 0, batch: 1549\n",
      "loss None\n",
      "batch time cost: 5.268762111663818\n",
      "Epoch: 0, batch: 1550\n",
      "loss None\n",
      "batch time cost: 5.579917669296265\n",
      "Relu Train Epoch: 0 [99200/318582 (0%)]\tLoss: 0.895690\n",
      "Epoch: 0, batch: 1551\n",
      "loss None\n",
      "batch time cost: 5.235395908355713\n",
      "Epoch: 0, batch: 1552\n",
      "loss None\n",
      "batch time cost: 5.226001262664795\n",
      "Epoch: 0, batch: 1553\n",
      "loss None\n",
      "batch time cost: 5.277524948120117\n",
      "Epoch: 0, batch: 1554\n",
      "loss None\n",
      "batch time cost: 5.313854932785034\n",
      "Epoch: 0, batch: 1555\n",
      "loss None\n",
      "batch time cost: 5.392606973648071\n",
      "Epoch: 0, batch: 1556\n",
      "loss None\n",
      "batch time cost: 5.320394992828369\n",
      "Epoch: 0, batch: 1557\n",
      "loss None\n",
      "batch time cost: 5.6913769245147705\n",
      "Epoch: 0, batch: 1558\n",
      "loss None\n",
      "batch time cost: 5.363004922866821\n",
      "Epoch: 0, batch: 1559\n",
      "loss None\n",
      "batch time cost: 5.277038097381592\n",
      "Epoch: 0, batch: 1560\n",
      "loss None\n",
      "batch time cost: 5.245159149169922\n",
      "Relu Train Epoch: 0 [99840/318582 (0%)]\tLoss: 1.053093\n",
      "Epoch: 0, batch: 1561\n",
      "loss None\n",
      "batch time cost: 5.2684550285339355\n",
      "Epoch: 0, batch: 1562\n",
      "loss None\n",
      "batch time cost: 5.290580987930298\n",
      "Epoch: 0, batch: 1563\n",
      "loss None\n",
      "batch time cost: 5.287736177444458\n",
      "Epoch: 0, batch: 1564\n",
      "loss None\n",
      "batch time cost: 5.6579718589782715\n",
      "Epoch: 0, batch: 1565\n",
      "loss None\n",
      "batch time cost: 5.430966138839722\n",
      "Epoch: 0, batch: 1566\n",
      "loss None\n",
      "batch time cost: 5.654258966445923\n",
      "Epoch: 0, batch: 1567\n",
      "loss None\n",
      "batch time cost: 5.310343265533447\n",
      "Epoch: 0, batch: 1568\n",
      "loss None\n",
      "batch time cost: 5.276421070098877\n",
      "Epoch: 0, batch: 1569\n",
      "loss None\n",
      "batch time cost: 5.256036996841431\n",
      "Epoch: 0, batch: 1570\n",
      "loss None\n",
      "batch time cost: 5.272993087768555\n",
      "Relu Train Epoch: 0 [100480/318582 (0%)]\tLoss: 1.008748\n",
      "Epoch: 0, batch: 1571\n",
      "loss None\n",
      "batch time cost: 5.6050310134887695\n",
      "Epoch: 0, batch: 1572\n",
      "loss None\n",
      "batch time cost: 5.253578186035156\n",
      "Epoch: 0, batch: 1573\n",
      "loss None\n",
      "batch time cost: 5.300979852676392\n",
      "Epoch: 0, batch: 1574\n",
      "loss None\n",
      "batch time cost: 5.263470649719238\n",
      "Epoch: 0, batch: 1575\n",
      "loss None\n",
      "batch time cost: 5.298148155212402\n",
      "Epoch: 0, batch: 1576\n",
      "loss None\n",
      "batch time cost: 5.315087080001831\n",
      "Epoch: 0, batch: 1577\n",
      "loss None\n",
      "batch time cost: 5.470324993133545\n",
      "Epoch: 0, batch: 1578\n",
      "loss None\n",
      "batch time cost: 5.884739875793457\n",
      "Epoch: 0, batch: 1579\n",
      "loss None\n",
      "batch time cost: 5.611948013305664\n",
      "Epoch: 0, batch: 1580\n",
      "loss None\n",
      "batch time cost: 5.281198263168335\n",
      "Relu Train Epoch: 0 [101120/318582 (0%)]\tLoss: 1.025142\n",
      "Epoch: 0, batch: 1581\n",
      "loss None\n",
      "batch time cost: 5.3059117794036865\n",
      "Epoch: 0, batch: 1582\n",
      "loss None\n",
      "batch time cost: 5.248983860015869\n",
      "Epoch: 0, batch: 1583\n",
      "loss None\n",
      "batch time cost: 5.261979103088379\n",
      "Epoch: 0, batch: 1584\n",
      "loss None\n",
      "batch time cost: 5.2707679271698\n",
      "Epoch: 0, batch: 1585\n",
      "loss None\n",
      "batch time cost: 5.238437175750732\n",
      "Epoch: 0, batch: 1586\n",
      "loss None\n",
      "batch time cost: 5.5928308963775635\n",
      "Epoch: 0, batch: 1587\n",
      "loss None\n",
      "batch time cost: 5.302411079406738\n",
      "Epoch: 0, batch: 1588\n",
      "loss None\n",
      "batch time cost: 5.382805109024048\n",
      "Epoch: 0, batch: 1589\n",
      "loss None\n",
      "batch time cost: 5.308968782424927\n",
      "Epoch: 0, batch: 1590\n",
      "loss None\n",
      "batch time cost: 5.280325889587402\n",
      "Relu Train Epoch: 0 [101760/318582 (0%)]\tLoss: 0.866949\n",
      "Epoch: 0, batch: 1591\n",
      "loss None\n",
      "batch time cost: 5.301455974578857\n",
      "Epoch: 0, batch: 1592\n",
      "loss None\n",
      "batch time cost: 5.299110174179077\n",
      "Epoch: 0, batch: 1593\n",
      "loss None\n",
      "batch time cost: 5.575149774551392\n",
      "Epoch: 0, batch: 1594\n",
      "loss None\n",
      "batch time cost: 5.317435026168823\n",
      "Epoch: 0, batch: 1595\n",
      "loss None\n",
      "batch time cost: 5.230629920959473\n",
      "Epoch: 0, batch: 1596\n",
      "loss None\n",
      "batch time cost: 5.241733074188232\n",
      "Epoch: 0, batch: 1597\n",
      "loss None\n",
      "batch time cost: 5.279578924179077\n",
      "Epoch: 0, batch: 1598\n",
      "loss None\n",
      "batch time cost: 5.330729246139526\n",
      "Epoch: 0, batch: 1599\n",
      "loss None\n",
      "batch time cost: 7.906814098358154\n",
      "Epoch: 0, batch: 1600\n",
      "loss None\n",
      "batch time cost: 8.776205062866211\n",
      "Relu Train Epoch: 0 [102400/318582 (0%)]\tLoss: 0.946502\n",
      "Epoch: 0, batch: 1601\n",
      "loss None\n",
      "batch time cost: 7.8981969356536865\n",
      "Epoch: 0, batch: 1602\n",
      "loss None\n",
      "batch time cost: 7.525800943374634\n",
      "Epoch: 0, batch: 1603\n",
      "loss None\n",
      "batch time cost: 6.144546747207642\n",
      "Epoch: 0, batch: 1604\n",
      "loss None\n",
      "batch time cost: 5.990692138671875\n",
      "Epoch: 0, batch: 1605\n",
      "loss None\n",
      "batch time cost: 5.623523235321045\n",
      "Epoch: 0, batch: 1606\n",
      "loss None\n",
      "batch time cost: 5.318773031234741\n",
      "Epoch: 0, batch: 1607\n",
      "loss None\n",
      "batch time cost: 5.278378009796143\n",
      "Epoch: 0, batch: 1608\n",
      "loss None\n",
      "batch time cost: 7.877013921737671\n",
      "Epoch: 0, batch: 1609\n",
      "loss None\n",
      "batch time cost: 5.291203022003174\n",
      "Epoch: 0, batch: 1610\n",
      "loss None\n",
      "batch time cost: 5.312826156616211\n",
      "Relu Train Epoch: 0 [103040/318582 (0%)]\tLoss: 0.940092\n",
      "Epoch: 0, batch: 1611\n",
      "loss None\n",
      "batch time cost: 5.249232769012451\n",
      "Epoch: 0, batch: 1612\n",
      "loss None\n",
      "batch time cost: 5.297775983810425\n",
      "Epoch: 0, batch: 1613\n",
      "loss None\n",
      "batch time cost: 5.265440940856934\n",
      "Epoch: 0, batch: 1614\n",
      "loss None\n",
      "batch time cost: 5.237419128417969\n",
      "Epoch: 0, batch: 1615\n",
      "loss None\n",
      "batch time cost: 6.968739986419678\n",
      "Epoch: 0, batch: 1616\n",
      "loss None\n",
      "batch time cost: 6.927304029464722\n",
      "Epoch: 0, batch: 1617\n",
      "loss None\n",
      "batch time cost: 6.058473110198975\n",
      "Epoch: 0, batch: 1618\n",
      "loss None\n",
      "batch time cost: 6.218451738357544\n",
      "Epoch: 0, batch: 1619\n",
      "loss None\n",
      "batch time cost: 6.9031078815460205\n",
      "Epoch: 0, batch: 1620\n",
      "loss None\n",
      "batch time cost: 5.554019212722778\n",
      "Relu Train Epoch: 0 [103680/318582 (0%)]\tLoss: 1.005290\n",
      "Epoch: 0, batch: 1621\n",
      "loss None\n",
      "batch time cost: 5.2591259479522705\n",
      "Epoch: 0, batch: 1622\n",
      "loss None\n",
      "batch time cost: 5.567350149154663\n",
      "Epoch: 0, batch: 1623\n",
      "loss None\n",
      "batch time cost: 5.268534898757935\n",
      "Epoch: 0, batch: 1624\n",
      "loss None\n",
      "batch time cost: 5.319204807281494\n",
      "Epoch: 0, batch: 1625\n",
      "loss None\n",
      "batch time cost: 5.255931854248047\n",
      "Epoch: 0, batch: 1626\n",
      "loss None\n",
      "batch time cost: 5.2272632122039795\n",
      "Epoch: 0, batch: 1627\n",
      "loss None\n",
      "batch time cost: 5.266428232192993\n",
      "Epoch: 0, batch: 1628\n",
      "loss None\n",
      "batch time cost: 5.251507997512817\n",
      "Epoch: 0, batch: 1629\n",
      "loss None\n",
      "batch time cost: 5.641482591629028\n",
      "Epoch: 0, batch: 1630\n",
      "loss None\n",
      "batch time cost: 5.411880254745483\n",
      "Relu Train Epoch: 0 [104320/318582 (0%)]\tLoss: 0.875396\n",
      "Epoch: 0, batch: 1631\n",
      "loss None\n",
      "batch time cost: 5.2916951179504395\n",
      "Epoch: 0, batch: 1632\n",
      "loss None\n",
      "batch time cost: 5.257981300354004\n",
      "Epoch: 0, batch: 1633\n",
      "loss None\n",
      "batch time cost: 5.235841989517212\n",
      "Epoch: 0, batch: 1634\n",
      "loss None\n",
      "batch time cost: 5.233844041824341\n",
      "Epoch: 0, batch: 1635\n",
      "loss None\n",
      "batch time cost: 5.233397960662842\n",
      "Epoch: 0, batch: 1636\n",
      "loss None\n",
      "batch time cost: 5.739506959915161\n",
      "Epoch: 0, batch: 1637\n",
      "loss None\n",
      "batch time cost: 5.324949026107788\n",
      "Epoch: 0, batch: 1638\n",
      "loss None\n",
      "batch time cost: 5.328657865524292\n",
      "Epoch: 0, batch: 1639\n",
      "loss None\n",
      "batch time cost: 5.273420095443726\n",
      "Epoch: 0, batch: 1640\n",
      "loss None\n",
      "batch time cost: 5.3323540687561035\n",
      "Relu Train Epoch: 0 [104960/318582 (0%)]\tLoss: 0.737603\n",
      "Epoch: 0, batch: 1641\n",
      "loss None\n",
      "batch time cost: 5.288764953613281\n",
      "Epoch: 0, batch: 1642\n",
      "loss None\n",
      "batch time cost: 5.29389214515686\n",
      "Epoch: 0, batch: 1643\n",
      "loss None\n",
      "batch time cost: 5.278074264526367\n",
      "Epoch: 0, batch: 1644\n",
      "loss None\n",
      "batch time cost: 5.727308750152588\n",
      "Epoch: 0, batch: 1645\n",
      "loss None\n",
      "batch time cost: 5.265927076339722\n",
      "Epoch: 0, batch: 1646\n",
      "loss None\n",
      "batch time cost: 5.278630018234253\n",
      "Epoch: 0, batch: 1647\n",
      "loss None\n",
      "batch time cost: 5.278578996658325\n",
      "Epoch: 0, batch: 1648\n",
      "loss None\n",
      "batch time cost: 5.2630579471588135\n",
      "Epoch: 0, batch: 1649\n",
      "loss None\n",
      "batch time cost: 5.238972902297974\n",
      "Epoch: 0, batch: 1650\n",
      "loss None\n",
      "batch time cost: 5.275611877441406\n",
      "Relu Train Epoch: 0 [105600/318582 (0%)]\tLoss: 0.872229\n",
      "Epoch: 0, batch: 1651\n",
      "loss None\n",
      "batch time cost: 5.618669271469116\n",
      "Epoch: 0, batch: 1652\n",
      "loss None\n",
      "batch time cost: 5.369612216949463\n",
      "Epoch: 0, batch: 1653\n",
      "loss None\n",
      "batch time cost: 5.232306957244873\n",
      "Epoch: 0, batch: 1654\n",
      "loss None\n",
      "batch time cost: 5.264098882675171\n",
      "Epoch: 0, batch: 1655\n",
      "loss None\n",
      "batch time cost: 5.247862100601196\n",
      "Epoch: 0, batch: 1656\n",
      "loss None\n",
      "batch time cost: 5.253031015396118\n",
      "Epoch: 0, batch: 1657\n",
      "loss None\n",
      "batch time cost: 5.238581895828247\n",
      "Epoch: 0, batch: 1658\n",
      "loss None\n",
      "batch time cost: 5.628022909164429\n",
      "Epoch: 0, batch: 1659\n",
      "loss None\n",
      "batch time cost: 5.328161001205444\n",
      "Epoch: 0, batch: 1660\n",
      "loss None\n",
      "batch time cost: 5.309421062469482\n",
      "Relu Train Epoch: 0 [106240/318582 (0%)]\tLoss: 0.866909\n",
      "Epoch: 0, batch: 1661\n",
      "loss None\n",
      "batch time cost: 5.242195129394531\n",
      "Epoch: 0, batch: 1662\n",
      "loss None\n",
      "batch time cost: 5.258759260177612\n",
      "Epoch: 0, batch: 1663\n",
      "loss None\n",
      "batch time cost: 5.4129798412323\n",
      "Epoch: 0, batch: 1664\n",
      "loss None\n",
      "batch time cost: 5.276226043701172\n",
      "Epoch: 0, batch: 1665\n",
      "loss None\n",
      "batch time cost: 5.888150215148926\n",
      "Epoch: 0, batch: 1666\n",
      "loss None\n",
      "batch time cost: 6.007179021835327\n",
      "Epoch: 0, batch: 1667\n",
      "loss None\n",
      "batch time cost: 5.518701076507568\n",
      "Epoch: 0, batch: 1668\n",
      "loss None\n",
      "batch time cost: 5.44223690032959\n",
      "Epoch: 0, batch: 1669\n",
      "loss None\n",
      "batch time cost: 5.362553119659424\n",
      "Epoch: 0, batch: 1670\n",
      "loss None\n",
      "batch time cost: 5.253007888793945\n",
      "Relu Train Epoch: 0 [106880/318582 (0%)]\tLoss: 1.074786\n",
      "Epoch: 0, batch: 1671\n",
      "loss None\n",
      "batch time cost: 5.222654819488525\n",
      "Epoch: 0, batch: 1672\n",
      "loss None\n",
      "batch time cost: 5.295661926269531\n",
      "Epoch: 0, batch: 1673\n",
      "loss None\n",
      "batch time cost: 5.617715835571289\n",
      "Epoch: 0, batch: 1674\n",
      "loss None\n",
      "batch time cost: 5.282145023345947\n",
      "Epoch: 0, batch: 1675\n",
      "loss None\n",
      "batch time cost: 5.315576076507568\n",
      "Epoch: 0, batch: 1676\n",
      "loss None\n",
      "batch time cost: 5.27799916267395\n",
      "Epoch: 0, batch: 1677\n",
      "loss None\n",
      "batch time cost: 5.268959999084473\n",
      "Epoch: 0, batch: 1678\n",
      "loss None\n",
      "batch time cost: 5.307375192642212\n",
      "Epoch: 0, batch: 1679\n",
      "loss None\n",
      "batch time cost: 5.29664421081543\n",
      "Epoch: 0, batch: 1680\n",
      "loss None\n",
      "batch time cost: 5.617203950881958\n",
      "Relu Train Epoch: 0 [107520/318582 (0%)]\tLoss: 0.921294\n",
      "Epoch: 0, batch: 1681\n",
      "loss None\n",
      "batch time cost: 5.2796289920806885\n",
      "Epoch: 0, batch: 1682\n",
      "loss None\n",
      "batch time cost: 5.3411338329315186\n",
      "Epoch: 0, batch: 1683\n",
      "loss None\n",
      "batch time cost: 5.3096089363098145\n",
      "Epoch: 0, batch: 1684\n",
      "loss None\n",
      "batch time cost: 5.2969279289245605\n",
      "Epoch: 0, batch: 1685\n",
      "loss None\n",
      "batch time cost: 5.35313606262207\n",
      "Epoch: 0, batch: 1686\n",
      "loss None\n",
      "batch time cost: 5.335144281387329\n",
      "Epoch: 0, batch: 1687\n",
      "loss None\n",
      "batch time cost: 5.63167405128479\n",
      "Epoch: 0, batch: 1688\n",
      "loss None\n",
      "batch time cost: 5.450579881668091\n",
      "Epoch: 0, batch: 1689\n",
      "loss None\n",
      "batch time cost: 5.306391000747681\n",
      "Epoch: 0, batch: 1690\n",
      "loss None\n",
      "batch time cost: 5.849820852279663\n",
      "Relu Train Epoch: 0 [108160/318582 (0%)]\tLoss: 0.793325\n",
      "Epoch: 0, batch: 1691\n",
      "loss None\n",
      "batch time cost: 5.9290900230407715\n",
      "Epoch: 0, batch: 1692\n",
      "loss None\n",
      "batch time cost: 5.316776752471924\n",
      "Epoch: 0, batch: 1693\n",
      "loss None\n",
      "batch time cost: 5.289459943771362\n",
      "Epoch: 0, batch: 1694\n",
      "loss None\n",
      "batch time cost: 5.632282018661499\n",
      "Epoch: 0, batch: 1695\n",
      "loss None\n",
      "batch time cost: 5.244956016540527\n",
      "Epoch: 0, batch: 1696\n",
      "loss None\n",
      "batch time cost: 5.302906036376953\n",
      "Epoch: 0, batch: 1697\n",
      "loss None\n",
      "batch time cost: 5.36110520362854\n",
      "Epoch: 0, batch: 1698\n",
      "loss None\n",
      "batch time cost: 5.281747817993164\n",
      "Epoch: 0, batch: 1699\n",
      "loss None\n",
      "batch time cost: 5.269808053970337\n",
      "Epoch: 0, batch: 1700\n",
      "loss None\n",
      "batch time cost: 5.264058828353882\n",
      "Relu Train Epoch: 0 [108800/318582 (0%)]\tLoss: 0.738611\n",
      "Epoch: 0, batch: 1701\n",
      "loss None\n",
      "batch time cost: 5.6628992557525635\n",
      "Epoch: 0, batch: 1702\n",
      "loss None\n",
      "batch time cost: 5.282707929611206\n",
      "Epoch: 0, batch: 1703\n",
      "loss None\n",
      "batch time cost: 5.249892950057983\n",
      "Epoch: 0, batch: 1704\n",
      "loss None\n",
      "batch time cost: 5.257968187332153\n",
      "Epoch: 0, batch: 1705\n",
      "loss None\n",
      "batch time cost: 5.2621190547943115\n",
      "Epoch: 0, batch: 1706\n",
      "loss None\n",
      "batch time cost: 5.26125168800354\n",
      "Epoch: 0, batch: 1707\n",
      "loss None\n",
      "batch time cost: 5.365299224853516\n",
      "Epoch: 0, batch: 1708\n",
      "loss None\n",
      "batch time cost: 5.348862886428833\n",
      "Epoch: 0, batch: 1709\n",
      "loss None\n",
      "batch time cost: 5.577342987060547\n",
      "Epoch: 0, batch: 1710\n",
      "loss None\n",
      "batch time cost: 5.337939023971558\n",
      "Relu Train Epoch: 0 [109440/318582 (0%)]\tLoss: 0.967373\n",
      "Epoch: 0, batch: 1711\n",
      "loss None\n",
      "batch time cost: 5.345650911331177\n",
      "Epoch: 0, batch: 1712\n",
      "loss None\n",
      "batch time cost: 5.329188108444214\n",
      "Epoch: 0, batch: 1713\n",
      "loss None\n",
      "batch time cost: 5.268125057220459\n",
      "Epoch: 0, batch: 1714\n",
      "loss None\n",
      "batch time cost: 5.302687406539917\n",
      "Epoch: 0, batch: 1715\n",
      "loss None\n",
      "batch time cost: 5.272504806518555\n",
      "Epoch: 0, batch: 1716\n",
      "loss None\n",
      "batch time cost: 5.554021120071411\n",
      "Epoch: 0, batch: 1717\n",
      "loss None\n",
      "batch time cost: 5.264793872833252\n",
      "Epoch: 0, batch: 1718\n",
      "loss None\n",
      "batch time cost: 5.245898008346558\n",
      "Epoch: 0, batch: 1719\n",
      "loss None\n",
      "batch time cost: 5.273883104324341\n",
      "Epoch: 0, batch: 1720\n",
      "loss None\n",
      "batch time cost: 5.301363229751587\n",
      "Relu Train Epoch: 0 [110080/318582 (0%)]\tLoss: 0.666963\n",
      "Epoch: 0, batch: 1721\n",
      "loss None\n",
      "batch time cost: 5.31757378578186\n",
      "Epoch: 0, batch: 1722\n",
      "loss None\n",
      "batch time cost: 5.317548990249634\n",
      "Epoch: 0, batch: 1723\n",
      "loss None\n",
      "batch time cost: 5.649165868759155\n",
      "Epoch: 0, batch: 1724\n",
      "loss None\n",
      "batch time cost: 5.253151893615723\n",
      "Epoch: 0, batch: 1725\n",
      "loss None\n",
      "batch time cost: 5.282604217529297\n",
      "Epoch: 0, batch: 1726\n",
      "loss None\n",
      "batch time cost: 5.270545721054077\n",
      "Epoch: 0, batch: 1727\n",
      "loss None\n",
      "batch time cost: 5.304452896118164\n",
      "Epoch: 0, batch: 1728\n",
      "loss None\n",
      "batch time cost: 5.325908899307251\n",
      "Epoch: 0, batch: 1729\n",
      "loss None\n",
      "batch time cost: 5.28410792350769\n",
      "Epoch: 0, batch: 1730\n",
      "loss None\n",
      "batch time cost: 5.672218084335327\n",
      "Relu Train Epoch: 0 [110720/318582 (0%)]\tLoss: 0.969594\n",
      "Epoch: 0, batch: 1731\n",
      "loss None\n",
      "batch time cost: 5.382728815078735\n",
      "Epoch: 0, batch: 1732\n",
      "loss None\n",
      "batch time cost: 5.304214000701904\n",
      "Epoch: 0, batch: 1733\n",
      "loss None\n",
      "batch time cost: 5.2988059520721436\n",
      "Epoch: 0, batch: 1734\n",
      "loss None\n",
      "batch time cost: 5.293878078460693\n",
      "Epoch: 0, batch: 1735\n",
      "loss None\n",
      "batch time cost: 5.284095048904419\n",
      "Epoch: 0, batch: 1736\n",
      "loss None\n",
      "batch time cost: 5.246021032333374\n",
      "Epoch: 0, batch: 1737\n",
      "loss None\n",
      "batch time cost: 5.328837156295776\n",
      "Epoch: 0, batch: 1738\n",
      "loss None\n",
      "batch time cost: 5.628271102905273\n",
      "Epoch: 0, batch: 1739\n",
      "loss None\n",
      "batch time cost: 5.274089097976685\n",
      "Epoch: 0, batch: 1740\n",
      "loss None\n",
      "batch time cost: 5.293251037597656\n",
      "Relu Train Epoch: 0 [111360/318582 (0%)]\tLoss: 0.854856\n",
      "Epoch: 0, batch: 1741\n",
      "loss None\n",
      "batch time cost: 5.719676971435547\n",
      "Epoch: 0, batch: 1742\n",
      "loss None\n",
      "batch time cost: 5.256413221359253\n",
      "Epoch: 0, batch: 1743\n",
      "loss None\n",
      "batch time cost: 5.266471862792969\n",
      "Epoch: 0, batch: 1744\n",
      "loss None\n",
      "batch time cost: 5.239410877227783\n",
      "Epoch: 0, batch: 1745\n",
      "loss None\n",
      "batch time cost: 5.64800500869751\n",
      "Epoch: 0, batch: 1746\n",
      "loss None\n",
      "batch time cost: 5.263308048248291\n",
      "Epoch: 0, batch: 1747\n",
      "loss None\n",
      "batch time cost: 5.245620965957642\n",
      "Epoch: 0, batch: 1748\n",
      "loss None\n",
      "batch time cost: 5.241225004196167\n",
      "Epoch: 0, batch: 1749\n",
      "loss None\n",
      "batch time cost: 5.292480945587158\n",
      "Epoch: 0, batch: 1750\n",
      "loss None\n",
      "batch time cost: 5.283912897109985\n",
      "Relu Train Epoch: 0 [112000/318582 (0%)]\tLoss: 0.863226\n",
      "Epoch: 0, batch: 1751\n",
      "loss None\n",
      "batch time cost: 5.283060312271118\n",
      "Epoch: 0, batch: 1752\n",
      "loss None\n",
      "batch time cost: 5.762875080108643\n",
      "Epoch: 0, batch: 1753\n",
      "loss None\n",
      "batch time cost: 5.409209966659546\n",
      "Epoch: 0, batch: 1754\n",
      "loss None\n",
      "batch time cost: 5.315329074859619\n",
      "Epoch: 0, batch: 1755\n",
      "loss None\n",
      "batch time cost: 5.354732990264893\n",
      "Epoch: 0, batch: 1756\n",
      "loss None\n",
      "batch time cost: 5.2977070808410645\n",
      "Epoch: 0, batch: 1757\n",
      "loss None\n",
      "batch time cost: 5.278416156768799\n",
      "Epoch: 0, batch: 1758\n",
      "loss None\n",
      "batch time cost: 5.302723169326782\n",
      "Epoch: 0, batch: 1759\n",
      "loss None\n",
      "batch time cost: 5.578953981399536\n",
      "Epoch: 0, batch: 1760\n",
      "loss None\n",
      "batch time cost: 5.260892868041992\n",
      "Relu Train Epoch: 0 [112640/318582 (0%)]\tLoss: 0.643790\n",
      "Epoch: 0, batch: 1761\n",
      "loss None\n",
      "batch time cost: 5.253125190734863\n",
      "Epoch: 0, batch: 1762\n",
      "loss None\n",
      "batch time cost: 5.25472617149353\n",
      "Epoch: 0, batch: 1763\n",
      "loss None\n",
      "batch time cost: 5.36006498336792\n",
      "Epoch: 0, batch: 1764\n",
      "loss None\n",
      "batch time cost: 5.2829742431640625\n",
      "Epoch: 0, batch: 1765\n",
      "loss None\n",
      "batch time cost: 5.272729873657227\n",
      "Epoch: 0, batch: 1766\n",
      "loss None\n",
      "batch time cost: 5.684169054031372\n",
      "Epoch: 0, batch: 1767\n",
      "loss None\n",
      "batch time cost: 5.358395099639893\n",
      "Epoch: 0, batch: 1768\n",
      "loss None\n",
      "batch time cost: 5.297973155975342\n",
      "Epoch: 0, batch: 1769\n",
      "loss None\n",
      "batch time cost: 5.235202074050903\n",
      "Epoch: 0, batch: 1770\n",
      "loss None\n",
      "batch time cost: 5.281933069229126\n",
      "Relu Train Epoch: 0 [113280/318582 (0%)]\tLoss: 1.008370\n",
      "Epoch: 0, batch: 1771\n",
      "loss None\n",
      "batch time cost: 5.254622936248779\n",
      "Epoch: 0, batch: 1772\n",
      "loss None\n",
      "batch time cost: 5.226846218109131\n",
      "Epoch: 0, batch: 1773\n",
      "loss None\n",
      "batch time cost: 5.237552881240845\n",
      "Epoch: 0, batch: 1774\n",
      "loss None\n",
      "batch time cost: 5.63810920715332\n",
      "Epoch: 0, batch: 1775\n",
      "loss None\n",
      "batch time cost: 7.037574052810669\n",
      "Epoch: 0, batch: 1776\n",
      "loss None\n",
      "batch time cost: 6.748927116394043\n",
      "Epoch: 0, batch: 1777\n",
      "loss None\n",
      "batch time cost: 6.802710056304932\n",
      "Epoch: 0, batch: 1778\n",
      "loss None\n",
      "batch time cost: 6.924412250518799\n",
      "Epoch: 0, batch: 1779\n",
      "loss None\n",
      "batch time cost: 5.396342039108276\n",
      "Epoch: 0, batch: 1780\n",
      "loss None\n",
      "batch time cost: 5.3263020515441895\n",
      "Relu Train Epoch: 0 [113920/318582 (0%)]\tLoss: 0.826647\n",
      "Epoch: 0, batch: 1781\n",
      "loss None\n",
      "batch time cost: 5.599830865859985\n",
      "Epoch: 0, batch: 1782\n",
      "loss None\n",
      "batch time cost: 5.212925910949707\n",
      "Epoch: 0, batch: 1783\n",
      "loss None\n",
      "batch time cost: 5.276195049285889\n",
      "Epoch: 0, batch: 1784\n",
      "loss None\n",
      "batch time cost: 5.262336015701294\n",
      "Epoch: 0, batch: 1785\n",
      "loss None\n",
      "batch time cost: 5.270560026168823\n",
      "Epoch: 0, batch: 1786\n",
      "loss None\n",
      "batch time cost: 5.29697322845459\n",
      "Epoch: 0, batch: 1787\n",
      "loss None\n",
      "batch time cost: 5.254021883010864\n",
      "Epoch: 0, batch: 1788\n",
      "loss None\n",
      "batch time cost: 5.863673210144043\n",
      "Epoch: 0, batch: 1789\n",
      "loss None\n",
      "batch time cost: 5.335153341293335\n",
      "Epoch: 0, batch: 1790\n",
      "loss None\n",
      "batch time cost: 5.2683188915252686\n",
      "Relu Train Epoch: 0 [114560/318582 (0%)]\tLoss: 0.818746\n",
      "Epoch: 0, batch: 1791\n",
      "loss None\n",
      "batch time cost: 5.259400844573975\n",
      "Epoch: 0, batch: 1792\n",
      "loss None\n",
      "batch time cost: 5.2944018840789795\n",
      "Epoch: 0, batch: 1793\n",
      "loss None\n",
      "batch time cost: 5.226036787033081\n",
      "Epoch: 0, batch: 1794\n",
      "loss None\n",
      "batch time cost: 5.256657361984253\n",
      "Epoch: 0, batch: 1795\n",
      "loss None\n",
      "batch time cost: 5.60167121887207\n",
      "Epoch: 0, batch: 1796\n",
      "loss None\n",
      "batch time cost: 5.693241119384766\n",
      "Epoch: 0, batch: 1797\n",
      "loss None\n",
      "batch time cost: 5.293437957763672\n",
      "Epoch: 0, batch: 1798\n",
      "loss None\n",
      "batch time cost: 5.46495509147644\n",
      "Epoch: 0, batch: 1799\n",
      "loss None\n",
      "batch time cost: 5.461040735244751\n",
      "Epoch: 0, batch: 1800\n",
      "loss None\n",
      "batch time cost: 5.51171088218689\n",
      "Relu Train Epoch: 0 [115200/318582 (0%)]\tLoss: 0.840406\n",
      "Epoch: 0, batch: 1801\n",
      "loss None\n",
      "batch time cost: 5.288945913314819\n",
      "Epoch: 0, batch: 1802\n",
      "loss None\n",
      "batch time cost: 5.302618741989136\n",
      "Epoch: 0, batch: 1803\n",
      "loss None\n",
      "batch time cost: 5.594033241271973\n",
      "Epoch: 0, batch: 1804\n",
      "loss None\n",
      "batch time cost: 5.278166055679321\n",
      "Epoch: 0, batch: 1805\n",
      "loss None\n",
      "batch time cost: 5.372164011001587\n",
      "Epoch: 0, batch: 1806\n",
      "loss None\n",
      "batch time cost: 5.313668966293335\n",
      "Epoch: 0, batch: 1807\n",
      "loss None\n",
      "batch time cost: 5.330958843231201\n",
      "Epoch: 0, batch: 1808\n",
      "loss None\n",
      "batch time cost: 5.240858793258667\n",
      "Epoch: 0, batch: 1809\n",
      "loss None\n",
      "batch time cost: 5.329185962677002\n",
      "Epoch: 0, batch: 1810\n",
      "loss None\n",
      "batch time cost: 5.631569862365723\n",
      "Relu Train Epoch: 0 [115840/318582 (0%)]\tLoss: 0.729595\n",
      "Epoch: 0, batch: 1811\n",
      "loss None\n",
      "batch time cost: 5.318209171295166\n",
      "Epoch: 0, batch: 1812\n",
      "loss None\n",
      "batch time cost: 5.3283751010894775\n",
      "Epoch: 0, batch: 1813\n",
      "loss None\n",
      "batch time cost: 5.246718883514404\n",
      "Epoch: 0, batch: 1814\n",
      "loss None\n",
      "batch time cost: 5.27069091796875\n",
      "Epoch: 0, batch: 1815\n",
      "loss None\n",
      "batch time cost: 5.26499605178833\n",
      "Epoch: 0, batch: 1816\n",
      "loss None\n",
      "batch time cost: 5.2255518436431885\n",
      "Epoch: 0, batch: 1817\n",
      "loss None\n",
      "batch time cost: 5.540280103683472\n",
      "Epoch: 0, batch: 1818\n",
      "loss None\n",
      "batch time cost: 5.4737229347229\n",
      "Epoch: 0, batch: 1819\n",
      "loss None\n",
      "batch time cost: 5.2994019985198975\n",
      "Epoch: 0, batch: 1820\n",
      "loss None\n",
      "batch time cost: 5.34419584274292\n",
      "Relu Train Epoch: 0 [116480/318582 (0%)]\tLoss: 0.837332\n",
      "Epoch: 0, batch: 1821\n",
      "loss None\n",
      "batch time cost: 5.521661996841431\n",
      "Epoch: 0, batch: 1822\n",
      "loss None\n",
      "batch time cost: 5.632692098617554\n",
      "Epoch: 0, batch: 1823\n",
      "loss None\n",
      "batch time cost: 5.679391145706177\n",
      "Epoch: 0, batch: 1824\n",
      "loss None\n",
      "batch time cost: 5.646456003189087\n",
      "Epoch: 0, batch: 1825\n",
      "loss None\n",
      "batch time cost: 5.284613132476807\n",
      "Epoch: 0, batch: 1826\n",
      "loss None\n",
      "batch time cost: 5.261836051940918\n",
      "Epoch: 0, batch: 1827\n",
      "loss None\n",
      "batch time cost: 5.259324789047241\n",
      "Epoch: 0, batch: 1828\n",
      "loss None\n",
      "batch time cost: 5.311924934387207\n",
      "Epoch: 0, batch: 1829\n",
      "loss None\n",
      "batch time cost: 5.345585107803345\n",
      "Epoch: 0, batch: 1830\n",
      "loss None\n",
      "batch time cost: 5.2537291049957275\n",
      "Relu Train Epoch: 0 [117120/318582 (0%)]\tLoss: 0.843224\n",
      "Epoch: 0, batch: 1831\n",
      "loss None\n",
      "batch time cost: 5.741825103759766\n",
      "Epoch: 0, batch: 1832\n",
      "loss None\n",
      "batch time cost: 5.336231231689453\n",
      "Epoch: 0, batch: 1833\n",
      "loss None\n",
      "batch time cost: 5.294010877609253\n",
      "Epoch: 0, batch: 1834\n",
      "loss None\n",
      "batch time cost: 5.277107000350952\n",
      "Epoch: 0, batch: 1835\n",
      "loss None\n",
      "batch time cost: 5.267182111740112\n",
      "Epoch: 0, batch: 1836\n",
      "loss None\n",
      "batch time cost: 5.2861340045928955\n",
      "Epoch: 0, batch: 1837\n",
      "loss None\n",
      "batch time cost: 5.283504009246826\n",
      "Epoch: 0, batch: 1838\n",
      "loss None\n",
      "batch time cost: 5.298230886459351\n",
      "Epoch: 0, batch: 1839\n",
      "loss None\n",
      "batch time cost: 5.556443214416504\n",
      "Epoch: 0, batch: 1840\n",
      "loss None\n",
      "batch time cost: 5.230319261550903\n",
      "Relu Train Epoch: 0 [117760/318582 (0%)]\tLoss: 0.780415\n",
      "Epoch: 0, batch: 1841\n",
      "loss None\n",
      "batch time cost: 5.352141857147217\n",
      "Epoch: 0, batch: 1842\n",
      "loss None\n",
      "batch time cost: 5.327569007873535\n",
      "Epoch: 0, batch: 1843\n",
      "loss None\n",
      "batch time cost: 5.276221036911011\n",
      "Epoch: 0, batch: 1844\n",
      "loss None\n",
      "batch time cost: 5.331430912017822\n",
      "Epoch: 0, batch: 1845\n",
      "loss None\n",
      "batch time cost: 5.376151084899902\n",
      "Epoch: 0, batch: 1846\n",
      "loss None\n",
      "batch time cost: 5.5614869594573975\n",
      "Epoch: 0, batch: 1847\n",
      "loss None\n",
      "batch time cost: 5.287888050079346\n",
      "Epoch: 0, batch: 1848\n",
      "loss None\n",
      "batch time cost: 5.255615949630737\n",
      "Epoch: 0, batch: 1849\n",
      "loss None\n",
      "batch time cost: 5.2503252029418945\n",
      "Epoch: 0, batch: 1850\n",
      "loss None\n",
      "batch time cost: 5.2905378341674805\n",
      "Relu Train Epoch: 0 [118400/318582 (0%)]\tLoss: 0.831152\n",
      "Epoch: 0, batch: 1851\n",
      "loss None\n",
      "batch time cost: 5.273938179016113\n",
      "Epoch: 0, batch: 1852\n",
      "loss None\n",
      "batch time cost: 5.274133920669556\n",
      "Epoch: 0, batch: 1853\n",
      "loss None\n",
      "batch time cost: 6.068341970443726\n",
      "Epoch: 0, batch: 1854\n",
      "loss None\n",
      "batch time cost: 5.508141756057739\n",
      "Epoch: 0, batch: 1855\n",
      "loss None\n",
      "batch time cost: 5.292008876800537\n",
      "Epoch: 0, batch: 1856\n",
      "loss None\n",
      "batch time cost: 5.210836887359619\n",
      "Epoch: 0, batch: 1857\n",
      "loss None\n",
      "batch time cost: 5.289000988006592\n",
      "Epoch: 0, batch: 1858\n",
      "loss None\n",
      "batch time cost: 5.239268779754639\n",
      "Epoch: 0, batch: 1859\n",
      "loss None\n",
      "batch time cost: 5.264224052429199\n",
      "Epoch: 0, batch: 1860\n",
      "loss None\n",
      "batch time cost: 5.606872797012329\n",
      "Relu Train Epoch: 0 [119040/318582 (0%)]\tLoss: 0.804157\n",
      "Epoch: 0, batch: 1861\n",
      "loss None\n",
      "batch time cost: 5.35640025138855\n",
      "Epoch: 0, batch: 1862\n",
      "loss None\n",
      "batch time cost: 5.2939677238464355\n",
      "Epoch: 0, batch: 1863\n",
      "loss None\n",
      "batch time cost: 5.2602219581604\n",
      "Epoch: 0, batch: 1864\n",
      "loss None\n",
      "batch time cost: 5.222582817077637\n",
      "Epoch: 0, batch: 1865\n",
      "loss None\n",
      "batch time cost: 5.254961013793945\n",
      "Epoch: 0, batch: 1866\n",
      "loss None\n",
      "batch time cost: 5.2809600830078125\n",
      "Epoch: 0, batch: 1867\n",
      "loss None\n",
      "batch time cost: 5.324943780899048\n",
      "Epoch: 0, batch: 1868\n",
      "loss None\n",
      "batch time cost: 5.552666902542114\n",
      "Epoch: 0, batch: 1869\n",
      "loss None\n",
      "batch time cost: 5.280367136001587\n",
      "Epoch: 0, batch: 1870\n",
      "loss None\n",
      "batch time cost: 5.299951076507568\n",
      "Relu Train Epoch: 0 [119680/318582 (0%)]\tLoss: 0.736452\n",
      "Epoch: 0, batch: 1871\n",
      "loss None\n",
      "batch time cost: 5.289293050765991\n",
      "Epoch: 0, batch: 1872\n",
      "loss None\n",
      "batch time cost: 5.302546977996826\n",
      "Epoch: 0, batch: 1873\n",
      "loss None\n",
      "batch time cost: 5.29656982421875\n",
      "Epoch: 0, batch: 1874\n",
      "loss None\n",
      "batch time cost: 5.389469146728516\n",
      "Epoch: 0, batch: 1875\n",
      "loss None\n",
      "batch time cost: 5.621872186660767\n",
      "Epoch: 0, batch: 1876\n",
      "loss None\n",
      "batch time cost: 5.365239858627319\n",
      "Epoch: 0, batch: 1877\n",
      "loss None\n",
      "batch time cost: 5.246771812438965\n",
      "Epoch: 0, batch: 1878\n",
      "loss None\n",
      "batch time cost: 5.464928865432739\n",
      "Epoch: 0, batch: 1879\n",
      "loss None\n",
      "batch time cost: 5.420942783355713\n",
      "Epoch: 0, batch: 1880\n",
      "loss None\n",
      "batch time cost: 5.312151670455933\n",
      "Relu Train Epoch: 0 [120320/318582 (0%)]\tLoss: 0.962126\n",
      "Epoch: 0, batch: 1881\n",
      "loss None\n",
      "batch time cost: 5.294740200042725\n",
      "Epoch: 0, batch: 1882\n",
      "loss None\n",
      "batch time cost: 5.643675804138184\n",
      "Epoch: 0, batch: 1883\n",
      "loss None\n",
      "batch time cost: 5.374364137649536\n",
      "Epoch: 0, batch: 1884\n",
      "loss None\n",
      "batch time cost: 5.309334754943848\n",
      "Epoch: 0, batch: 1885\n",
      "loss None\n",
      "batch time cost: 5.352502107620239\n",
      "Epoch: 0, batch: 1886\n",
      "loss None\n",
      "batch time cost: 5.297090768814087\n",
      "Epoch: 0, batch: 1887\n",
      "loss None\n",
      "batch time cost: 5.259937047958374\n",
      "Epoch: 0, batch: 1888\n",
      "loss None\n",
      "batch time cost: 5.285330057144165\n",
      "Epoch: 0, batch: 1889\n",
      "loss None\n",
      "batch time cost: 7.7797770500183105\n",
      "Epoch: 0, batch: 1890\n",
      "loss None\n",
      "batch time cost: 5.325343132019043\n",
      "Relu Train Epoch: 0 [120960/318582 (0%)]\tLoss: 0.880826\n",
      "Epoch: 0, batch: 1891\n",
      "loss None\n",
      "batch time cost: 5.2798027992248535\n",
      "Epoch: 0, batch: 1892\n",
      "loss None\n",
      "batch time cost: 5.294489145278931\n",
      "Epoch: 0, batch: 1893\n",
      "loss None\n",
      "batch time cost: 5.214266300201416\n",
      "Epoch: 0, batch: 1894\n",
      "loss None\n",
      "batch time cost: 5.261641979217529\n",
      "Epoch: 0, batch: 1895\n",
      "loss None\n",
      "batch time cost: 5.240657806396484\n",
      "Epoch: 0, batch: 1896\n",
      "loss None\n",
      "batch time cost: 5.65966010093689\n",
      "Epoch: 0, batch: 1897\n",
      "loss None\n",
      "batch time cost: 5.339065074920654\n",
      "Epoch: 0, batch: 1898\n",
      "loss None\n",
      "batch time cost: 5.324388265609741\n",
      "Epoch: 0, batch: 1899\n",
      "loss None\n",
      "batch time cost: 5.276593923568726\n",
      "Epoch: 0, batch: 1900\n",
      "loss None\n",
      "batch time cost: 5.201992988586426\n",
      "Relu Train Epoch: 0 [121600/318582 (0%)]\tLoss: 0.847340\n",
      "Epoch: 0, batch: 1901\n",
      "loss None\n",
      "batch time cost: 5.257390737533569\n",
      "Epoch: 0, batch: 1902\n",
      "loss None\n",
      "batch time cost: 5.276325225830078\n",
      "Epoch: 0, batch: 1903\n",
      "loss None\n",
      "batch time cost: 5.226605176925659\n",
      "Epoch: 0, batch: 1904\n",
      "loss None\n",
      "batch time cost: 5.666208982467651\n",
      "Epoch: 0, batch: 1905\n",
      "loss None\n",
      "batch time cost: 5.268842935562134\n",
      "Epoch: 0, batch: 1906\n",
      "loss None\n",
      "batch time cost: 5.285001993179321\n",
      "Epoch: 0, batch: 1907\n",
      "loss None\n",
      "batch time cost: 5.479839086532593\n",
      "Epoch: 0, batch: 1908\n",
      "loss None\n",
      "batch time cost: 5.349538803100586\n",
      "Epoch: 0, batch: 1909\n",
      "loss None\n",
      "batch time cost: 5.266340017318726\n",
      "Epoch: 0, batch: 1910\n",
      "loss None\n",
      "batch time cost: 5.242888927459717\n",
      "Relu Train Epoch: 0 [122240/318582 (0%)]\tLoss: 0.883123\n",
      "Epoch: 0, batch: 1911\n",
      "loss None\n",
      "batch time cost: 5.584467887878418\n",
      "Epoch: 0, batch: 1912\n",
      "loss None\n",
      "batch time cost: 5.339195966720581\n",
      "Epoch: 0, batch: 1913\n",
      "loss None\n",
      "batch time cost: 5.304856777191162\n",
      "Epoch: 0, batch: 1914\n",
      "loss None\n",
      "batch time cost: 5.320807933807373\n",
      "Epoch: 0, batch: 1915\n",
      "loss None\n",
      "batch time cost: 5.250529050827026\n",
      "Epoch: 0, batch: 1916\n",
      "loss None\n",
      "batch time cost: 5.292927980422974\n",
      "Epoch: 0, batch: 1917\n",
      "loss None\n",
      "batch time cost: 5.273722887039185\n",
      "Epoch: 0, batch: 1918\n",
      "loss None\n",
      "batch time cost: 5.623070240020752\n",
      "Epoch: 0, batch: 1919\n",
      "loss None\n",
      "batch time cost: 5.334205150604248\n",
      "Epoch: 0, batch: 1920\n",
      "loss None\n",
      "batch time cost: 5.318908929824829\n",
      "Relu Train Epoch: 0 [122880/318582 (0%)]\tLoss: 0.687028\n",
      "Epoch: 0, batch: 1921\n",
      "loss None\n",
      "batch time cost: 5.269801139831543\n",
      "Epoch: 0, batch: 1922\n",
      "loss None\n",
      "batch time cost: 5.303339004516602\n",
      "Epoch: 0, batch: 1923\n",
      "loss None\n",
      "batch time cost: 5.334010124206543\n",
      "Epoch: 0, batch: 1924\n",
      "loss None\n",
      "batch time cost: 5.267328977584839\n",
      "Epoch: 0, batch: 1925\n",
      "loss None\n",
      "batch time cost: 7.5369179248809814\n",
      "Epoch: 0, batch: 1926\n",
      "loss None\n",
      "batch time cost: 6.707784414291382\n",
      "Epoch: 0, batch: 1927\n",
      "loss None\n",
      "batch time cost: 5.836665153503418\n",
      "Epoch: 0, batch: 1928\n",
      "loss None\n",
      "batch time cost: 5.295656204223633\n",
      "Epoch: 0, batch: 1929\n",
      "loss None\n",
      "batch time cost: 5.384862899780273\n",
      "Epoch: 0, batch: 1930\n",
      "loss None\n",
      "batch time cost: 5.276618003845215\n",
      "Relu Train Epoch: 0 [123520/318582 (0%)]\tLoss: 0.781326\n",
      "Epoch: 0, batch: 1931\n",
      "loss None\n",
      "batch time cost: 5.264355659484863\n",
      "Epoch: 0, batch: 1932\n",
      "loss None\n",
      "batch time cost: 5.276440143585205\n",
      "Epoch: 0, batch: 1933\n",
      "loss None\n",
      "batch time cost: 6.596109867095947\n",
      "Epoch: 0, batch: 1934\n",
      "loss None\n",
      "batch time cost: 5.4316956996917725\n",
      "Epoch: 0, batch: 1935\n",
      "loss None\n",
      "batch time cost: 5.293645858764648\n",
      "Epoch: 0, batch: 1936\n",
      "loss None\n",
      "batch time cost: 5.266240119934082\n",
      "Epoch: 0, batch: 1937\n",
      "loss None\n",
      "batch time cost: 5.219872951507568\n",
      "Epoch: 0, batch: 1938\n",
      "loss None\n",
      "batch time cost: 5.216676712036133\n",
      "Epoch: 0, batch: 1939\n",
      "loss None\n",
      "batch time cost: 5.327885150909424\n",
      "Epoch: 0, batch: 1940\n",
      "loss None\n",
      "batch time cost: 5.854343891143799\n",
      "Relu Train Epoch: 0 [124160/318582 (0%)]\tLoss: 0.875826\n",
      "Epoch: 0, batch: 1941\n",
      "loss None\n",
      "batch time cost: 7.294967174530029\n",
      "Epoch: 0, batch: 1942\n",
      "loss None\n",
      "batch time cost: 7.489962816238403\n",
      "Epoch: 0, batch: 1943\n",
      "loss None\n",
      "batch time cost: 7.37202000617981\n",
      "Epoch: 0, batch: 1944\n",
      "loss None\n",
      "batch time cost: 5.562263011932373\n",
      "Epoch: 0, batch: 1945\n",
      "loss None\n",
      "batch time cost: 5.32928204536438\n",
      "Epoch: 0, batch: 1946\n",
      "loss None\n",
      "batch time cost: 5.258111953735352\n",
      "Epoch: 0, batch: 1947\n",
      "loss None\n",
      "batch time cost: 5.7212042808532715\n",
      "Epoch: 0, batch: 1948\n",
      "loss None\n",
      "batch time cost: 5.3395819664001465\n",
      "Epoch: 0, batch: 1949\n",
      "loss None\n",
      "batch time cost: 5.241892099380493\n",
      "Epoch: 0, batch: 1950\n",
      "loss None\n",
      "batch time cost: 5.337636947631836\n",
      "Relu Train Epoch: 0 [124800/318582 (0%)]\tLoss: 0.811769\n",
      "Epoch: 0, batch: 1951\n",
      "loss None\n",
      "batch time cost: 5.275026321411133\n",
      "Epoch: 0, batch: 1952\n",
      "loss None\n",
      "batch time cost: 5.286226987838745\n",
      "Epoch: 0, batch: 1953\n",
      "loss None\n",
      "batch time cost: 5.290075302124023\n",
      "Epoch: 0, batch: 1954\n",
      "loss None\n",
      "batch time cost: 5.693718910217285\n",
      "Epoch: 0, batch: 1955\n",
      "loss None\n",
      "batch time cost: 5.303858280181885\n",
      "Epoch: 0, batch: 1956\n",
      "loss None\n",
      "batch time cost: 5.281865835189819\n",
      "Epoch: 0, batch: 1957\n",
      "loss None\n",
      "batch time cost: 5.274507761001587\n",
      "Epoch: 0, batch: 1958\n",
      "loss None\n",
      "batch time cost: 5.313451051712036\n",
      "Epoch: 0, batch: 1959\n",
      "loss None\n",
      "batch time cost: 5.272842884063721\n",
      "Epoch: 0, batch: 1960\n",
      "loss None\n",
      "batch time cost: 5.295007944107056\n",
      "Relu Train Epoch: 0 [125440/318582 (0%)]\tLoss: 0.935544\n",
      "Epoch: 0, batch: 1961\n",
      "loss None\n",
      "batch time cost: 5.642131805419922\n",
      "Epoch: 0, batch: 1962\n",
      "loss None\n",
      "batch time cost: 5.3517069816589355\n",
      "Epoch: 0, batch: 1963\n",
      "loss None\n",
      "batch time cost: 5.2675089836120605\n",
      "Epoch: 0, batch: 1964\n",
      "loss None\n",
      "batch time cost: 5.2679290771484375\n",
      "Epoch: 0, batch: 1965\n",
      "loss None\n",
      "batch time cost: 5.261610984802246\n",
      "Epoch: 0, batch: 1966\n",
      "loss None\n",
      "batch time cost: 5.261986017227173\n",
      "Epoch: 0, batch: 1967\n",
      "loss None\n",
      "batch time cost: 5.282777786254883\n",
      "Epoch: 0, batch: 1968\n",
      "loss None\n",
      "batch time cost: 5.269874811172485\n",
      "Epoch: 0, batch: 1969\n",
      "loss None\n",
      "batch time cost: 7.453121662139893\n",
      "Epoch: 0, batch: 1970\n",
      "loss None\n",
      "batch time cost: 6.091809034347534\n",
      "Relu Train Epoch: 0 [126080/318582 (0%)]\tLoss: 0.903091\n",
      "Epoch: 0, batch: 1971\n",
      "loss None\n",
      "batch time cost: 5.32846999168396\n",
      "Epoch: 0, batch: 1972\n",
      "loss None\n",
      "batch time cost: 5.356673955917358\n",
      "Epoch: 0, batch: 1973\n",
      "loss None\n",
      "batch time cost: 5.254144906997681\n",
      "Epoch: 0, batch: 1974\n",
      "loss None\n",
      "batch time cost: 5.293597936630249\n",
      "Epoch: 0, batch: 1975\n",
      "loss None\n",
      "batch time cost: 5.335974931716919\n",
      "Epoch: 0, batch: 1976\n",
      "loss None\n",
      "batch time cost: 6.278408050537109\n",
      "Epoch: 0, batch: 1977\n",
      "loss None\n",
      "batch time cost: 5.86513876914978\n",
      "Epoch: 0, batch: 1978\n",
      "loss None\n",
      "batch time cost: 5.370450973510742\n",
      "Epoch: 0, batch: 1979\n",
      "loss None\n",
      "batch time cost: 5.301904916763306\n",
      "Epoch: 0, batch: 1980\n",
      "loss None\n",
      "batch time cost: 5.311743974685669\n",
      "Relu Train Epoch: 0 [126720/318582 (0%)]\tLoss: 0.873571\n",
      "Epoch: 0, batch: 1981\n",
      "loss None\n",
      "batch time cost: 5.258429765701294\n",
      "Epoch: 0, batch: 1982\n",
      "loss None\n",
      "batch time cost: 5.268862962722778\n",
      "Epoch: 0, batch: 1983\n",
      "loss None\n",
      "batch time cost: 6.300565004348755\n",
      "Epoch: 0, batch: 1984\n",
      "loss None\n",
      "batch time cost: 5.83135986328125\n",
      "Epoch: 0, batch: 1985\n",
      "loss None\n",
      "batch time cost: 5.386109828948975\n",
      "Epoch: 0, batch: 1986\n",
      "loss None\n",
      "batch time cost: 5.258886098861694\n",
      "Epoch: 0, batch: 1987\n",
      "loss None\n",
      "batch time cost: 5.269469738006592\n",
      "Epoch: 0, batch: 1988\n",
      "loss None\n",
      "batch time cost: 5.259908199310303\n",
      "Epoch: 0, batch: 1989\n",
      "loss None\n",
      "batch time cost: 5.260058164596558\n",
      "Epoch: 0, batch: 1990\n",
      "loss None\n",
      "batch time cost: 5.67352294921875\n",
      "Relu Train Epoch: 0 [127360/318582 (0%)]\tLoss: 0.965636\n",
      "Epoch: 0, batch: 1991\n",
      "loss None\n",
      "batch time cost: 5.289693117141724\n",
      "Epoch: 0, batch: 1992\n",
      "loss None\n",
      "batch time cost: 5.350043058395386\n",
      "Epoch: 0, batch: 1993\n",
      "loss None\n",
      "batch time cost: 5.287459850311279\n",
      "Epoch: 0, batch: 1994\n",
      "loss None\n",
      "batch time cost: 5.390172004699707\n",
      "Epoch: 0, batch: 1995\n",
      "loss None\n",
      "batch time cost: 5.369923830032349\n",
      "Epoch: 0, batch: 1996\n",
      "loss None\n",
      "batch time cost: 5.295269727706909\n",
      "Epoch: 0, batch: 1997\n",
      "loss None\n",
      "batch time cost: 5.2751569747924805\n",
      "Epoch: 0, batch: 1998\n",
      "loss None\n",
      "batch time cost: 5.679511785507202\n",
      "Epoch: 0, batch: 1999\n",
      "loss None\n",
      "batch time cost: 5.3466269969940186\n",
      "Epoch: 0, batch: 2000\n",
      "loss None\n",
      "batch time cost: 5.262357950210571\n",
      "Relu Train Epoch: 0 [128000/318582 (0%)]\tLoss: 0.925727\n",
      "Epoch: 0, batch: 2001\n",
      "loss None\n",
      "batch time cost: 5.254319906234741\n",
      "Epoch: 0, batch: 2002\n",
      "loss None\n",
      "batch time cost: 5.277204990386963\n",
      "Epoch: 0, batch: 2003\n",
      "loss None\n",
      "batch time cost: 5.233007192611694\n",
      "Epoch: 0, batch: 2004\n",
      "loss None\n",
      "batch time cost: 5.215744972229004\n",
      "Epoch: 0, batch: 2005\n",
      "loss None\n",
      "batch time cost: 5.799000978469849\n",
      "Epoch: 0, batch: 2006\n",
      "loss None\n",
      "batch time cost: 5.408879995346069\n",
      "Epoch: 0, batch: 2007\n",
      "loss None\n",
      "batch time cost: 5.342029094696045\n",
      "Epoch: 0, batch: 2008\n",
      "loss None\n",
      "batch time cost: 5.2481982707977295\n",
      "Epoch: 0, batch: 2009\n",
      "loss None\n",
      "batch time cost: 5.269788980484009\n",
      "Epoch: 0, batch: 2010\n",
      "loss None\n",
      "batch time cost: 5.317754030227661\n",
      "Relu Train Epoch: 0 [128640/318582 (0%)]\tLoss: 0.937156\n",
      "Epoch: 0, batch: 2011\n",
      "loss None\n",
      "batch time cost: 5.296124219894409\n",
      "Epoch: 0, batch: 2012\n",
      "loss None\n",
      "batch time cost: 5.8976359367370605\n",
      "Epoch: 0, batch: 2013\n",
      "loss None\n",
      "batch time cost: 5.72111701965332\n",
      "Epoch: 0, batch: 2014\n",
      "loss None\n",
      "batch time cost: 5.385657787322998\n",
      "Epoch: 0, batch: 2015\n",
      "loss None\n",
      "batch time cost: 5.278439998626709\n",
      "Epoch: 0, batch: 2016\n",
      "loss None\n",
      "batch time cost: 5.308323621749878\n",
      "Epoch: 0, batch: 2017\n",
      "loss None\n",
      "batch time cost: 5.218799114227295\n",
      "Epoch: 0, batch: 2018\n",
      "loss None\n",
      "batch time cost: 5.258951902389526\n",
      "Epoch: 0, batch: 2019\n",
      "loss None\n",
      "batch time cost: 6.278890132904053\n",
      "Epoch: 0, batch: 2020\n",
      "loss None\n",
      "batch time cost: 6.039069890975952\n",
      "Relu Train Epoch: 0 [129280/318582 (0%)]\tLoss: 0.880151\n",
      "Epoch: 0, batch: 2021\n",
      "loss None\n",
      "batch time cost: 5.331143856048584\n",
      "Epoch: 0, batch: 2022\n",
      "loss None\n",
      "batch time cost: 5.338395833969116\n",
      "Epoch: 0, batch: 2023\n",
      "loss None\n",
      "batch time cost: 5.263302803039551\n",
      "Epoch: 0, batch: 2024\n",
      "loss None\n",
      "batch time cost: 5.296143054962158\n",
      "Epoch: 0, batch: 2025\n",
      "loss None\n",
      "batch time cost: 5.26232123374939\n",
      "Epoch: 0, batch: 2026\n",
      "loss None\n",
      "batch time cost: 6.479579210281372\n",
      "Epoch: 0, batch: 2027\n",
      "loss None\n",
      "batch time cost: 6.870789051055908\n",
      "Epoch: 0, batch: 2028\n",
      "loss None\n",
      "batch time cost: 7.151205062866211\n",
      "Epoch: 0, batch: 2029\n",
      "loss None\n",
      "batch time cost: 5.317751884460449\n",
      "Epoch: 0, batch: 2030\n",
      "loss None\n",
      "batch time cost: 5.2934088706970215\n",
      "Relu Train Epoch: 0 [129920/318582 (0%)]\tLoss: 0.926888\n",
      "Epoch: 0, batch: 2031\n",
      "loss None\n",
      "batch time cost: 5.280375957489014\n",
      "Epoch: 0, batch: 2032\n",
      "loss None\n",
      "batch time cost: 5.250664949417114\n",
      "Epoch: 0, batch: 2033\n",
      "loss None\n",
      "batch time cost: 5.205595970153809\n",
      "Epoch: 0, batch: 2034\n",
      "loss None\n",
      "batch time cost: 7.462965965270996\n",
      "Epoch: 0, batch: 2035\n",
      "loss None\n",
      "batch time cost: 7.56612491607666\n",
      "Epoch: 0, batch: 2036\n",
      "loss None\n",
      "batch time cost: 6.985224008560181\n",
      "Epoch: 0, batch: 2037\n",
      "loss None\n",
      "batch time cost: 5.604077100753784\n",
      "Epoch: 0, batch: 2038\n",
      "loss None\n",
      "batch time cost: 6.875468015670776\n",
      "Epoch: 0, batch: 2039\n",
      "loss None\n",
      "batch time cost: 6.545616149902344\n",
      "Epoch: 0, batch: 2040\n",
      "loss None\n",
      "batch time cost: 5.58303165435791\n",
      "Relu Train Epoch: 0 [130560/318582 (0%)]\tLoss: 0.965384\n",
      "Epoch: 0, batch: 2041\n",
      "loss None\n",
      "batch time cost: 5.872603178024292\n",
      "Epoch: 0, batch: 2042\n",
      "loss None\n",
      "batch time cost: 5.475886106491089\n",
      "Epoch: 0, batch: 2043\n",
      "loss None\n",
      "batch time cost: 5.545117139816284\n",
      "Epoch: 0, batch: 2044\n",
      "loss None\n",
      "batch time cost: 5.767954349517822\n",
      "Epoch: 0, batch: 2045\n",
      "loss None\n",
      "batch time cost: 5.3045361042022705\n",
      "Epoch: 0, batch: 2046\n",
      "loss None\n",
      "batch time cost: 5.28815484046936\n",
      "Epoch: 0, batch: 2047\n",
      "loss None\n",
      "batch time cost: 5.453397989273071\n",
      "Epoch: 0, batch: 2048\n",
      "loss None\n",
      "batch time cost: 5.612030982971191\n",
      "Epoch: 0, batch: 2049\n",
      "loss None\n",
      "batch time cost: 5.261675119400024\n",
      "Epoch: 0, batch: 2050\n",
      "loss None\n",
      "batch time cost: 5.282402038574219\n",
      "Relu Train Epoch: 0 [131200/318582 (0%)]\tLoss: 0.921535\n",
      "Epoch: 0, batch: 2051\n",
      "loss None\n",
      "batch time cost: 5.369499921798706\n",
      "Epoch: 0, batch: 2052\n",
      "loss None\n",
      "batch time cost: 5.368715047836304\n",
      "Epoch: 0, batch: 2053\n",
      "loss None\n",
      "batch time cost: 5.246224880218506\n",
      "Epoch: 0, batch: 2054\n",
      "loss None\n",
      "batch time cost: 5.284704923629761\n",
      "Epoch: 0, batch: 2055\n",
      "loss None\n",
      "batch time cost: 5.669604063034058\n",
      "Epoch: 0, batch: 2056\n",
      "loss None\n",
      "batch time cost: 5.346020936965942\n",
      "Epoch: 0, batch: 2057\n",
      "loss None\n",
      "batch time cost: 5.261283874511719\n",
      "Epoch: 0, batch: 2058\n",
      "loss None\n",
      "batch time cost: 5.261244058609009\n",
      "Epoch: 0, batch: 2059\n",
      "loss None\n",
      "batch time cost: 5.332669019699097\n",
      "Epoch: 0, batch: 2060\n",
      "loss None\n",
      "batch time cost: 5.309356927871704\n",
      "Relu Train Epoch: 0 [131840/318582 (0%)]\tLoss: 0.745828\n",
      "Epoch: 0, batch: 2061\n",
      "loss None\n",
      "batch time cost: 5.299721002578735\n",
      "Epoch: 0, batch: 2062\n",
      "loss None\n",
      "batch time cost: 5.36181902885437\n",
      "Epoch: 0, batch: 2063\n",
      "loss None\n",
      "batch time cost: 6.131109952926636\n",
      "Epoch: 0, batch: 2064\n",
      "loss None\n",
      "batch time cost: 5.346728086471558\n",
      "Epoch: 0, batch: 2065\n",
      "loss None\n",
      "batch time cost: 5.249135255813599\n",
      "Epoch: 0, batch: 2066\n",
      "loss None\n",
      "batch time cost: 5.313627004623413\n",
      "Epoch: 0, batch: 2067\n",
      "loss None\n",
      "batch time cost: 5.2811479568481445\n",
      "Epoch: 0, batch: 2068\n",
      "loss None\n",
      "batch time cost: 5.302666902542114\n",
      "Epoch: 0, batch: 2069\n",
      "loss None\n",
      "batch time cost: 5.316317796707153\n",
      "Epoch: 0, batch: 2070\n",
      "loss None\n",
      "batch time cost: 6.087757110595703\n",
      "Relu Train Epoch: 0 [132480/318582 (0%)]\tLoss: 0.902221\n",
      "Epoch: 0, batch: 2071\n",
      "loss None\n",
      "batch time cost: 5.35810399055481\n",
      "Epoch: 0, batch: 2072\n",
      "loss None\n",
      "batch time cost: 5.266196966171265\n",
      "Epoch: 0, batch: 2073\n",
      "loss None\n",
      "batch time cost: 5.271660804748535\n",
      "Epoch: 0, batch: 2074\n",
      "loss None\n",
      "batch time cost: 5.246697902679443\n",
      "Epoch: 0, batch: 2075\n",
      "loss None\n",
      "batch time cost: 5.203948974609375\n",
      "Epoch: 0, batch: 2076\n",
      "loss None\n",
      "batch time cost: 5.2653210163116455\n",
      "Epoch: 0, batch: 2077\n",
      "loss None\n",
      "batch time cost: 6.240186929702759\n",
      "Epoch: 0, batch: 2078\n",
      "loss None\n",
      "batch time cost: 5.5050950050354\n",
      "Epoch: 0, batch: 2079\n",
      "loss None\n",
      "batch time cost: 5.3739330768585205\n",
      "Epoch: 0, batch: 2080\n",
      "loss None\n",
      "batch time cost: 5.307139873504639\n",
      "Relu Train Epoch: 0 [133120/318582 (0%)]\tLoss: 0.683218\n",
      "Epoch: 0, batch: 2081\n",
      "loss None\n",
      "batch time cost: 5.346143960952759\n",
      "Epoch: 0, batch: 2082\n",
      "loss None\n",
      "batch time cost: 5.321703910827637\n",
      "Epoch: 0, batch: 2083\n",
      "loss None\n",
      "batch time cost: 5.263512134552002\n",
      "Epoch: 0, batch: 2084\n",
      "loss None\n",
      "batch time cost: 5.61862587928772\n",
      "Epoch: 0, batch: 2085\n",
      "loss None\n",
      "batch time cost: 5.421331882476807\n",
      "Epoch: 0, batch: 2086\n",
      "loss None\n",
      "batch time cost: 5.3657989501953125\n",
      "Epoch: 0, batch: 2087\n",
      "loss None\n",
      "batch time cost: 5.285041809082031\n",
      "Epoch: 0, batch: 2088\n",
      "loss None\n",
      "batch time cost: 5.314043045043945\n",
      "Epoch: 0, batch: 2089\n",
      "loss None\n",
      "batch time cost: 5.282736778259277\n",
      "Epoch: 0, batch: 2090\n",
      "loss None\n",
      "batch time cost: 5.2630391120910645\n",
      "Relu Train Epoch: 0 [133760/318582 (0%)]\tLoss: 0.942536\n",
      "Epoch: 0, batch: 2091\n",
      "loss None\n",
      "batch time cost: 5.6949992179870605\n",
      "Epoch: 0, batch: 2092\n",
      "loss None\n",
      "batch time cost: 5.636246681213379\n",
      "Epoch: 0, batch: 2093\n",
      "loss None\n",
      "batch time cost: 5.608045816421509\n",
      "Epoch: 0, batch: 2094\n",
      "loss None\n",
      "batch time cost: 5.321433067321777\n",
      "Epoch: 0, batch: 2095\n",
      "loss None\n",
      "batch time cost: 5.342807054519653\n",
      "Epoch: 0, batch: 2096\n",
      "loss None\n",
      "batch time cost: 5.318011045455933\n",
      "Epoch: 0, batch: 2097\n",
      "loss None\n",
      "batch time cost: 5.260326147079468\n",
      "Epoch: 0, batch: 2098\n",
      "loss None\n",
      "batch time cost: 5.244280099868774\n",
      "Epoch: 0, batch: 2099\n",
      "loss None\n",
      "batch time cost: 5.630499839782715\n",
      "Epoch: 0, batch: 2100\n",
      "loss None\n",
      "batch time cost: 5.342231750488281\n",
      "Relu Train Epoch: 0 [134400/318582 (0%)]\tLoss: 0.820584\n",
      "Epoch: 0, batch: 2101\n",
      "loss None\n",
      "batch time cost: 5.314192056655884\n",
      "Epoch: 0, batch: 2102\n",
      "loss None\n",
      "batch time cost: 5.229885816574097\n",
      "Epoch: 0, batch: 2103\n",
      "loss None\n",
      "batch time cost: 5.329138278961182\n",
      "Epoch: 0, batch: 2104\n",
      "loss None\n",
      "batch time cost: 5.278608083724976\n",
      "Epoch: 0, batch: 2105\n",
      "loss None\n",
      "batch time cost: 5.263227224349976\n",
      "Epoch: 0, batch: 2106\n",
      "loss None\n",
      "batch time cost: 7.299539089202881\n",
      "Epoch: 0, batch: 2107\n",
      "loss None\n",
      "batch time cost: 6.569244146347046\n",
      "Epoch: 0, batch: 2108\n",
      "loss None\n",
      "batch time cost: 6.004359245300293\n",
      "Epoch: 0, batch: 2109\n",
      "loss None\n",
      "batch time cost: 5.93951678276062\n",
      "Epoch: 0, batch: 2110\n",
      "loss None\n",
      "batch time cost: 5.3210906982421875\n",
      "Relu Train Epoch: 0 [135040/318582 (0%)]\tLoss: 0.811968\n",
      "Epoch: 0, batch: 2111\n",
      "loss None\n",
      "batch time cost: 5.334342002868652\n",
      "Epoch: 0, batch: 2112\n",
      "loss None\n",
      "batch time cost: 5.323472023010254\n",
      "Epoch: 0, batch: 2113\n",
      "loss None\n",
      "batch time cost: 6.490411043167114\n",
      "Epoch: 0, batch: 2114\n",
      "loss None\n",
      "batch time cost: 6.00917387008667\n",
      "Epoch: 0, batch: 2115\n",
      "loss None\n",
      "batch time cost: 5.326493263244629\n",
      "Epoch: 0, batch: 2116\n",
      "loss None\n",
      "batch time cost: 5.2702317237854\n",
      "Epoch: 0, batch: 2117\n",
      "loss None\n",
      "batch time cost: 5.300218820571899\n",
      "Epoch: 0, batch: 2118\n",
      "loss None\n",
      "batch time cost: 5.255154132843018\n",
      "Epoch: 0, batch: 2119\n",
      "loss None\n",
      "batch time cost: 5.2817223072052\n",
      "Epoch: 0, batch: 2120\n",
      "loss None\n",
      "batch time cost: 5.658663988113403\n",
      "Relu Train Epoch: 0 [135680/318582 (0%)]\tLoss: 0.792024\n",
      "Epoch: 0, batch: 2121\n",
      "loss None\n",
      "batch time cost: 5.328076124191284\n",
      "Epoch: 0, batch: 2122\n",
      "loss None\n",
      "batch time cost: 5.275454044342041\n",
      "Epoch: 0, batch: 2123\n",
      "loss None\n",
      "batch time cost: 5.2587950229644775\n",
      "Epoch: 0, batch: 2124\n",
      "loss None\n",
      "batch time cost: 5.580063104629517\n",
      "Epoch: 0, batch: 2125\n",
      "loss None\n",
      "batch time cost: 5.301338195800781\n",
      "Epoch: 0, batch: 2126\n",
      "loss None\n",
      "batch time cost: 5.285025119781494\n",
      "Epoch: 0, batch: 2127\n",
      "loss None\n",
      "batch time cost: 5.33315896987915\n",
      "Epoch: 0, batch: 2128\n",
      "loss None\n",
      "batch time cost: 5.70741605758667\n",
      "Epoch: 0, batch: 2129\n",
      "loss None\n",
      "batch time cost: 5.2699949741363525\n",
      "Epoch: 0, batch: 2130\n",
      "loss None\n",
      "batch time cost: 5.25948691368103\n",
      "Relu Train Epoch: 0 [136320/318582 (0%)]\tLoss: 0.872150\n",
      "Epoch: 0, batch: 2131\n",
      "loss None\n",
      "batch time cost: 5.222908973693848\n",
      "Epoch: 0, batch: 2132\n",
      "loss None\n",
      "batch time cost: 5.227630138397217\n",
      "Epoch: 0, batch: 2133\n",
      "loss None\n",
      "batch time cost: 5.315377950668335\n",
      "Epoch: 0, batch: 2134\n",
      "loss None\n",
      "batch time cost: 5.308204889297485\n",
      "Epoch: 0, batch: 2135\n",
      "loss None\n",
      "batch time cost: 7.617854356765747\n",
      "Epoch: 0, batch: 2136\n",
      "loss None\n",
      "batch time cost: 5.278537273406982\n",
      "Epoch: 0, batch: 2137\n",
      "loss None\n",
      "batch time cost: 5.260601758956909\n",
      "Epoch: 0, batch: 2138\n",
      "loss None\n",
      "batch time cost: 5.274933099746704\n",
      "Epoch: 0, batch: 2139\n",
      "loss None\n",
      "batch time cost: 5.260197162628174\n",
      "Epoch: 0, batch: 2140\n",
      "loss None\n",
      "batch time cost: 5.302145004272461\n",
      "Relu Train Epoch: 0 [136960/318582 (0%)]\tLoss: 0.757716\n",
      "Epoch: 0, batch: 2141\n",
      "loss None\n",
      "batch time cost: 5.29736590385437\n",
      "Epoch: 0, batch: 2142\n",
      "loss None\n",
      "batch time cost: 6.057041168212891\n",
      "Epoch: 0, batch: 2143\n",
      "loss None\n",
      "batch time cost: 6.043367147445679\n",
      "Epoch: 0, batch: 2144\n",
      "loss None\n",
      "batch time cost: 7.464179992675781\n",
      "Epoch: 0, batch: 2145\n",
      "loss None\n",
      "batch time cost: 5.924600124359131\n",
      "Epoch: 0, batch: 2146\n",
      "loss None\n",
      "batch time cost: 6.0097339153289795\n",
      "Epoch: 0, batch: 2147\n",
      "loss None\n",
      "batch time cost: 5.318782091140747\n",
      "Epoch: 0, batch: 2148\n",
      "loss None\n",
      "batch time cost: 5.347280263900757\n",
      "Epoch: 0, batch: 2149\n",
      "loss None\n",
      "batch time cost: 5.744418144226074\n",
      "Epoch: 0, batch: 2150\n",
      "loss None\n",
      "batch time cost: 5.360599040985107\n",
      "Relu Train Epoch: 0 [137600/318582 (0%)]\tLoss: 0.795324\n",
      "Epoch: 0, batch: 2151\n",
      "loss None\n",
      "batch time cost: 5.329210996627808\n",
      "Epoch: 0, batch: 2152\n",
      "loss None\n",
      "batch time cost: 5.285210132598877\n",
      "Epoch: 0, batch: 2153\n",
      "loss None\n",
      "batch time cost: 5.2310919761657715\n",
      "Epoch: 0, batch: 2154\n",
      "loss None\n",
      "batch time cost: 5.180840969085693\n",
      "Epoch: 0, batch: 2155\n",
      "loss None\n",
      "batch time cost: 5.328293800354004\n",
      "Epoch: 0, batch: 2156\n",
      "loss None\n",
      "batch time cost: 6.051148891448975\n",
      "Epoch: 0, batch: 2157\n",
      "loss None\n",
      "batch time cost: 5.4615349769592285\n",
      "Epoch: 0, batch: 2158\n",
      "loss None\n",
      "batch time cost: 5.607533693313599\n",
      "Epoch: 0, batch: 2159\n",
      "loss None\n",
      "batch time cost: 5.294601917266846\n",
      "Epoch: 0, batch: 2160\n",
      "loss None\n",
      "batch time cost: 5.718877077102661\n",
      "Relu Train Epoch: 0 [138240/318582 (0%)]\tLoss: 0.862866\n",
      "Epoch: 0, batch: 2161\n",
      "loss None\n",
      "batch time cost: 5.364576816558838\n",
      "Epoch: 0, batch: 2162\n",
      "loss None\n",
      "batch time cost: 5.340472936630249\n",
      "Epoch: 0, batch: 2163\n",
      "loss None\n",
      "batch time cost: 5.292251110076904\n",
      "Epoch: 0, batch: 2164\n",
      "loss None\n",
      "batch time cost: 5.677516937255859\n",
      "Epoch: 0, batch: 2165\n",
      "loss None\n",
      "batch time cost: 5.324427843093872\n",
      "Epoch: 0, batch: 2166\n",
      "loss None\n",
      "batch time cost: 5.316763877868652\n",
      "Epoch: 0, batch: 2167\n",
      "loss None\n",
      "batch time cost: 5.311033010482788\n",
      "Epoch: 0, batch: 2168\n",
      "loss None\n",
      "batch time cost: 5.26511812210083\n",
      "Epoch: 0, batch: 2169\n",
      "loss None\n",
      "batch time cost: 5.279863119125366\n",
      "Epoch: 0, batch: 2170\n",
      "loss None\n",
      "batch time cost: 5.255702972412109\n",
      "Relu Train Epoch: 0 [138880/318582 (0%)]\tLoss: 0.768341\n",
      "Epoch: 0, batch: 2171\n",
      "loss None\n",
      "batch time cost: 5.7997119426727295\n",
      "Epoch: 0, batch: 2172\n",
      "loss None\n",
      "batch time cost: 5.324051141738892\n",
      "Epoch: 0, batch: 2173\n",
      "loss None\n",
      "batch time cost: 5.405205965042114\n",
      "Epoch: 0, batch: 2174\n",
      "loss None\n",
      "batch time cost: 5.3171961307525635\n",
      "Epoch: 0, batch: 2175\n",
      "loss None\n",
      "batch time cost: 5.367186069488525\n",
      "Epoch: 0, batch: 2176\n",
      "loss None\n",
      "batch time cost: 5.294869899749756\n",
      "Epoch: 0, batch: 2177\n",
      "loss None\n",
      "batch time cost: 5.252954721450806\n",
      "Epoch: 0, batch: 2178\n",
      "loss None\n",
      "batch time cost: 5.606489896774292\n",
      "Epoch: 0, batch: 2179\n",
      "loss None\n",
      "batch time cost: 5.474259853363037\n",
      "Epoch: 0, batch: 2180\n",
      "loss None\n",
      "batch time cost: 5.327533960342407\n",
      "Relu Train Epoch: 0 [139520/318582 (0%)]\tLoss: 0.950772\n",
      "Epoch: 0, batch: 2181\n",
      "loss None\n",
      "batch time cost: 5.31040096282959\n",
      "Epoch: 0, batch: 2182\n",
      "loss None\n",
      "batch time cost: 5.287480115890503\n",
      "Epoch: 0, batch: 2183\n",
      "loss None\n",
      "batch time cost: 5.253327131271362\n",
      "Epoch: 0, batch: 2184\n",
      "loss None\n",
      "batch time cost: 5.222724199295044\n",
      "Epoch: 0, batch: 2185\n",
      "loss None\n",
      "batch time cost: 5.6499762535095215\n",
      "Epoch: 0, batch: 2186\n",
      "loss None\n",
      "batch time cost: 5.290754795074463\n",
      "Epoch: 0, batch: 2187\n",
      "loss None\n",
      "batch time cost: 5.293769836425781\n",
      "Epoch: 0, batch: 2188\n",
      "loss None\n",
      "batch time cost: 5.379974842071533\n",
      "Epoch: 0, batch: 2189\n",
      "loss None\n",
      "batch time cost: 5.3506858348846436\n",
      "Epoch: 0, batch: 2190\n",
      "loss None\n",
      "batch time cost: 5.311721086502075\n",
      "Relu Train Epoch: 0 [140160/318582 (0%)]\tLoss: 0.757881\n",
      "Epoch: 0, batch: 2191\n",
      "loss None\n",
      "batch time cost: 5.2474753856658936\n",
      "Epoch: 0, batch: 2192\n",
      "loss None\n",
      "batch time cost: 5.239728927612305\n",
      "Epoch: 0, batch: 2193\n",
      "loss None\n",
      "batch time cost: 7.784295082092285\n",
      "Epoch: 0, batch: 2194\n",
      "loss None\n",
      "batch time cost: 7.568166017532349\n",
      "Epoch: 0, batch: 2195\n",
      "loss None\n",
      "batch time cost: 5.976594924926758\n",
      "Epoch: 0, batch: 2196\n",
      "loss None\n",
      "batch time cost: 6.074083089828491\n",
      "Epoch: 0, batch: 2197\n",
      "loss None\n",
      "batch time cost: 5.835363864898682\n",
      "Epoch: 0, batch: 2198\n",
      "loss None\n",
      "batch time cost: 5.620888948440552\n",
      "Epoch: 0, batch: 2199\n",
      "loss None\n",
      "batch time cost: 5.3449060916900635\n",
      "Epoch: 0, batch: 2200\n",
      "loss None\n",
      "batch time cost: 5.703849792480469\n",
      "Relu Train Epoch: 0 [140800/318582 (0%)]\tLoss: 0.784978\n",
      "Epoch: 0, batch: 2201\n",
      "loss None\n",
      "batch time cost: 5.302528142929077\n",
      "Epoch: 0, batch: 2202\n",
      "loss None\n",
      "batch time cost: 5.250787258148193\n",
      "Epoch: 0, batch: 2203\n",
      "loss None\n",
      "batch time cost: 5.242431879043579\n",
      "Epoch: 0, batch: 2204\n",
      "loss None\n",
      "batch time cost: 5.275629043579102\n",
      "Epoch: 0, batch: 2205\n",
      "loss None\n",
      "batch time cost: 5.227736234664917\n",
      "Epoch: 0, batch: 2206\n",
      "loss None\n",
      "batch time cost: 5.251334190368652\n",
      "Epoch: 0, batch: 2207\n",
      "loss None\n",
      "batch time cost: 5.729101896286011\n",
      "Epoch: 0, batch: 2208\n",
      "loss None\n",
      "batch time cost: 5.461383819580078\n",
      "Epoch: 0, batch: 2209\n",
      "loss None\n",
      "batch time cost: 5.914366960525513\n",
      "Epoch: 0, batch: 2210\n",
      "loss None\n",
      "batch time cost: 5.935486793518066\n",
      "Relu Train Epoch: 0 [141440/318582 (0%)]\tLoss: 0.730935\n",
      "Epoch: 0, batch: 2211\n",
      "loss None\n",
      "batch time cost: 5.766073942184448\n",
      "Epoch: 0, batch: 2212\n",
      "loss None\n",
      "batch time cost: 5.840728759765625\n",
      "Epoch: 0, batch: 2213\n",
      "loss None\n",
      "batch time cost: 5.312281131744385\n",
      "Epoch: 0, batch: 2214\n",
      "loss None\n",
      "batch time cost: 5.683212995529175\n",
      "Epoch: 0, batch: 2215\n",
      "loss None\n",
      "batch time cost: 5.312720775604248\n",
      "Epoch: 0, batch: 2216\n",
      "loss None\n",
      "batch time cost: 5.27686619758606\n",
      "Epoch: 0, batch: 2217\n",
      "loss None\n",
      "batch time cost: 5.304098129272461\n",
      "Epoch: 0, batch: 2218\n",
      "loss None\n",
      "batch time cost: 5.267221689224243\n",
      "Epoch: 0, batch: 2219\n",
      "loss None\n",
      "batch time cost: 5.269605875015259\n",
      "Epoch: 0, batch: 2220\n",
      "loss None\n",
      "batch time cost: 5.2356040477752686\n",
      "Relu Train Epoch: 0 [142080/318582 (0%)]\tLoss: 0.813478\n",
      "Epoch: 0, batch: 2221\n",
      "loss None\n",
      "batch time cost: 5.618481159210205\n",
      "Epoch: 0, batch: 2222\n",
      "loss None\n",
      "batch time cost: 5.341115951538086\n",
      "Epoch: 0, batch: 2223\n",
      "loss None\n",
      "batch time cost: 5.3177759647369385\n",
      "Epoch: 0, batch: 2224\n",
      "loss None\n",
      "batch time cost: 5.293220043182373\n",
      "Epoch: 0, batch: 2225\n",
      "loss None\n",
      "batch time cost: 5.292748212814331\n",
      "Epoch: 0, batch: 2226\n",
      "loss None\n",
      "batch time cost: 5.24118185043335\n",
      "Epoch: 0, batch: 2227\n",
      "loss None\n",
      "batch time cost: 5.241047143936157\n",
      "Epoch: 0, batch: 2228\n",
      "loss None\n",
      "batch time cost: 5.212513208389282\n",
      "Epoch: 0, batch: 2229\n",
      "loss None\n",
      "batch time cost: 5.612648963928223\n",
      "Epoch: 0, batch: 2230\n",
      "loss None\n",
      "batch time cost: 5.312525987625122\n",
      "Relu Train Epoch: 0 [142720/318582 (0%)]\tLoss: 0.749991\n",
      "Epoch: 0, batch: 2231\n",
      "loss None\n",
      "batch time cost: 5.333378791809082\n",
      "Epoch: 0, batch: 2232\n",
      "loss None\n",
      "batch time cost: 5.841617107391357\n",
      "Epoch: 0, batch: 2233\n",
      "loss None\n",
      "batch time cost: 5.340467929840088\n",
      "Epoch: 0, batch: 2234\n",
      "loss None\n",
      "batch time cost: 5.267848014831543\n",
      "Epoch: 0, batch: 2235\n",
      "loss None\n",
      "batch time cost: 5.285821914672852\n",
      "Epoch: 0, batch: 2236\n",
      "loss None\n",
      "batch time cost: 5.6268250942230225\n",
      "Epoch: 0, batch: 2237\n",
      "loss None\n",
      "batch time cost: 5.356317043304443\n",
      "Epoch: 0, batch: 2238\n",
      "loss None\n",
      "batch time cost: 5.248520851135254\n",
      "Epoch: 0, batch: 2239\n",
      "loss None\n",
      "batch time cost: 5.2358598709106445\n",
      "Epoch: 0, batch: 2240\n",
      "loss None\n",
      "batch time cost: 5.232820987701416\n",
      "Relu Train Epoch: 0 [143360/318582 (0%)]\tLoss: 0.818969\n",
      "Epoch: 0, batch: 2241\n",
      "loss None\n",
      "batch time cost: 5.237282991409302\n",
      "Epoch: 0, batch: 2242\n",
      "loss None\n",
      "batch time cost: 5.2472381591796875\n",
      "Epoch: 0, batch: 2243\n",
      "loss None\n",
      "batch time cost: 5.784681081771851\n",
      "Epoch: 0, batch: 2244\n",
      "loss None\n",
      "batch time cost: 6.2444679737091064\n",
      "Epoch: 0, batch: 2245\n",
      "loss None\n",
      "batch time cost: 6.511940240859985\n",
      "Epoch: 0, batch: 2246\n",
      "loss None\n",
      "batch time cost: 5.6365578174591064\n",
      "Epoch: 0, batch: 2247\n",
      "loss None\n",
      "batch time cost: 5.8607261180877686\n",
      "Epoch: 0, batch: 2248\n",
      "loss None\n",
      "batch time cost: 5.373323202133179\n",
      "Epoch: 0, batch: 2249\n",
      "loss None\n",
      "batch time cost: 5.2808239459991455\n",
      "Epoch: 0, batch: 2250\n",
      "loss None\n",
      "batch time cost: 7.573302984237671\n",
      "Relu Train Epoch: 0 [144000/318582 (0%)]\tLoss: 1.047707\n",
      "Epoch: 0, batch: 2251\n",
      "loss None\n",
      "batch time cost: 5.292953968048096\n",
      "Epoch: 0, batch: 2252\n",
      "loss None\n",
      "batch time cost: 5.26951789855957\n",
      "Epoch: 0, batch: 2253\n",
      "loss None\n",
      "batch time cost: 5.3095080852508545\n",
      "Epoch: 0, batch: 2254\n",
      "loss None\n",
      "batch time cost: 5.2628350257873535\n",
      "Epoch: 0, batch: 2255\n",
      "loss None\n",
      "batch time cost: 5.275774002075195\n",
      "Epoch: 0, batch: 2256\n",
      "loss None\n",
      "batch time cost: 5.279038190841675\n",
      "Epoch: 0, batch: 2257\n",
      "loss None\n",
      "batch time cost: 5.238321781158447\n",
      "Epoch: 0, batch: 2258\n",
      "loss None\n",
      "batch time cost: 7.6833391189575195\n",
      "Epoch: 0, batch: 2259\n",
      "loss None\n",
      "batch time cost: 5.702777147293091\n",
      "Epoch: 0, batch: 2260\n",
      "loss None\n",
      "batch time cost: 5.838068962097168\n",
      "Relu Train Epoch: 0 [144640/318582 (0%)]\tLoss: 0.716227\n",
      "Epoch: 0, batch: 2261\n",
      "loss None\n",
      "batch time cost: 5.522814035415649\n",
      "Epoch: 0, batch: 2262\n",
      "loss None\n",
      "batch time cost: 5.319806098937988\n",
      "Epoch: 0, batch: 2263\n",
      "loss None\n",
      "batch time cost: 5.438091993331909\n",
      "Epoch: 0, batch: 2264\n",
      "loss None\n",
      "batch time cost: 5.329251766204834\n",
      "Epoch: 0, batch: 2265\n",
      "loss None\n",
      "batch time cost: 7.452769041061401\n",
      "Epoch: 0, batch: 2266\n",
      "loss None\n",
      "batch time cost: 5.272137880325317\n",
      "Epoch: 0, batch: 2267\n",
      "loss None\n",
      "batch time cost: 5.354843854904175\n",
      "Epoch: 0, batch: 2268\n",
      "loss None\n",
      "batch time cost: 6.794934988021851\n",
      "Epoch: 0, batch: 2269\n",
      "loss None\n",
      "batch time cost: 6.9610371589660645\n",
      "Epoch: 0, batch: 2270\n",
      "loss None\n",
      "batch time cost: 6.653458118438721\n",
      "Relu Train Epoch: 0 [145280/318582 (0%)]\tLoss: 0.845703\n",
      "Epoch: 0, batch: 2271\n",
      "loss None\n",
      "batch time cost: 6.945742845535278\n",
      "Epoch: 0, batch: 2272\n",
      "loss None\n",
      "batch time cost: 8.851643085479736\n",
      "Epoch: 0, batch: 2273\n",
      "loss None\n",
      "batch time cost: 7.200777769088745\n",
      "Epoch: 0, batch: 2274\n",
      "loss None\n",
      "batch time cost: 6.237102746963501\n",
      "Epoch: 0, batch: 2275\n",
      "loss None\n",
      "batch time cost: 5.316493034362793\n",
      "Epoch: 0, batch: 2276\n",
      "loss None\n",
      "batch time cost: 5.2512290477752686\n",
      "Epoch: 0, batch: 2277\n",
      "loss None\n",
      "batch time cost: 5.306313991546631\n",
      "Epoch: 0, batch: 2278\n",
      "loss None\n",
      "batch time cost: 5.3029680252075195\n",
      "Epoch: 0, batch: 2279\n",
      "loss None\n",
      "batch time cost: 5.659118890762329\n",
      "Epoch: 0, batch: 2280\n",
      "loss None\n",
      "batch time cost: 5.265995025634766\n",
      "Relu Train Epoch: 0 [145920/318582 (0%)]\tLoss: 0.723256\n",
      "Epoch: 0, batch: 2281\n",
      "loss None\n",
      "batch time cost: 5.333418130874634\n",
      "Epoch: 0, batch: 2282\n",
      "loss None\n",
      "batch time cost: 5.2932679653167725\n",
      "Epoch: 0, batch: 2283\n",
      "loss None\n",
      "batch time cost: 5.263620853424072\n",
      "Epoch: 0, batch: 2284\n",
      "loss None\n",
      "batch time cost: 5.368969917297363\n",
      "Epoch: 0, batch: 2285\n",
      "loss None\n",
      "batch time cost: 5.827422857284546\n",
      "Epoch: 0, batch: 2286\n",
      "loss None\n",
      "batch time cost: 5.882458925247192\n",
      "Epoch: 0, batch: 2287\n",
      "loss None\n",
      "batch time cost: 5.498589038848877\n",
      "Epoch: 0, batch: 2288\n",
      "loss None\n",
      "batch time cost: 5.373564958572388\n",
      "Epoch: 0, batch: 2289\n",
      "loss None\n",
      "batch time cost: 5.265304088592529\n",
      "Epoch: 0, batch: 2290\n",
      "loss None\n",
      "batch time cost: 5.275537967681885\n",
      "Relu Train Epoch: 0 [146560/318582 (0%)]\tLoss: 0.954432\n",
      "Epoch: 0, batch: 2291\n",
      "loss None\n",
      "batch time cost: 5.276803255081177\n",
      "Epoch: 0, batch: 2292\n",
      "loss None\n",
      "batch time cost: 5.2780327796936035\n",
      "Epoch: 0, batch: 2293\n",
      "loss None\n",
      "batch time cost: 5.302416086196899\n",
      "Epoch: 0, batch: 2294\n",
      "loss None\n",
      "batch time cost: 5.547672986984253\n",
      "Epoch: 0, batch: 2295\n",
      "loss None\n",
      "batch time cost: 5.262861013412476\n",
      "Epoch: 0, batch: 2296\n",
      "loss None\n",
      "batch time cost: 5.33857274055481\n",
      "Epoch: 0, batch: 2297\n",
      "loss None\n",
      "batch time cost: 5.325202941894531\n",
      "Epoch: 0, batch: 2298\n",
      "loss None\n",
      "batch time cost: 5.2551109790802\n",
      "Epoch: 0, batch: 2299\n",
      "loss None\n",
      "batch time cost: 5.223153114318848\n",
      "Epoch: 0, batch: 2300\n",
      "loss None\n",
      "batch time cost: 5.275284290313721\n",
      "Relu Train Epoch: 0 [147200/318582 (0%)]\tLoss: 0.707201\n",
      "Epoch: 0, batch: 2301\n",
      "loss None\n",
      "batch time cost: 5.6421098709106445\n",
      "Epoch: 0, batch: 2302\n",
      "loss None\n",
      "batch time cost: 5.289446115493774\n",
      "Epoch: 0, batch: 2303\n",
      "loss None\n",
      "batch time cost: 5.3123040199279785\n",
      "Epoch: 0, batch: 2304\n",
      "loss None\n",
      "batch time cost: 5.351465940475464\n",
      "Epoch: 0, batch: 2305\n",
      "loss None\n",
      "batch time cost: 5.295277118682861\n",
      "Epoch: 0, batch: 2306\n",
      "loss None\n",
      "batch time cost: 5.231900930404663\n",
      "Epoch: 0, batch: 2307\n",
      "loss None\n",
      "batch time cost: 5.332510948181152\n",
      "Epoch: 0, batch: 2308\n",
      "loss None\n",
      "batch time cost: 7.363739728927612\n",
      "Epoch: 0, batch: 2309\n",
      "loss None\n",
      "batch time cost: 5.858561038970947\n",
      "Epoch: 0, batch: 2310\n",
      "loss None\n",
      "batch time cost: 5.580243110656738\n",
      "Relu Train Epoch: 0 [147840/318582 (0%)]\tLoss: 0.752835\n",
      "Epoch: 0, batch: 2311\n",
      "loss None\n",
      "batch time cost: 5.300565004348755\n",
      "Epoch: 0, batch: 2312\n",
      "loss None\n",
      "batch time cost: 5.258194923400879\n",
      "Epoch: 0, batch: 2313\n",
      "loss None\n",
      "batch time cost: 5.259900808334351\n",
      "Epoch: 0, batch: 2314\n",
      "loss None\n",
      "batch time cost: 5.258362054824829\n",
      "Epoch: 0, batch: 2315\n",
      "loss None\n",
      "batch time cost: 5.652004241943359\n",
      "Epoch: 0, batch: 2316\n",
      "loss None\n",
      "batch time cost: 5.289682865142822\n",
      "Epoch: 0, batch: 2317\n",
      "loss None\n",
      "batch time cost: 5.314821720123291\n",
      "Epoch: 0, batch: 2318\n",
      "loss None\n",
      "batch time cost: 5.323426961898804\n",
      "Epoch: 0, batch: 2319\n",
      "loss None\n",
      "batch time cost: 5.294149875640869\n",
      "Epoch: 0, batch: 2320\n",
      "loss None\n",
      "batch time cost: 5.367475986480713\n",
      "Relu Train Epoch: 0 [148480/318582 (0%)]\tLoss: 0.738717\n",
      "Epoch: 0, batch: 2321\n",
      "loss None\n",
      "batch time cost: 5.331654071807861\n",
      "Epoch: 0, batch: 2322\n",
      "loss None\n",
      "batch time cost: 5.307283163070679\n",
      "Epoch: 0, batch: 2323\n",
      "loss None\n",
      "batch time cost: 5.706498861312866\n",
      "Epoch: 0, batch: 2324\n",
      "loss None\n",
      "batch time cost: 5.626235246658325\n",
      "Epoch: 0, batch: 2325\n",
      "loss None\n",
      "batch time cost: 5.598116874694824\n",
      "Epoch: 0, batch: 2326\n",
      "loss None\n",
      "batch time cost: 5.275373935699463\n",
      "Epoch: 0, batch: 2327\n",
      "loss None\n",
      "batch time cost: 5.276085138320923\n",
      "Epoch: 0, batch: 2328\n",
      "loss None\n",
      "batch time cost: 5.325333118438721\n",
      "Epoch: 0, batch: 2329\n",
      "loss None\n",
      "batch time cost: 5.6362011432647705\n",
      "Epoch: 0, batch: 2330\n",
      "loss None\n",
      "batch time cost: 6.122605800628662\n",
      "Relu Train Epoch: 0 [149120/318582 (0%)]\tLoss: 1.198493\n",
      "Epoch: 0, batch: 2331\n",
      "loss None\n",
      "batch time cost: 5.706731081008911\n",
      "Epoch: 0, batch: 2332\n",
      "loss None\n",
      "batch time cost: 5.3381452560424805\n",
      "Epoch: 0, batch: 2333\n",
      "loss None\n",
      "batch time cost: 5.3056488037109375\n",
      "Epoch: 0, batch: 2334\n",
      "loss None\n",
      "batch time cost: 5.2857911586761475\n",
      "Epoch: 0, batch: 2335\n",
      "loss None\n",
      "batch time cost: 5.260699987411499\n",
      "Epoch: 0, batch: 2336\n",
      "loss None\n",
      "batch time cost: 5.243902921676636\n",
      "Epoch: 0, batch: 2337\n",
      "loss None\n",
      "batch time cost: 5.626441240310669\n",
      "Epoch: 0, batch: 2338\n",
      "loss None\n",
      "batch time cost: 5.320502042770386\n",
      "Epoch: 0, batch: 2339\n",
      "loss None\n",
      "batch time cost: 5.370693206787109\n",
      "Epoch: 0, batch: 2340\n",
      "loss None\n",
      "batch time cost: 5.769733190536499\n",
      "Relu Train Epoch: 0 [149760/318582 (0%)]\tLoss: 0.820242\n",
      "Epoch: 0, batch: 2341\n",
      "loss None\n",
      "batch time cost: 5.355677843093872\n",
      "Epoch: 0, batch: 2342\n",
      "loss None\n",
      "batch time cost: 5.304351806640625\n",
      "Epoch: 0, batch: 2343\n",
      "loss None\n",
      "batch time cost: 5.242830038070679\n",
      "Epoch: 0, batch: 2344\n",
      "loss None\n",
      "batch time cost: 5.628573894500732\n",
      "Epoch: 0, batch: 2345\n",
      "loss None\n",
      "batch time cost: 5.301203966140747\n",
      "Epoch: 0, batch: 2346\n",
      "loss None\n",
      "batch time cost: 5.32492208480835\n",
      "Epoch: 0, batch: 2347\n",
      "loss None\n",
      "batch time cost: 5.348951101303101\n",
      "Epoch: 0, batch: 2348\n",
      "loss None\n",
      "batch time cost: 5.265055894851685\n",
      "Epoch: 0, batch: 2349\n",
      "loss None\n",
      "batch time cost: 5.275696277618408\n",
      "Epoch: 0, batch: 2350\n",
      "loss None\n",
      "batch time cost: 5.287171125411987\n",
      "Relu Train Epoch: 0 [150400/318582 (0%)]\tLoss: 1.009280\n",
      "Epoch: 0, batch: 2351\n",
      "loss None\n",
      "batch time cost: 5.971741199493408\n",
      "Epoch: 0, batch: 2352\n",
      "loss None\n",
      "batch time cost: 5.356674909591675\n",
      "Epoch: 0, batch: 2353\n",
      "loss None\n",
      "batch time cost: 5.284559011459351\n",
      "Epoch: 0, batch: 2354\n",
      "loss None\n",
      "batch time cost: 5.334119081497192\n",
      "Epoch: 0, batch: 2355\n",
      "loss None\n",
      "batch time cost: 5.260600805282593\n",
      "Epoch: 0, batch: 2356\n",
      "loss None\n",
      "batch time cost: 5.287992715835571\n",
      "Epoch: 0, batch: 2357\n",
      "loss None\n",
      "batch time cost: 5.237995862960815\n",
      "Epoch: 0, batch: 2358\n",
      "loss None\n",
      "batch time cost: 5.2833170890808105\n",
      "Epoch: 0, batch: 2359\n",
      "loss None\n",
      "batch time cost: 7.532018184661865\n",
      "Epoch: 0, batch: 2360\n",
      "loss None\n",
      "batch time cost: 7.221736907958984\n",
      "Relu Train Epoch: 0 [151040/318582 (0%)]\tLoss: 0.842522\n",
      "Epoch: 0, batch: 2361\n",
      "loss None\n",
      "batch time cost: 6.740821123123169\n",
      "Epoch: 0, batch: 2362\n",
      "loss None\n",
      "batch time cost: 7.584036111831665\n",
      "Epoch: 0, batch: 2363\n",
      "loss None\n",
      "batch time cost: 5.417825937271118\n",
      "Epoch: 0, batch: 2364\n",
      "loss None\n",
      "batch time cost: 5.2994701862335205\n",
      "Epoch: 0, batch: 2365\n",
      "loss None\n",
      "batch time cost: 5.370226144790649\n",
      "Epoch: 0, batch: 2366\n",
      "loss None\n",
      "batch time cost: 5.701373100280762\n",
      "Epoch: 0, batch: 2367\n",
      "loss None\n",
      "batch time cost: 5.3055739402771\n",
      "Epoch: 0, batch: 2368\n",
      "loss None\n",
      "batch time cost: 5.261378049850464\n",
      "Epoch: 0, batch: 2369\n",
      "loss None\n",
      "batch time cost: 5.29456901550293\n",
      "Epoch: 0, batch: 2370\n",
      "loss None\n",
      "batch time cost: 5.250267744064331\n",
      "Relu Train Epoch: 0 [151680/318582 (0%)]\tLoss: 0.970948\n",
      "Epoch: 0, batch: 2371\n",
      "loss None\n",
      "batch time cost: 5.251029968261719\n",
      "Epoch: 0, batch: 2372\n",
      "loss None\n",
      "batch time cost: 5.286101818084717\n",
      "Epoch: 0, batch: 2373\n",
      "loss None\n",
      "batch time cost: 6.104035139083862\n",
      "Epoch: 0, batch: 2374\n",
      "loss None\n",
      "batch time cost: 5.448585033416748\n",
      "Epoch: 0, batch: 2375\n",
      "loss None\n",
      "batch time cost: 5.4241273403167725\n",
      "Epoch: 0, batch: 2376\n",
      "loss None\n",
      "batch time cost: 5.437238693237305\n",
      "Epoch: 0, batch: 2377\n",
      "loss None\n",
      "batch time cost: 5.314143180847168\n",
      "Epoch: 0, batch: 2378\n",
      "loss None\n",
      "batch time cost: 5.218116044998169\n",
      "Epoch: 0, batch: 2379\n",
      "loss None\n",
      "batch time cost: 5.277582883834839\n",
      "Epoch: 0, batch: 2380\n",
      "loss None\n",
      "batch time cost: 5.781930923461914\n",
      "Relu Train Epoch: 0 [152320/318582 (0%)]\tLoss: 0.765067\n",
      "Epoch: 0, batch: 2381\n",
      "loss None\n",
      "batch time cost: 5.2475221157073975\n",
      "Epoch: 0, batch: 2382\n",
      "loss None\n",
      "batch time cost: 5.301614761352539\n",
      "Epoch: 0, batch: 2383\n",
      "loss None\n",
      "batch time cost: 5.719966173171997\n",
      "Epoch: 0, batch: 2384\n",
      "loss None\n",
      "batch time cost: 5.934384107589722\n",
      "Epoch: 0, batch: 2385\n",
      "loss None\n",
      "batch time cost: 5.280746936798096\n",
      "Epoch: 0, batch: 2386\n",
      "loss None\n",
      "batch time cost: 5.226871013641357\n",
      "Epoch: 0, batch: 2387\n",
      "loss None\n",
      "batch time cost: 5.330507040023804\n",
      "Epoch: 0, batch: 2388\n",
      "loss None\n",
      "batch time cost: 5.623005151748657\n",
      "Epoch: 0, batch: 2389\n",
      "loss None\n",
      "batch time cost: 5.168453931808472\n",
      "Epoch: 0, batch: 2390\n",
      "loss None\n",
      "batch time cost: 5.2692179679870605\n",
      "Relu Train Epoch: 0 [152960/318582 (0%)]\tLoss: 0.837612\n",
      "Epoch: 0, batch: 2391\n",
      "loss None\n",
      "batch time cost: 5.2443461418151855\n",
      "Epoch: 0, batch: 2392\n",
      "loss None\n",
      "batch time cost: 5.2653467655181885\n",
      "Epoch: 0, batch: 2393\n",
      "loss None\n",
      "batch time cost: 5.286919116973877\n",
      "Epoch: 0, batch: 2394\n",
      "loss None\n",
      "batch time cost: 6.0010130405426025\n",
      "Epoch: 0, batch: 2395\n",
      "loss None\n",
      "batch time cost: 6.508150815963745\n",
      "Epoch: 0, batch: 2396\n",
      "loss None\n",
      "batch time cost: 5.764071941375732\n",
      "Epoch: 0, batch: 2397\n",
      "loss None\n",
      "batch time cost: 5.344574928283691\n",
      "Epoch: 0, batch: 2398\n",
      "loss None\n",
      "batch time cost: 5.296708106994629\n",
      "Epoch: 0, batch: 2399\n",
      "loss None\n",
      "batch time cost: 5.283435106277466\n",
      "Epoch: 0, batch: 2400\n",
      "loss None\n",
      "batch time cost: 5.243540048599243\n",
      "Relu Train Epoch: 0 [153600/318582 (0%)]\tLoss: 0.851860\n",
      "Epoch: 0, batch: 2401\n",
      "loss None\n",
      "batch time cost: 5.2652857303619385\n",
      "Epoch: 0, batch: 2402\n",
      "loss None\n",
      "batch time cost: 5.8722920417785645\n",
      "Epoch: 0, batch: 2403\n",
      "loss None\n",
      "batch time cost: 5.600604057312012\n",
      "Epoch: 0, batch: 2404\n",
      "loss None\n",
      "batch time cost: 5.261317014694214\n",
      "Epoch: 0, batch: 2405\n",
      "loss None\n",
      "batch time cost: 5.282786846160889\n",
      "Epoch: 0, batch: 2406\n",
      "loss None\n",
      "batch time cost: 5.252360820770264\n",
      "Epoch: 0, batch: 2407\n",
      "loss None\n",
      "batch time cost: 5.278610944747925\n",
      "Epoch: 0, batch: 2408\n",
      "loss None\n",
      "batch time cost: 5.249371767044067\n",
      "Epoch: 0, batch: 2409\n",
      "loss None\n",
      "batch time cost: 5.749072074890137\n",
      "Epoch: 0, batch: 2410\n",
      "loss None\n",
      "batch time cost: 5.343303918838501\n",
      "Relu Train Epoch: 0 [154240/318582 (0%)]\tLoss: 1.069584\n",
      "Epoch: 0, batch: 2411\n",
      "loss None\n",
      "batch time cost: 5.294100046157837\n",
      "Epoch: 0, batch: 2412\n",
      "loss None\n",
      "batch time cost: 5.309392929077148\n",
      "Epoch: 0, batch: 2413\n",
      "loss None\n",
      "batch time cost: 5.3426549434661865\n",
      "Epoch: 0, batch: 2414\n",
      "loss None\n",
      "batch time cost: 5.296615839004517\n",
      "Epoch: 0, batch: 2415\n",
      "loss None\n",
      "batch time cost: 5.287825107574463\n",
      "Epoch: 0, batch: 2416\n",
      "loss None\n",
      "batch time cost: 6.291614294052124\n",
      "Epoch: 0, batch: 2417\n",
      "loss None\n",
      "batch time cost: 5.613448143005371\n",
      "Epoch: 0, batch: 2418\n",
      "loss None\n",
      "batch time cost: 5.407949686050415\n",
      "Epoch: 0, batch: 2419\n",
      "loss None\n",
      "batch time cost: 5.301290035247803\n",
      "Epoch: 0, batch: 2420\n",
      "loss None\n",
      "batch time cost: 5.382059812545776\n",
      "Relu Train Epoch: 0 [154880/318582 (0%)]\tLoss: 0.882703\n",
      "Epoch: 0, batch: 2421\n",
      "loss None\n",
      "batch time cost: 5.264307022094727\n",
      "Epoch: 0, batch: 2422\n",
      "loss None\n",
      "batch time cost: 5.281357049942017\n",
      "Epoch: 0, batch: 2423\n",
      "loss None\n",
      "batch time cost: 5.222054958343506\n",
      "Epoch: 0, batch: 2424\n",
      "loss None\n",
      "batch time cost: 5.809634685516357\n",
      "Epoch: 0, batch: 2425\n",
      "loss None\n",
      "batch time cost: 5.282973766326904\n",
      "Epoch: 0, batch: 2426\n",
      "loss None\n",
      "batch time cost: 5.263602256774902\n",
      "Epoch: 0, batch: 2427\n",
      "loss None\n",
      "batch time cost: 5.340955972671509\n",
      "Epoch: 0, batch: 2428\n",
      "loss None\n",
      "batch time cost: 7.828336954116821\n",
      "Epoch: 0, batch: 2429\n",
      "loss None\n",
      "batch time cost: 7.462437152862549\n",
      "Epoch: 0, batch: 2430\n",
      "loss None\n",
      "batch time cost: 7.304451942443848\n",
      "Relu Train Epoch: 0 [155520/318582 (0%)]\tLoss: 0.811093\n",
      "Epoch: 0, batch: 2431\n",
      "loss None\n",
      "batch time cost: 7.907253980636597\n",
      "Epoch: 0, batch: 2432\n",
      "loss None\n",
      "batch time cost: 6.661106109619141\n",
      "Epoch: 0, batch: 2433\n",
      "loss None\n",
      "batch time cost: 5.291965961456299\n",
      "Epoch: 0, batch: 2434\n",
      "loss None\n",
      "batch time cost: 5.27341103553772\n",
      "Epoch: 0, batch: 2435\n",
      "loss None\n",
      "batch time cost: 5.306269884109497\n",
      "Epoch: 0, batch: 2436\n",
      "loss None\n",
      "batch time cost: 5.287435054779053\n",
      "Epoch: 0, batch: 2437\n",
      "loss None\n",
      "batch time cost: 5.311818838119507\n",
      "Epoch: 0, batch: 2438\n",
      "loss None\n",
      "batch time cost: 7.998244762420654\n",
      "Epoch: 0, batch: 2439\n",
      "loss None\n",
      "batch time cost: 5.395292043685913\n",
      "Epoch: 0, batch: 2440\n",
      "loss None\n",
      "batch time cost: 5.301285028457642\n",
      "Relu Train Epoch: 0 [156160/318582 (0%)]\tLoss: 0.839797\n",
      "Epoch: 0, batch: 2441\n",
      "loss None\n",
      "batch time cost: 5.299649000167847\n",
      "Epoch: 0, batch: 2442\n",
      "loss None\n",
      "batch time cost: 5.2606542110443115\n",
      "Epoch: 0, batch: 2443\n",
      "loss None\n",
      "batch time cost: 5.238983869552612\n",
      "Epoch: 0, batch: 2444\n",
      "loss None\n",
      "batch time cost: 5.252840995788574\n",
      "Epoch: 0, batch: 2445\n",
      "loss None\n",
      "batch time cost: 5.626657962799072\n",
      "Epoch: 0, batch: 2446\n",
      "loss None\n",
      "batch time cost: 5.31583309173584\n",
      "Epoch: 0, batch: 2447\n",
      "loss None\n",
      "batch time cost: 5.563549041748047\n",
      "Epoch: 0, batch: 2448\n",
      "loss None\n",
      "batch time cost: 5.590128183364868\n",
      "Epoch: 0, batch: 2449\n",
      "loss None\n",
      "batch time cost: 5.308484077453613\n",
      "Epoch: 0, batch: 2450\n",
      "loss None\n",
      "batch time cost: 5.2730700969696045\n",
      "Relu Train Epoch: 0 [156800/318582 (0%)]\tLoss: 0.876751\n",
      "Epoch: 0, batch: 2451\n",
      "loss None\n",
      "batch time cost: 5.308768033981323\n",
      "Epoch: 0, batch: 2452\n",
      "loss None\n",
      "batch time cost: 5.263912916183472\n",
      "Epoch: 0, batch: 2453\n",
      "loss None\n",
      "batch time cost: 5.725407838821411\n",
      "Epoch: 0, batch: 2454\n",
      "loss None\n",
      "batch time cost: 5.303311109542847\n",
      "Epoch: 0, batch: 2455\n",
      "loss None\n",
      "batch time cost: 5.303918838500977\n",
      "Epoch: 0, batch: 2456\n",
      "loss None\n",
      "batch time cost: 5.289802074432373\n",
      "Epoch: 0, batch: 2457\n",
      "loss None\n",
      "batch time cost: 5.302235126495361\n",
      "Epoch: 0, batch: 2458\n",
      "loss None\n",
      "batch time cost: 5.3925158977508545\n",
      "Epoch: 0, batch: 2459\n",
      "loss None\n",
      "batch time cost: 5.26370096206665\n",
      "Epoch: 0, batch: 2460\n",
      "loss None\n",
      "batch time cost: 5.617013931274414\n",
      "Relu Train Epoch: 0 [157440/318582 (0%)]\tLoss: 0.643302\n",
      "Epoch: 0, batch: 2461\n",
      "loss None\n",
      "batch time cost: 5.292987108230591\n",
      "Epoch: 0, batch: 2462\n",
      "loss None\n",
      "batch time cost: 5.3122172355651855\n",
      "Epoch: 0, batch: 2463\n",
      "loss None\n",
      "batch time cost: 5.261396408081055\n",
      "Epoch: 0, batch: 2464\n",
      "loss None\n",
      "batch time cost: 5.369598865509033\n",
      "Epoch: 0, batch: 2465\n",
      "loss None\n",
      "batch time cost: 5.314975023269653\n",
      "Epoch: 0, batch: 2466\n",
      "loss None\n",
      "batch time cost: 5.26093316078186\n",
      "Epoch: 0, batch: 2467\n",
      "loss None\n",
      "batch time cost: 5.642806053161621\n",
      "Epoch: 0, batch: 2468\n",
      "loss None\n",
      "batch time cost: 5.299283981323242\n",
      "Epoch: 0, batch: 2469\n",
      "loss None\n",
      "batch time cost: 5.3005781173706055\n",
      "Epoch: 0, batch: 2470\n",
      "loss None\n",
      "batch time cost: 5.395443916320801\n",
      "Relu Train Epoch: 0 [158080/318582 (0%)]\tLoss: 0.757215\n",
      "Epoch: 0, batch: 2471\n",
      "loss None\n",
      "batch time cost: 5.786379098892212\n",
      "Epoch: 0, batch: 2472\n",
      "loss None\n",
      "batch time cost: 5.320324182510376\n",
      "Epoch: 0, batch: 2473\n",
      "loss None\n",
      "batch time cost: 5.266262054443359\n",
      "Epoch: 0, batch: 2474\n",
      "loss None\n",
      "batch time cost: 5.596486330032349\n",
      "Epoch: 0, batch: 2475\n",
      "loss None\n",
      "batch time cost: 5.2925660610198975\n",
      "Epoch: 0, batch: 2476\n",
      "loss None\n",
      "batch time cost: 5.3725409507751465\n",
      "Epoch: 0, batch: 2477\n",
      "loss None\n",
      "batch time cost: 5.27273964881897\n",
      "Epoch: 0, batch: 2478\n",
      "loss None\n",
      "batch time cost: 5.241734027862549\n",
      "Epoch: 0, batch: 2479\n",
      "loss None\n",
      "batch time cost: 5.259823799133301\n",
      "Epoch: 0, batch: 2480\n",
      "loss None\n",
      "batch time cost: 5.265545129776001\n",
      "Relu Train Epoch: 0 [158720/318582 (0%)]\tLoss: 0.762845\n",
      "Epoch: 0, batch: 2481\n",
      "loss None\n",
      "batch time cost: 6.298488140106201\n",
      "Epoch: 0, batch: 2482\n",
      "loss None\n",
      "batch time cost: 5.6103620529174805\n",
      "Epoch: 0, batch: 2483\n",
      "loss None\n",
      "batch time cost: 5.456089973449707\n",
      "Epoch: 0, batch: 2484\n",
      "loss None\n",
      "batch time cost: 5.34148907661438\n",
      "Epoch: 0, batch: 2485\n",
      "loss None\n",
      "batch time cost: 5.323275089263916\n",
      "Epoch: 0, batch: 2486\n",
      "loss None\n",
      "batch time cost: 5.303040981292725\n",
      "Epoch: 0, batch: 2487\n",
      "loss None\n",
      "batch time cost: 5.281736135482788\n",
      "Epoch: 0, batch: 2488\n",
      "loss None\n",
      "batch time cost: 5.344401121139526\n",
      "Epoch: 0, batch: 2489\n",
      "loss None\n",
      "batch time cost: 5.590347051620483\n",
      "Epoch: 0, batch: 2490\n",
      "loss None\n",
      "batch time cost: 5.300508975982666\n",
      "Relu Train Epoch: 0 [159360/318582 (1%)]\tLoss: 0.667379\n",
      "Epoch: 0, batch: 2491\n",
      "loss None\n",
      "batch time cost: 5.263391017913818\n",
      "Epoch: 0, batch: 2492\n",
      "loss None\n",
      "batch time cost: 5.306682109832764\n",
      "Epoch: 0, batch: 2493\n",
      "loss None\n",
      "batch time cost: 5.404932022094727\n",
      "Epoch: 0, batch: 2494\n",
      "loss None\n",
      "batch time cost: 5.285133123397827\n",
      "Epoch: 0, batch: 2495\n",
      "loss None\n",
      "batch time cost: 5.267196178436279\n",
      "Epoch: 0, batch: 2496\n",
      "loss None\n",
      "batch time cost: 5.771965980529785\n",
      "Epoch: 0, batch: 2497\n",
      "loss None\n",
      "batch time cost: 5.267865896224976\n",
      "Epoch: 0, batch: 2498\n",
      "loss None\n",
      "batch time cost: 5.257388114929199\n",
      "Epoch: 0, batch: 2499\n",
      "loss None\n",
      "batch time cost: 5.278240919113159\n",
      "Epoch: 0, batch: 2500\n",
      "loss None\n",
      "batch time cost: 5.279356002807617\n",
      "Relu Train Epoch: 0 [160000/318582 (1%)]\tLoss: 0.839273\n",
      "Epoch: 0, batch: 2501\n",
      "loss None\n",
      "batch time cost: 5.294007062911987\n",
      "Epoch: 0, batch: 2502\n",
      "loss None\n",
      "batch time cost: 5.278379917144775\n",
      "Epoch: 0, batch: 2503\n",
      "loss None\n",
      "batch time cost: 6.355268955230713\n",
      "Epoch: 0, batch: 2504\n",
      "loss None\n",
      "batch time cost: 5.772835969924927\n",
      "Epoch: 0, batch: 2505\n",
      "loss None\n",
      "batch time cost: 5.371482849121094\n",
      "Epoch: 0, batch: 2506\n",
      "loss None\n",
      "batch time cost: 5.306553840637207\n",
      "Epoch: 0, batch: 2507\n",
      "loss None\n",
      "batch time cost: 5.284492015838623\n",
      "Epoch: 0, batch: 2508\n",
      "loss None\n",
      "batch time cost: 5.299908876419067\n",
      "Epoch: 0, batch: 2509\n",
      "loss None\n",
      "batch time cost: 5.270664930343628\n",
      "Epoch: 0, batch: 2510\n",
      "loss None\n",
      "batch time cost: 5.598830223083496\n",
      "Relu Train Epoch: 0 [160640/318582 (1%)]\tLoss: 0.606400\n",
      "Epoch: 0, batch: 2511\n",
      "loss None\n",
      "batch time cost: 5.269657850265503\n",
      "Epoch: 0, batch: 2512\n",
      "loss None\n",
      "batch time cost: 5.315479040145874\n",
      "Epoch: 0, batch: 2513\n",
      "loss None\n",
      "batch time cost: 5.2311718463897705\n",
      "Epoch: 0, batch: 2514\n",
      "loss None\n",
      "batch time cost: 5.373347997665405\n",
      "Epoch: 0, batch: 2515\n",
      "loss None\n",
      "batch time cost: 5.294020175933838\n",
      "Epoch: 0, batch: 2516\n",
      "loss None\n",
      "batch time cost: 5.2690911293029785\n",
      "Epoch: 0, batch: 2517\n",
      "loss None\n",
      "batch time cost: 5.30675482749939\n",
      "Epoch: 0, batch: 2518\n",
      "loss None\n",
      "batch time cost: 6.1483073234558105\n",
      "Epoch: 0, batch: 2519\n",
      "loss None\n",
      "batch time cost: 5.482288837432861\n",
      "Epoch: 0, batch: 2520\n",
      "loss None\n",
      "batch time cost: 5.275844097137451\n",
      "Relu Train Epoch: 0 [161280/318582 (1%)]\tLoss: 0.883721\n",
      "Epoch: 0, batch: 2521\n",
      "loss None\n",
      "batch time cost: 5.172989845275879\n",
      "Epoch: 0, batch: 2522\n",
      "loss None\n",
      "batch time cost: 5.234960317611694\n",
      "Epoch: 0, batch: 2523\n",
      "loss None\n",
      "batch time cost: 5.311604022979736\n",
      "Epoch: 0, batch: 2524\n",
      "loss None\n",
      "batch time cost: 5.321430921554565\n",
      "Epoch: 0, batch: 2525\n",
      "loss None\n",
      "batch time cost: 6.907073020935059\n",
      "Epoch: 0, batch: 2526\n",
      "loss None\n",
      "batch time cost: 6.037347078323364\n",
      "Epoch: 0, batch: 2527\n",
      "loss None\n",
      "batch time cost: 5.670247793197632\n",
      "Epoch: 0, batch: 2528\n",
      "loss None\n",
      "batch time cost: 5.330296039581299\n",
      "Epoch: 0, batch: 2529\n",
      "loss None\n",
      "batch time cost: 5.27292799949646\n",
      "Epoch: 0, batch: 2530\n",
      "loss None\n",
      "batch time cost: 5.3231728076934814\n",
      "Relu Train Epoch: 0 [161920/318582 (1%)]\tLoss: 0.761826\n",
      "Epoch: 0, batch: 2531\n",
      "loss None\n",
      "batch time cost: 5.355169057846069\n",
      "Epoch: 0, batch: 2532\n",
      "loss None\n",
      "batch time cost: 5.71409797668457\n",
      "Epoch: 0, batch: 2533\n",
      "loss None\n",
      "batch time cost: 5.314548015594482\n",
      "Epoch: 0, batch: 2534\n",
      "loss None\n",
      "batch time cost: 5.357248067855835\n",
      "Epoch: 0, batch: 2535\n",
      "loss None\n",
      "batch time cost: 5.276133060455322\n",
      "Epoch: 0, batch: 2536\n",
      "loss None\n",
      "batch time cost: 5.397099018096924\n",
      "Epoch: 0, batch: 2537\n",
      "loss None\n",
      "batch time cost: 5.2816760540008545\n",
      "Epoch: 0, batch: 2538\n",
      "loss None\n",
      "batch time cost: 5.276144981384277\n",
      "Epoch: 0, batch: 2539\n",
      "loss None\n",
      "batch time cost: 5.929202079772949\n",
      "Epoch: 0, batch: 2540\n",
      "loss None\n",
      "batch time cost: 5.344634056091309\n",
      "Relu Train Epoch: 0 [162560/318582 (1%)]\tLoss: 0.864563\n",
      "Epoch: 0, batch: 2541\n",
      "loss None\n",
      "batch time cost: 5.281795978546143\n",
      "Epoch: 0, batch: 2542\n",
      "loss None\n",
      "batch time cost: 5.282113075256348\n",
      "Epoch: 0, batch: 2543\n",
      "loss None\n",
      "batch time cost: 5.287383794784546\n",
      "Epoch: 0, batch: 2544\n",
      "loss None\n",
      "batch time cost: 5.309417963027954\n",
      "Epoch: 0, batch: 2545\n",
      "loss None\n",
      "batch time cost: 5.316204071044922\n",
      "Epoch: 0, batch: 2546\n",
      "loss None\n",
      "batch time cost: 5.603070974349976\n",
      "Epoch: 0, batch: 2547\n",
      "loss None\n",
      "batch time cost: 7.567223072052002\n",
      "Epoch: 0, batch: 2548\n",
      "loss None\n",
      "batch time cost: 5.3906569480896\n",
      "Epoch: 0, batch: 2549\n",
      "loss None\n",
      "batch time cost: 5.330979108810425\n",
      "Epoch: 0, batch: 2550\n",
      "loss None\n",
      "batch time cost: 5.304815292358398\n",
      "Relu Train Epoch: 0 [163200/318582 (1%)]\tLoss: 0.882222\n",
      "Epoch: 0, batch: 2551\n",
      "loss None\n",
      "batch time cost: 5.267197847366333\n",
      "Epoch: 0, batch: 2552\n",
      "loss None\n",
      "batch time cost: 5.302812099456787\n",
      "Epoch: 0, batch: 2553\n",
      "loss None\n",
      "batch time cost: 5.2688798904418945\n",
      "Epoch: 0, batch: 2554\n",
      "loss None\n",
      "batch time cost: 5.657560110092163\n",
      "Epoch: 0, batch: 2555\n",
      "loss None\n",
      "batch time cost: 5.30325984954834\n",
      "Epoch: 0, batch: 2556\n",
      "loss None\n",
      "batch time cost: 5.327411890029907\n",
      "Epoch: 0, batch: 2557\n",
      "loss None\n",
      "batch time cost: 5.302741050720215\n",
      "Epoch: 0, batch: 2558\n",
      "loss None\n",
      "batch time cost: 5.619412183761597\n",
      "Epoch: 0, batch: 2559\n",
      "loss None\n",
      "batch time cost: 5.324977874755859\n",
      "Epoch: 0, batch: 2560\n",
      "loss None\n",
      "batch time cost: 5.334947109222412\n",
      "Relu Train Epoch: 0 [163840/318582 (1%)]\tLoss: 0.905259\n",
      "Epoch: 0, batch: 2561\n",
      "loss None\n",
      "batch time cost: 5.6143269538879395\n",
      "Epoch: 0, batch: 2562\n",
      "loss None\n",
      "batch time cost: 5.298770189285278\n",
      "Epoch: 0, batch: 2563\n",
      "loss None\n",
      "batch time cost: 5.54643988609314\n",
      "Epoch: 0, batch: 2564\n",
      "loss None\n",
      "batch time cost: 5.333822965621948\n",
      "Epoch: 0, batch: 2565\n",
      "loss None\n",
      "batch time cost: 5.265918970108032\n",
      "Epoch: 0, batch: 2566\n",
      "loss None\n",
      "batch time cost: 5.3174779415130615\n",
      "Epoch: 0, batch: 2567\n",
      "loss None\n",
      "batch time cost: 5.3371357917785645\n",
      "Epoch: 0, batch: 2568\n",
      "loss None\n",
      "batch time cost: 5.661057949066162\n",
      "Epoch: 0, batch: 2569\n",
      "loss None\n",
      "batch time cost: 5.526976108551025\n",
      "Epoch: 0, batch: 2570\n",
      "loss None\n",
      "batch time cost: 5.277225017547607\n",
      "Relu Train Epoch: 0 [164480/318582 (1%)]\tLoss: 0.898906\n",
      "Epoch: 0, batch: 2571\n",
      "loss None\n",
      "batch time cost: 5.344283819198608\n",
      "Epoch: 0, batch: 2572\n",
      "loss None\n",
      "batch time cost: 5.285343885421753\n",
      "Epoch: 0, batch: 2573\n",
      "loss None\n",
      "batch time cost: 5.431438207626343\n",
      "Epoch: 0, batch: 2574\n",
      "loss None\n",
      "batch time cost: 5.2416932582855225\n",
      "Epoch: 0, batch: 2575\n",
      "loss None\n",
      "batch time cost: 5.603476047515869\n",
      "Epoch: 0, batch: 2576\n",
      "loss None\n",
      "batch time cost: 5.329312086105347\n",
      "Epoch: 0, batch: 2577\n",
      "loss None\n",
      "batch time cost: 5.2081968784332275\n",
      "Epoch: 0, batch: 2578\n",
      "loss None\n",
      "batch time cost: 5.290203094482422\n",
      "Epoch: 0, batch: 2579\n",
      "loss None\n",
      "batch time cost: 5.326091051101685\n",
      "Epoch: 0, batch: 2580\n",
      "loss None\n",
      "batch time cost: 5.305233955383301\n",
      "Relu Train Epoch: 0 [165120/318582 (1%)]\tLoss: 0.846306\n",
      "Epoch: 0, batch: 2581\n",
      "loss None\n",
      "batch time cost: 5.30817985534668\n",
      "Epoch: 0, batch: 2582\n",
      "loss None\n",
      "batch time cost: 5.267879962921143\n",
      "Epoch: 0, batch: 2583\n",
      "loss None\n",
      "batch time cost: 6.102709054946899\n",
      "Epoch: 0, batch: 2584\n",
      "loss None\n",
      "batch time cost: 6.73237681388855\n",
      "Epoch: 0, batch: 2585\n",
      "loss None\n",
      "batch time cost: 5.292026996612549\n",
      "Epoch: 0, batch: 2586\n",
      "loss None\n",
      "batch time cost: 5.31463098526001\n",
      "Epoch: 0, batch: 2587\n",
      "loss None\n",
      "batch time cost: 5.338310718536377\n",
      "Epoch: 0, batch: 2588\n",
      "loss None\n",
      "batch time cost: 5.35350489616394\n",
      "Epoch: 0, batch: 2589\n",
      "loss None\n",
      "batch time cost: 5.309741258621216\n",
      "Epoch: 0, batch: 2590\n",
      "loss None\n",
      "batch time cost: 6.226611137390137\n",
      "Relu Train Epoch: 0 [165760/318582 (1%)]\tLoss: 1.070257\n",
      "Epoch: 0, batch: 2591\n",
      "loss None\n",
      "batch time cost: 5.318806171417236\n",
      "Epoch: 0, batch: 2592\n",
      "loss None\n",
      "batch time cost: 5.350561857223511\n",
      "Epoch: 0, batch: 2593\n",
      "loss None\n",
      "batch time cost: 5.251515865325928\n",
      "Epoch: 0, batch: 2594\n",
      "loss None\n",
      "batch time cost: 5.257113218307495\n",
      "Epoch: 0, batch: 2595\n",
      "loss None\n",
      "batch time cost: 5.221803903579712\n",
      "Epoch: 0, batch: 2596\n",
      "loss None\n",
      "batch time cost: 5.239242076873779\n",
      "Epoch: 0, batch: 2597\n",
      "loss None\n",
      "batch time cost: 5.967501878738403\n",
      "Epoch: 0, batch: 2598\n",
      "loss None\n",
      "batch time cost: 5.45776104927063\n",
      "Epoch: 0, batch: 2599\n",
      "loss None\n",
      "batch time cost: 5.748162031173706\n",
      "Epoch: 0, batch: 2600\n",
      "loss None\n",
      "batch time cost: 5.397423982620239\n",
      "Relu Train Epoch: 0 [166400/318582 (1%)]\tLoss: 0.995339\n",
      "Epoch: 0, batch: 2601\n",
      "loss None\n",
      "batch time cost: 5.40565299987793\n",
      "Epoch: 0, batch: 2602\n",
      "loss None\n",
      "batch time cost: 5.429533958435059\n",
      "Epoch: 0, batch: 2603\n",
      "loss None\n",
      "batch time cost: 5.311131000518799\n",
      "Epoch: 0, batch: 2604\n",
      "loss None\n",
      "batch time cost: 5.713013172149658\n",
      "Epoch: 0, batch: 2605\n",
      "loss None\n",
      "batch time cost: 5.316972970962524\n",
      "Epoch: 0, batch: 2606\n",
      "loss None\n",
      "batch time cost: 5.295953989028931\n",
      "Epoch: 0, batch: 2607\n",
      "loss None\n",
      "batch time cost: 5.262183904647827\n",
      "Epoch: 0, batch: 2608\n",
      "loss None\n",
      "batch time cost: 5.2877912521362305\n",
      "Epoch: 0, batch: 2609\n",
      "loss None\n",
      "batch time cost: 5.329270839691162\n",
      "Epoch: 0, batch: 2610\n",
      "loss None\n",
      "batch time cost: 5.278942346572876\n",
      "Relu Train Epoch: 0 [167040/318582 (1%)]\tLoss: 0.592610\n",
      "Epoch: 0, batch: 2611\n",
      "loss None\n",
      "batch time cost: 5.529011011123657\n",
      "Epoch: 0, batch: 2612\n",
      "loss None\n",
      "batch time cost: 5.238113880157471\n",
      "Epoch: 0, batch: 2613\n",
      "loss None\n",
      "batch time cost: 5.348837852478027\n",
      "Epoch: 0, batch: 2614\n",
      "loss None\n",
      "batch time cost: 5.313990831375122\n",
      "Epoch: 0, batch: 2615\n",
      "loss None\n",
      "batch time cost: 5.3144309520721436\n",
      "Epoch: 0, batch: 2616\n",
      "loss None\n",
      "batch time cost: 5.269644021987915\n",
      "Epoch: 0, batch: 2617\n",
      "loss None\n",
      "batch time cost: 5.217677116394043\n",
      "Epoch: 0, batch: 2618\n",
      "loss None\n",
      "batch time cost: 5.25186824798584\n",
      "Epoch: 0, batch: 2619\n",
      "loss None\n",
      "batch time cost: 6.006605863571167\n",
      "Epoch: 0, batch: 2620\n",
      "loss None\n",
      "batch time cost: 5.503823757171631\n",
      "Relu Train Epoch: 0 [167680/318582 (1%)]\tLoss: 0.782624\n",
      "Epoch: 0, batch: 2621\n",
      "loss None\n",
      "batch time cost: 5.988837003707886\n",
      "Epoch: 0, batch: 2622\n",
      "loss None\n",
      "batch time cost: 5.740484237670898\n",
      "Epoch: 0, batch: 2623\n",
      "loss None\n",
      "batch time cost: 6.909090280532837\n",
      "Epoch: 0, batch: 2624\n",
      "loss None\n",
      "batch time cost: 5.374300003051758\n",
      "Epoch: 0, batch: 2625\n",
      "loss None\n",
      "batch time cost: 5.288856744766235\n",
      "Epoch: 0, batch: 2626\n",
      "loss None\n",
      "batch time cost: 5.639737129211426\n",
      "Epoch: 0, batch: 2627\n",
      "loss None\n",
      "batch time cost: 5.301815032958984\n",
      "Epoch: 0, batch: 2628\n",
      "loss None\n",
      "batch time cost: 5.2781078815460205\n",
      "Epoch: 0, batch: 2629\n",
      "loss None\n",
      "batch time cost: 5.2748072147369385\n",
      "Epoch: 0, batch: 2630\n",
      "loss None\n",
      "batch time cost: 5.21096396446228\n",
      "Relu Train Epoch: 0 [168320/318582 (1%)]\tLoss: 0.732255\n",
      "Epoch: 0, batch: 2631\n",
      "loss None\n",
      "batch time cost: 5.267906665802002\n",
      "Epoch: 0, batch: 2632\n",
      "loss None\n",
      "batch time cost: 5.204257965087891\n",
      "Epoch: 0, batch: 2633\n",
      "loss None\n",
      "batch time cost: 5.756330966949463\n",
      "Epoch: 0, batch: 2634\n",
      "loss None\n",
      "batch time cost: 5.392505645751953\n",
      "Epoch: 0, batch: 2635\n",
      "loss None\n",
      "batch time cost: 5.847941160202026\n",
      "Epoch: 0, batch: 2636\n",
      "loss None\n",
      "batch time cost: 5.635426044464111\n",
      "Epoch: 0, batch: 2637\n",
      "loss None\n",
      "batch time cost: 6.206974983215332\n",
      "Epoch: 0, batch: 2638\n",
      "loss None\n",
      "batch time cost: 7.190118074417114\n",
      "Epoch: 0, batch: 2639\n",
      "loss None\n",
      "batch time cost: 5.349715232849121\n",
      "Epoch: 0, batch: 2640\n",
      "loss None\n",
      "batch time cost: 5.687013149261475\n",
      "Relu Train Epoch: 0 [168960/318582 (1%)]\tLoss: 0.853576\n",
      "Epoch: 0, batch: 2641\n",
      "loss None\n",
      "batch time cost: 5.290019989013672\n",
      "Epoch: 0, batch: 2642\n",
      "loss None\n",
      "batch time cost: 5.228878974914551\n",
      "Epoch: 0, batch: 2643\n",
      "loss None\n",
      "batch time cost: 5.272323846817017\n",
      "Epoch: 0, batch: 2644\n",
      "loss None\n",
      "batch time cost: 5.2691850662231445\n",
      "Epoch: 0, batch: 2645\n",
      "loss None\n",
      "batch time cost: 5.326678991317749\n",
      "Epoch: 0, batch: 2646\n",
      "loss None\n",
      "batch time cost: 5.286777973175049\n",
      "Epoch: 0, batch: 2647\n",
      "loss None\n",
      "batch time cost: 5.23871111869812\n",
      "Epoch: 0, batch: 2648\n",
      "loss None\n",
      "batch time cost: 6.114253997802734\n",
      "Epoch: 0, batch: 2649\n",
      "loss None\n",
      "batch time cost: 5.482797622680664\n",
      "Epoch: 0, batch: 2650\n",
      "loss None\n",
      "batch time cost: 5.380656719207764\n",
      "Relu Train Epoch: 0 [169600/318582 (1%)]\tLoss: 0.747062\n",
      "Epoch: 0, batch: 2651\n",
      "loss None\n",
      "batch time cost: 5.422043085098267\n",
      "Epoch: 0, batch: 2652\n",
      "loss None\n",
      "batch time cost: 5.317670106887817\n",
      "Epoch: 0, batch: 2653\n",
      "loss None\n",
      "batch time cost: 5.293394088745117\n",
      "Epoch: 0, batch: 2654\n",
      "loss None\n",
      "batch time cost: 5.246012926101685\n",
      "Epoch: 0, batch: 2655\n",
      "loss None\n",
      "batch time cost: 5.746075868606567\n",
      "Epoch: 0, batch: 2656\n",
      "loss None\n",
      "batch time cost: 5.317777156829834\n",
      "Epoch: 0, batch: 2657\n",
      "loss None\n",
      "batch time cost: 5.310443878173828\n",
      "Epoch: 0, batch: 2658\n",
      "loss None\n",
      "batch time cost: 5.25360894203186\n",
      "Epoch: 0, batch: 2659\n",
      "loss None\n",
      "batch time cost: 5.248808860778809\n",
      "Epoch: 0, batch: 2660\n",
      "loss None\n",
      "batch time cost: 5.278555870056152\n",
      "Relu Train Epoch: 0 [170240/318582 (1%)]\tLoss: 0.810762\n",
      "Epoch: 0, batch: 2661\n",
      "loss None\n",
      "batch time cost: 5.268525838851929\n",
      "Epoch: 0, batch: 2662\n",
      "loss None\n",
      "batch time cost: 5.668529033660889\n",
      "Epoch: 0, batch: 2663\n",
      "loss None\n",
      "batch time cost: 5.291913032531738\n",
      "Epoch: 0, batch: 2664\n",
      "loss None\n",
      "batch time cost: 5.276949167251587\n",
      "Epoch: 0, batch: 2665\n",
      "loss None\n",
      "batch time cost: 5.254086256027222\n",
      "Epoch: 0, batch: 2666\n",
      "loss None\n",
      "batch time cost: 5.268468856811523\n",
      "Epoch: 0, batch: 2667\n",
      "loss None\n",
      "batch time cost: 5.3197290897369385\n",
      "Epoch: 0, batch: 2668\n",
      "loss None\n",
      "batch time cost: 5.2611000537872314\n",
      "Epoch: 0, batch: 2669\n",
      "loss None\n",
      "batch time cost: 5.655032157897949\n",
      "Epoch: 0, batch: 2670\n",
      "loss None\n",
      "batch time cost: 5.859263896942139\n",
      "Relu Train Epoch: 0 [170880/318582 (1%)]\tLoss: 0.914463\n",
      "Epoch: 0, batch: 2671\n",
      "loss None\n",
      "batch time cost: 6.809129953384399\n",
      "Epoch: 0, batch: 2672\n",
      "loss None\n",
      "batch time cost: 6.6553380489349365\n",
      "Epoch: 0, batch: 2673\n",
      "loss None\n",
      "batch time cost: 5.76963472366333\n",
      "Epoch: 0, batch: 2674\n",
      "loss None\n",
      "batch time cost: 5.581813812255859\n",
      "Epoch: 0, batch: 2675\n",
      "loss None\n",
      "batch time cost: 5.31840181350708\n",
      "Epoch: 0, batch: 2676\n",
      "loss None\n",
      "batch time cost: 5.680298089981079\n",
      "Epoch: 0, batch: 2677\n",
      "loss None\n",
      "batch time cost: 5.329977035522461\n",
      "Epoch: 0, batch: 2678\n",
      "loss None\n",
      "batch time cost: 5.281271696090698\n",
      "Epoch: 0, batch: 2679\n",
      "loss None\n",
      "batch time cost: 5.2645039558410645\n",
      "Epoch: 0, batch: 2680\n",
      "loss None\n",
      "batch time cost: 5.257129192352295\n",
      "Relu Train Epoch: 0 [171520/318582 (1%)]\tLoss: 0.945754\n",
      "Epoch: 0, batch: 2681\n",
      "loss None\n",
      "batch time cost: 5.2280192375183105\n",
      "Epoch: 0, batch: 2682\n",
      "loss None\n",
      "batch time cost: 5.2354350090026855\n",
      "Epoch: 0, batch: 2683\n",
      "loss None\n",
      "batch time cost: 5.277261018753052\n",
      "Epoch: 0, batch: 2684\n",
      "loss None\n",
      "batch time cost: 8.877774953842163\n",
      "Epoch: 0, batch: 2685\n",
      "loss None\n",
      "batch time cost: 6.770382881164551\n",
      "Epoch: 0, batch: 2686\n",
      "loss None\n",
      "batch time cost: 6.99228310585022\n",
      "Epoch: 0, batch: 2687\n",
      "loss None\n",
      "batch time cost: 7.978430986404419\n",
      "Epoch: 0, batch: 2688\n",
      "loss None\n",
      "batch time cost: 8.231724739074707\n",
      "Epoch: 0, batch: 2689\n",
      "loss None\n",
      "batch time cost: 8.334357976913452\n",
      "Epoch: 0, batch: 2690\n",
      "loss None\n",
      "batch time cost: 5.801131963729858\n",
      "Relu Train Epoch: 0 [172160/318582 (1%)]\tLoss: 0.837199\n",
      "Epoch: 0, batch: 2691\n",
      "loss None\n",
      "batch time cost: 5.900578022003174\n",
      "Epoch: 0, batch: 2692\n",
      "loss None\n",
      "batch time cost: 5.900723934173584\n",
      "Epoch: 0, batch: 2693\n",
      "loss None\n",
      "batch time cost: 7.746035814285278\n",
      "Epoch: 0, batch: 2694\n",
      "loss None\n",
      "batch time cost: 6.742680072784424\n",
      "Epoch: 0, batch: 2695\n",
      "loss None\n",
      "batch time cost: 5.894428968429565\n",
      "Epoch: 0, batch: 2696\n",
      "loss None\n",
      "batch time cost: 6.119227886199951\n",
      "Epoch: 0, batch: 2697\n",
      "loss None\n",
      "batch time cost: 7.5494019985198975\n",
      "Epoch: 0, batch: 2698\n",
      "loss None\n",
      "batch time cost: 7.225870847702026\n",
      "Epoch: 0, batch: 2699\n",
      "loss None\n",
      "batch time cost: 5.281394958496094\n",
      "Epoch: 0, batch: 2700\n",
      "loss None\n",
      "batch time cost: 5.242959976196289\n",
      "Relu Train Epoch: 0 [172800/318582 (1%)]\tLoss: 0.749622\n",
      "Epoch: 0, batch: 2701\n",
      "loss None\n",
      "batch time cost: 5.226763010025024\n",
      "Epoch: 0, batch: 2702\n",
      "loss None\n",
      "batch time cost: 5.27144193649292\n",
      "Epoch: 0, batch: 2703\n",
      "loss None\n",
      "batch time cost: 5.246128082275391\n",
      "Epoch: 0, batch: 2704\n",
      "loss None\n",
      "batch time cost: 5.279366731643677\n",
      "Epoch: 0, batch: 2705\n",
      "loss None\n",
      "batch time cost: 7.494001150131226\n",
      "Epoch: 0, batch: 2706\n",
      "loss None\n",
      "batch time cost: 5.827539920806885\n",
      "Epoch: 0, batch: 2707\n",
      "loss None\n",
      "batch time cost: 7.980331659317017\n",
      "Epoch: 0, batch: 2708\n",
      "loss None\n",
      "batch time cost: 7.187937021255493\n",
      "Epoch: 0, batch: 2709\n",
      "loss None\n",
      "batch time cost: 7.189211130142212\n",
      "Epoch: 0, batch: 2710\n",
      "loss None\n",
      "batch time cost: 5.66938591003418\n",
      "Relu Train Epoch: 0 [173440/318582 (1%)]\tLoss: 0.747978\n",
      "Epoch: 0, batch: 2711\n",
      "loss None\n",
      "batch time cost: 5.36234974861145\n",
      "Epoch: 0, batch: 2712\n",
      "loss None\n",
      "batch time cost: 5.274343967437744\n",
      "Epoch: 0, batch: 2713\n",
      "loss None\n",
      "batch time cost: 5.580222845077515\n",
      "Epoch: 0, batch: 2714\n",
      "loss None\n",
      "batch time cost: 5.317337274551392\n",
      "Epoch: 0, batch: 2715\n",
      "loss None\n",
      "batch time cost: 5.2190101146698\n",
      "Epoch: 0, batch: 2716\n",
      "loss None\n",
      "batch time cost: 5.326478004455566\n",
      "Epoch: 0, batch: 2717\n",
      "loss None\n",
      "batch time cost: 5.295993089675903\n",
      "Epoch: 0, batch: 2718\n",
      "loss None\n",
      "batch time cost: 5.30103325843811\n",
      "Epoch: 0, batch: 2719\n",
      "loss None\n",
      "batch time cost: 5.297934293746948\n",
      "Epoch: 0, batch: 2720\n",
      "loss None\n",
      "batch time cost: 5.8005242347717285\n",
      "Relu Train Epoch: 0 [174080/318582 (1%)]\tLoss: 0.780404\n",
      "Epoch: 0, batch: 2721\n",
      "loss None\n",
      "batch time cost: 5.313209295272827\n",
      "Epoch: 0, batch: 2722\n",
      "loss None\n",
      "batch time cost: 5.309351921081543\n",
      "Epoch: 0, batch: 2723\n",
      "loss None\n",
      "batch time cost: 5.386568784713745\n",
      "Epoch: 0, batch: 2724\n",
      "loss None\n",
      "batch time cost: 5.4339048862457275\n",
      "Epoch: 0, batch: 2725\n",
      "loss None\n",
      "batch time cost: 5.311178922653198\n",
      "Epoch: 0, batch: 2726\n",
      "loss None\n",
      "batch time cost: 5.3693108558654785\n",
      "Epoch: 0, batch: 2727\n",
      "loss None\n",
      "batch time cost: 5.611450910568237\n",
      "Epoch: 0, batch: 2728\n",
      "loss None\n",
      "batch time cost: 5.34069299697876\n",
      "Epoch: 0, batch: 2729\n",
      "loss None\n",
      "batch time cost: 5.262493133544922\n",
      "Epoch: 0, batch: 2730\n",
      "loss None\n",
      "batch time cost: 5.287420034408569\n",
      "Relu Train Epoch: 0 [174720/318582 (1%)]\tLoss: 0.606668\n",
      "Epoch: 0, batch: 2731\n",
      "loss None\n",
      "batch time cost: 5.254298210144043\n",
      "Epoch: 0, batch: 2732\n",
      "loss None\n",
      "batch time cost: 5.298301935195923\n",
      "Epoch: 0, batch: 2733\n",
      "loss None\n",
      "batch time cost: 5.277741193771362\n",
      "Epoch: 0, batch: 2734\n",
      "loss None\n",
      "batch time cost: 5.572102069854736\n",
      "Epoch: 0, batch: 2735\n",
      "loss None\n",
      "batch time cost: 5.256324052810669\n",
      "Epoch: 0, batch: 2736\n",
      "loss None\n",
      "batch time cost: 5.336873292922974\n",
      "Epoch: 0, batch: 2737\n",
      "loss None\n",
      "batch time cost: 5.337637901306152\n",
      "Epoch: 0, batch: 2738\n",
      "loss None\n",
      "batch time cost: 5.3360209465026855\n",
      "Epoch: 0, batch: 2739\n",
      "loss None\n",
      "batch time cost: 5.323546886444092\n",
      "Epoch: 0, batch: 2740\n",
      "loss None\n",
      "batch time cost: 5.284757852554321\n",
      "Relu Train Epoch: 0 [175360/318582 (1%)]\tLoss: 0.990319\n",
      "Epoch: 0, batch: 2741\n",
      "loss None\n",
      "batch time cost: 5.997462034225464\n",
      "Epoch: 0, batch: 2742\n",
      "loss None\n",
      "batch time cost: 6.002609014511108\n",
      "Epoch: 0, batch: 2743\n",
      "loss None\n",
      "batch time cost: 6.014976978302002\n",
      "Epoch: 0, batch: 2744\n",
      "loss None\n",
      "batch time cost: 5.384357929229736\n",
      "Epoch: 0, batch: 2745\n",
      "loss None\n",
      "batch time cost: 5.363290071487427\n",
      "Epoch: 0, batch: 2746\n",
      "loss None\n",
      "batch time cost: 5.307066202163696\n",
      "Epoch: 0, batch: 2747\n",
      "loss None\n",
      "batch time cost: 5.268676996231079\n",
      "Epoch: 0, batch: 2748\n",
      "loss None\n",
      "batch time cost: 5.278167009353638\n",
      "Epoch: 0, batch: 2749\n",
      "loss None\n",
      "batch time cost: 5.775289058685303\n",
      "Epoch: 0, batch: 2750\n",
      "loss None\n",
      "batch time cost: 5.573057174682617\n",
      "Relu Train Epoch: 0 [176000/318582 (1%)]\tLoss: 0.896403\n",
      "Epoch: 0, batch: 2751\n",
      "loss None\n",
      "batch time cost: 5.406639099121094\n",
      "Epoch: 0, batch: 2752\n",
      "loss None\n",
      "batch time cost: 5.30230188369751\n",
      "Epoch: 0, batch: 2753\n",
      "loss None\n",
      "batch time cost: 5.269012212753296\n",
      "Epoch: 0, batch: 2754\n",
      "loss None\n",
      "batch time cost: 5.315430164337158\n",
      "Epoch: 0, batch: 2755\n",
      "loss None\n",
      "batch time cost: 5.28546404838562\n",
      "Epoch: 0, batch: 2756\n",
      "loss None\n",
      "batch time cost: 5.906829833984375\n",
      "Epoch: 0, batch: 2757\n",
      "loss None\n",
      "batch time cost: 6.280599117279053\n",
      "Epoch: 0, batch: 2758\n",
      "loss None\n",
      "batch time cost: 5.379966974258423\n",
      "Epoch: 0, batch: 2759\n",
      "loss None\n",
      "batch time cost: 5.266078948974609\n",
      "Epoch: 0, batch: 2760\n",
      "loss None\n",
      "batch time cost: 5.293436288833618\n",
      "Relu Train Epoch: 0 [176640/318582 (1%)]\tLoss: 0.798784\n",
      "Epoch: 0, batch: 2761\n",
      "loss None\n",
      "batch time cost: 5.315287828445435\n",
      "Epoch: 0, batch: 2762\n",
      "loss None\n",
      "batch time cost: 5.253294229507446\n",
      "Epoch: 0, batch: 2763\n",
      "loss None\n",
      "batch time cost: 5.771525144577026\n",
      "Epoch: 0, batch: 2764\n",
      "loss None\n",
      "batch time cost: 5.294093132019043\n",
      "Epoch: 0, batch: 2765\n",
      "loss None\n",
      "batch time cost: 5.336775064468384\n",
      "Epoch: 0, batch: 2766\n",
      "loss None\n",
      "batch time cost: 5.257954120635986\n",
      "Epoch: 0, batch: 2767\n",
      "loss None\n",
      "batch time cost: 5.238250970840454\n",
      "Epoch: 0, batch: 2768\n",
      "loss None\n",
      "batch time cost: 5.264712810516357\n",
      "Epoch: 0, batch: 2769\n",
      "loss None\n",
      "batch time cost: 5.283509016036987\n",
      "Epoch: 0, batch: 2770\n",
      "loss None\n",
      "batch time cost: 5.590142011642456\n",
      "Relu Train Epoch: 0 [177280/318582 (1%)]\tLoss: 0.852827\n",
      "Epoch: 0, batch: 2771\n",
      "loss None\n",
      "batch time cost: 5.3211989402771\n",
      "Epoch: 0, batch: 2772\n",
      "loss None\n",
      "batch time cost: 5.378441095352173\n",
      "Epoch: 0, batch: 2773\n",
      "loss None\n",
      "batch time cost: 5.338114976882935\n",
      "Epoch: 0, batch: 2774\n",
      "loss None\n",
      "batch time cost: 5.295244932174683\n",
      "Epoch: 0, batch: 2775\n",
      "loss None\n",
      "batch time cost: 5.284131050109863\n",
      "Epoch: 0, batch: 2776\n",
      "loss None\n",
      "batch time cost: 5.293799161911011\n",
      "Epoch: 0, batch: 2777\n",
      "loss None\n",
      "batch time cost: 5.273091077804565\n",
      "Epoch: 0, batch: 2778\n",
      "loss None\n",
      "batch time cost: 5.621127128601074\n",
      "Epoch: 0, batch: 2779\n",
      "loss None\n",
      "batch time cost: 5.319230318069458\n",
      "Epoch: 0, batch: 2780\n",
      "loss None\n",
      "batch time cost: 5.306041955947876\n",
      "Relu Train Epoch: 0 [177920/318582 (1%)]\tLoss: 0.695149\n",
      "Epoch: 0, batch: 2781\n",
      "loss None\n",
      "batch time cost: 5.254637718200684\n",
      "Epoch: 0, batch: 2782\n",
      "loss None\n",
      "batch time cost: 5.254734992980957\n",
      "Epoch: 0, batch: 2783\n",
      "loss None\n",
      "batch time cost: 5.2969629764556885\n",
      "Epoch: 0, batch: 2784\n",
      "loss None\n",
      "batch time cost: 5.251442909240723\n",
      "Epoch: 0, batch: 2785\n",
      "loss None\n",
      "batch time cost: 5.761353969573975\n",
      "Epoch: 0, batch: 2786\n",
      "loss None\n",
      "batch time cost: 5.353264808654785\n",
      "Epoch: 0, batch: 2787\n",
      "loss None\n",
      "batch time cost: 6.158713102340698\n",
      "Epoch: 0, batch: 2788\n",
      "loss None\n",
      "batch time cost: 5.377093076705933\n",
      "Epoch: 0, batch: 2789\n",
      "loss None\n",
      "batch time cost: 5.288567066192627\n",
      "Epoch: 0, batch: 2790\n",
      "loss None\n",
      "batch time cost: 5.285917043685913\n",
      "Relu Train Epoch: 0 [178560/318582 (1%)]\tLoss: 0.881623\n",
      "Epoch: 0, batch: 2791\n",
      "loss None\n",
      "batch time cost: 5.24000883102417\n",
      "Epoch: 0, batch: 2792\n",
      "loss None\n",
      "batch time cost: 5.541329860687256\n",
      "Epoch: 0, batch: 2793\n",
      "loss None\n",
      "batch time cost: 5.387937784194946\n",
      "Epoch: 0, batch: 2794\n",
      "loss None\n",
      "batch time cost: 5.4076621532440186\n",
      "Epoch: 0, batch: 2795\n",
      "loss None\n",
      "batch time cost: 5.3129730224609375\n",
      "Epoch: 0, batch: 2796\n",
      "loss None\n",
      "batch time cost: 5.31675910949707\n",
      "Epoch: 0, batch: 2797\n",
      "loss None\n",
      "batch time cost: 5.2569708824157715\n",
      "Epoch: 0, batch: 2798\n",
      "loss None\n",
      "batch time cost: 5.222955942153931\n",
      "Epoch: 0, batch: 2799\n",
      "loss None\n",
      "batch time cost: 5.738326072692871\n",
      "Epoch: 0, batch: 2800\n",
      "loss None\n",
      "batch time cost: 5.613612174987793\n",
      "Relu Train Epoch: 0 [179200/318582 (1%)]\tLoss: 0.742070\n",
      "Epoch: 0, batch: 2801\n",
      "loss None\n",
      "batch time cost: 5.5668559074401855\n",
      "Epoch: 0, batch: 2802\n",
      "loss None\n",
      "batch time cost: 5.399822950363159\n",
      "Epoch: 0, batch: 2803\n",
      "loss None\n",
      "batch time cost: 5.2752320766448975\n",
      "Epoch: 0, batch: 2804\n",
      "loss None\n",
      "batch time cost: 5.3301050662994385\n",
      "Epoch: 0, batch: 2805\n",
      "loss None\n",
      "batch time cost: 6.90096378326416\n",
      "Epoch: 0, batch: 2806\n",
      "loss None\n",
      "batch time cost: 6.085032224655151\n",
      "Epoch: 0, batch: 2807\n",
      "loss None\n",
      "batch time cost: 5.3297178745269775\n",
      "Epoch: 0, batch: 2808\n",
      "loss None\n",
      "batch time cost: 5.268747091293335\n",
      "Epoch: 0, batch: 2809\n",
      "loss None\n",
      "batch time cost: 5.31394100189209\n",
      "Epoch: 0, batch: 2810\n",
      "loss None\n",
      "batch time cost: 5.305018901824951\n",
      "Relu Train Epoch: 0 [179840/318582 (1%)]\tLoss: 0.813785\n",
      "Epoch: 0, batch: 2811\n",
      "loss None\n",
      "batch time cost: 5.320139646530151\n",
      "Epoch: 0, batch: 2812\n",
      "loss None\n",
      "batch time cost: 5.282947063446045\n",
      "Epoch: 0, batch: 2813\n",
      "loss None\n",
      "batch time cost: 5.239909887313843\n",
      "Epoch: 0, batch: 2814\n",
      "loss None\n",
      "batch time cost: 6.214977025985718\n",
      "Epoch: 0, batch: 2815\n",
      "loss None\n",
      "batch time cost: 5.321364164352417\n",
      "Epoch: 0, batch: 2816\n",
      "loss None\n",
      "batch time cost: 5.895169019699097\n",
      "Epoch: 0, batch: 2817\n",
      "loss None\n",
      "batch time cost: 5.6701178550720215\n",
      "Epoch: 0, batch: 2818\n",
      "loss None\n",
      "batch time cost: 5.386382818222046\n",
      "Epoch: 0, batch: 2819\n",
      "loss None\n",
      "batch time cost: 5.327548980712891\n",
      "Epoch: 0, batch: 2820\n",
      "loss None\n",
      "batch time cost: 5.351974964141846\n",
      "Relu Train Epoch: 0 [180480/318582 (1%)]\tLoss: 0.833776\n",
      "Epoch: 0, batch: 2821\n",
      "loss None\n",
      "batch time cost: 8.294872045516968\n",
      "Epoch: 0, batch: 2822\n",
      "loss None\n",
      "batch time cost: 6.366520166397095\n",
      "Epoch: 0, batch: 2823\n",
      "loss None\n",
      "batch time cost: 5.303677082061768\n",
      "Epoch: 0, batch: 2824\n",
      "loss None\n",
      "batch time cost: 5.299858093261719\n",
      "Epoch: 0, batch: 2825\n",
      "loss None\n",
      "batch time cost: 5.278480052947998\n",
      "Epoch: 0, batch: 2826\n",
      "loss None\n",
      "batch time cost: 5.466024875640869\n",
      "Epoch: 0, batch: 2827\n",
      "loss None\n",
      "batch time cost: 5.313114166259766\n",
      "Epoch: 0, batch: 2828\n",
      "loss None\n",
      "batch time cost: 8.234211206436157\n",
      "Epoch: 0, batch: 2829\n",
      "loss None\n",
      "batch time cost: 8.010056972503662\n",
      "Epoch: 0, batch: 2830\n",
      "loss None\n",
      "batch time cost: 7.136521100997925\n",
      "Relu Train Epoch: 0 [181120/318582 (1%)]\tLoss: 0.788458\n",
      "Epoch: 0, batch: 2831\n",
      "loss None\n",
      "batch time cost: 5.313112020492554\n",
      "Epoch: 0, batch: 2832\n",
      "loss None\n",
      "batch time cost: 5.333925008773804\n",
      "Epoch: 0, batch: 2833\n",
      "loss None\n",
      "batch time cost: 5.312235116958618\n",
      "Epoch: 0, batch: 2834\n",
      "loss None\n",
      "batch time cost: 5.269881010055542\n",
      "Epoch: 0, batch: 2835\n",
      "loss None\n",
      "batch time cost: 5.705880165100098\n",
      "Epoch: 0, batch: 2836\n",
      "loss None\n",
      "batch time cost: 5.334572076797485\n",
      "Epoch: 0, batch: 2837\n",
      "loss None\n",
      "batch time cost: 5.283119201660156\n",
      "Epoch: 0, batch: 2838\n",
      "loss None\n",
      "batch time cost: 5.310546875\n",
      "Epoch: 0, batch: 2839\n",
      "loss None\n",
      "batch time cost: 5.239933252334595\n",
      "Epoch: 0, batch: 2840\n",
      "loss None\n",
      "batch time cost: 5.242737293243408\n",
      "Relu Train Epoch: 0 [181760/318582 (1%)]\tLoss: 0.774141\n",
      "Epoch: 0, batch: 2841\n",
      "loss None\n",
      "batch time cost: 5.277440786361694\n",
      "Epoch: 0, batch: 2842\n",
      "loss None\n",
      "batch time cost: 5.351909160614014\n",
      "Epoch: 0, batch: 2843\n",
      "loss None\n",
      "batch time cost: 5.7120630741119385\n",
      "Epoch: 0, batch: 2844\n",
      "loss None\n",
      "batch time cost: 5.273157119750977\n",
      "Epoch: 0, batch: 2845\n",
      "loss None\n",
      "batch time cost: 5.352187156677246\n",
      "Epoch: 0, batch: 2846\n",
      "loss None\n",
      "batch time cost: 5.438841104507446\n",
      "Epoch: 0, batch: 2847\n",
      "loss None\n",
      "batch time cost: 6.235589981079102\n",
      "Epoch: 0, batch: 2848\n",
      "loss None\n",
      "batch time cost: 6.4262001514434814\n",
      "Epoch: 0, batch: 2849\n",
      "loss None\n",
      "batch time cost: 5.347979784011841\n",
      "Epoch: 0, batch: 2850\n",
      "loss None\n",
      "batch time cost: 5.721365928649902\n",
      "Relu Train Epoch: 0 [182400/318582 (1%)]\tLoss: 0.632240\n",
      "Epoch: 0, batch: 2851\n",
      "loss None\n",
      "batch time cost: 5.30430793762207\n",
      "Epoch: 0, batch: 2852\n",
      "loss None\n",
      "batch time cost: 5.247338056564331\n",
      "Epoch: 0, batch: 2853\n",
      "loss None\n",
      "batch time cost: 5.24128794670105\n",
      "Epoch: 0, batch: 2854\n",
      "loss None\n",
      "batch time cost: 5.272772789001465\n",
      "Epoch: 0, batch: 2855\n",
      "loss None\n",
      "batch time cost: 5.248795986175537\n",
      "Epoch: 0, batch: 2856\n",
      "loss None\n",
      "batch time cost: 5.237147808074951\n",
      "Epoch: 0, batch: 2857\n",
      "loss None\n",
      "batch time cost: 5.790386915206909\n",
      "Epoch: 0, batch: 2858\n",
      "loss None\n",
      "batch time cost: 7.483836889266968\n",
      "Epoch: 0, batch: 2859\n",
      "loss None\n",
      "batch time cost: 6.657783031463623\n",
      "Epoch: 0, batch: 2860\n",
      "loss None\n",
      "batch time cost: 5.41460919380188\n",
      "Relu Train Epoch: 0 [183040/318582 (1%)]\tLoss: 1.022386\n",
      "Epoch: 0, batch: 2861\n",
      "loss None\n",
      "batch time cost: 5.265366077423096\n",
      "Epoch: 0, batch: 2862\n",
      "loss None\n",
      "batch time cost: 5.349452972412109\n",
      "Epoch: 0, batch: 2863\n",
      "loss None\n",
      "batch time cost: 5.369697093963623\n",
      "Epoch: 0, batch: 2864\n",
      "loss None\n",
      "batch time cost: 5.690407991409302\n",
      "Epoch: 0, batch: 2865\n",
      "loss None\n",
      "batch time cost: 5.270972728729248\n",
      "Epoch: 0, batch: 2866\n",
      "loss None\n",
      "batch time cost: 5.250213146209717\n",
      "Epoch: 0, batch: 2867\n",
      "loss None\n",
      "batch time cost: 5.276871204376221\n",
      "Epoch: 0, batch: 2868\n",
      "loss None\n",
      "batch time cost: 5.245003938674927\n",
      "Epoch: 0, batch: 2869\n",
      "loss None\n",
      "batch time cost: 5.367043972015381\n",
      "Epoch: 0, batch: 2870\n",
      "loss None\n",
      "batch time cost: 5.276106834411621\n",
      "Relu Train Epoch: 0 [183680/318582 (1%)]\tLoss: 0.847488\n",
      "Epoch: 0, batch: 2871\n",
      "loss None\n",
      "batch time cost: 5.834764719009399\n",
      "Epoch: 0, batch: 2872\n",
      "loss None\n",
      "batch time cost: 5.311746835708618\n",
      "Epoch: 0, batch: 2873\n",
      "loss None\n",
      "batch time cost: 5.263400077819824\n",
      "Epoch: 0, batch: 2874\n",
      "loss None\n",
      "batch time cost: 5.238348960876465\n",
      "Epoch: 0, batch: 2875\n",
      "loss None\n",
      "batch time cost: 5.277535915374756\n",
      "Epoch: 0, batch: 2876\n",
      "loss None\n",
      "batch time cost: 5.295755863189697\n",
      "Epoch: 0, batch: 2877\n",
      "loss None\n",
      "batch time cost: 5.301954984664917\n",
      "Epoch: 0, batch: 2878\n",
      "loss None\n",
      "batch time cost: 5.2758097648620605\n",
      "Epoch: 0, batch: 2879\n",
      "loss None\n",
      "batch time cost: 5.950124025344849\n",
      "Epoch: 0, batch: 2880\n",
      "loss None\n",
      "batch time cost: 5.989742040634155\n",
      "Relu Train Epoch: 0 [184320/318582 (1%)]\tLoss: 0.804059\n",
      "Epoch: 0, batch: 2881\n",
      "loss None\n",
      "batch time cost: 5.328890085220337\n",
      "Epoch: 0, batch: 2882\n",
      "loss None\n",
      "batch time cost: 5.301986217498779\n",
      "Epoch: 0, batch: 2883\n",
      "loss None\n",
      "batch time cost: 5.308435916900635\n",
      "Epoch: 0, batch: 2884\n",
      "loss None\n",
      "batch time cost: 8.77079176902771\n",
      "Epoch: 0, batch: 2885\n",
      "loss None\n",
      "batch time cost: 5.379117012023926\n",
      "Epoch: 0, batch: 2886\n",
      "loss None\n",
      "batch time cost: 6.041943073272705\n",
      "Epoch: 0, batch: 2887\n",
      "loss None\n",
      "batch time cost: 5.384952068328857\n",
      "Epoch: 0, batch: 2888\n",
      "loss None\n",
      "batch time cost: 5.51603889465332\n",
      "Epoch: 0, batch: 2889\n",
      "loss None\n",
      "batch time cost: 5.278319835662842\n",
      "Epoch: 0, batch: 2890\n",
      "loss None\n",
      "batch time cost: 5.379562139511108\n",
      "Relu Train Epoch: 0 [184960/318582 (1%)]\tLoss: 0.793131\n",
      "Epoch: 0, batch: 2891\n",
      "loss None\n",
      "batch time cost: 5.2644758224487305\n",
      "Epoch: 0, batch: 2892\n",
      "loss None\n",
      "batch time cost: 5.2834906578063965\n",
      "Epoch: 0, batch: 2893\n",
      "loss None\n",
      "batch time cost: 5.585216760635376\n",
      "Epoch: 0, batch: 2894\n",
      "loss None\n",
      "batch time cost: 5.262275695800781\n",
      "Epoch: 0, batch: 2895\n",
      "loss None\n",
      "batch time cost: 5.245457887649536\n",
      "Epoch: 0, batch: 2896\n",
      "loss None\n",
      "batch time cost: 5.264226913452148\n",
      "Epoch: 0, batch: 2897\n",
      "loss None\n",
      "batch time cost: 5.2051918506622314\n",
      "Epoch: 0, batch: 2898\n",
      "loss None\n",
      "batch time cost: 5.236717939376831\n",
      "Epoch: 0, batch: 2899\n",
      "loss None\n",
      "batch time cost: 5.242368221282959\n",
      "Epoch: 0, batch: 2900\n",
      "loss None\n",
      "batch time cost: 5.616513252258301\n",
      "Relu Train Epoch: 0 [185600/318582 (1%)]\tLoss: 0.978801\n",
      "Epoch: 0, batch: 2901\n",
      "loss None\n",
      "batch time cost: 5.297392129898071\n",
      "Epoch: 0, batch: 2902\n",
      "loss None\n",
      "batch time cost: 5.312310218811035\n",
      "Epoch: 0, batch: 2903\n",
      "loss None\n",
      "batch time cost: 5.267693996429443\n",
      "Epoch: 0, batch: 2904\n",
      "loss None\n",
      "batch time cost: 5.249876022338867\n",
      "Epoch: 0, batch: 2905\n",
      "loss None\n",
      "batch time cost: 5.229929208755493\n",
      "Epoch: 0, batch: 2906\n",
      "loss None\n",
      "batch time cost: 5.275543928146362\n",
      "Epoch: 0, batch: 2907\n",
      "loss None\n",
      "batch time cost: 5.315126657485962\n",
      "Epoch: 0, batch: 2908\n",
      "loss None\n",
      "batch time cost: 5.595031023025513\n",
      "Epoch: 0, batch: 2909\n",
      "loss None\n",
      "batch time cost: 5.25409197807312\n",
      "Epoch: 0, batch: 2910\n",
      "loss None\n",
      "batch time cost: 5.282198667526245\n",
      "Relu Train Epoch: 0 [186240/318582 (1%)]\tLoss: 0.977067\n",
      "Epoch: 0, batch: 2911\n",
      "loss None\n",
      "batch time cost: 5.243314981460571\n",
      "Epoch: 0, batch: 2912\n",
      "loss None\n",
      "batch time cost: 5.260199069976807\n",
      "Epoch: 0, batch: 2913\n",
      "loss None\n",
      "batch time cost: 5.317437171936035\n",
      "Epoch: 0, batch: 2914\n",
      "loss None\n",
      "batch time cost: 5.264569044113159\n",
      "Epoch: 0, batch: 2915\n",
      "loss None\n",
      "batch time cost: 5.562993764877319\n",
      "Epoch: 0, batch: 2916\n",
      "loss None\n",
      "batch time cost: 5.317958831787109\n",
      "Epoch: 0, batch: 2917\n",
      "loss None\n",
      "batch time cost: 5.2466559410095215\n",
      "Epoch: 0, batch: 2918\n",
      "loss None\n",
      "batch time cost: 5.2567079067230225\n",
      "Epoch: 0, batch: 2919\n",
      "loss None\n",
      "batch time cost: 5.277477979660034\n",
      "Epoch: 0, batch: 2920\n",
      "loss None\n",
      "batch time cost: 5.250900983810425\n",
      "Relu Train Epoch: 0 [186880/318582 (1%)]\tLoss: 0.765257\n",
      "Epoch: 0, batch: 2921\n",
      "loss None\n",
      "batch time cost: 5.241339206695557\n",
      "Epoch: 0, batch: 2922\n",
      "loss None\n",
      "batch time cost: 5.577285051345825\n",
      "Epoch: 0, batch: 2923\n",
      "loss None\n",
      "batch time cost: 5.307959079742432\n",
      "Epoch: 0, batch: 2924\n",
      "loss None\n",
      "batch time cost: 5.305685997009277\n",
      "Epoch: 0, batch: 2925\n",
      "loss None\n",
      "batch time cost: 5.283993244171143\n",
      "Epoch: 0, batch: 2926\n",
      "loss None\n",
      "batch time cost: 5.2681639194488525\n",
      "Epoch: 0, batch: 2927\n",
      "loss None\n",
      "batch time cost: 5.220702886581421\n",
      "Epoch: 0, batch: 2928\n",
      "loss None\n",
      "batch time cost: 5.306936025619507\n",
      "Epoch: 0, batch: 2929\n",
      "loss None\n",
      "batch time cost: 5.543049097061157\n",
      "Epoch: 0, batch: 2930\n",
      "loss None\n",
      "batch time cost: 5.241711139678955\n",
      "Relu Train Epoch: 0 [187520/318582 (1%)]\tLoss: 0.837060\n",
      "Epoch: 0, batch: 2931\n",
      "loss None\n",
      "batch time cost: 5.258429050445557\n",
      "Epoch: 0, batch: 2932\n",
      "loss None\n",
      "batch time cost: 5.250757217407227\n",
      "Epoch: 0, batch: 2933\n",
      "loss None\n",
      "batch time cost: 5.242235898971558\n",
      "Epoch: 0, batch: 2934\n",
      "loss None\n",
      "batch time cost: 5.225013017654419\n",
      "Epoch: 0, batch: 2935\n",
      "loss None\n",
      "batch time cost: 5.3254289627075195\n",
      "Epoch: 0, batch: 2936\n",
      "loss None\n",
      "batch time cost: 5.576417922973633\n",
      "Epoch: 0, batch: 2937\n",
      "loss None\n",
      "batch time cost: 5.305531740188599\n",
      "Epoch: 0, batch: 2938\n",
      "loss None\n",
      "batch time cost: 5.27201771736145\n",
      "Epoch: 0, batch: 2939\n",
      "loss None\n",
      "batch time cost: 5.263067960739136\n",
      "Epoch: 0, batch: 2940\n",
      "loss None\n",
      "batch time cost: 5.1963050365448\n",
      "Relu Train Epoch: 0 [188160/318582 (1%)]\tLoss: 0.812124\n",
      "Epoch: 0, batch: 2941\n",
      "loss None\n",
      "batch time cost: 5.275409936904907\n",
      "Epoch: 0, batch: 2942\n",
      "loss None\n",
      "batch time cost: 5.289251089096069\n",
      "Epoch: 0, batch: 2943\n",
      "loss None\n",
      "batch time cost: 5.207422971725464\n",
      "Epoch: 0, batch: 2944\n",
      "loss None\n",
      "batch time cost: 5.603221893310547\n",
      "Epoch: 0, batch: 2945\n",
      "loss None\n",
      "batch time cost: 5.247651100158691\n",
      "Epoch: 0, batch: 2946\n",
      "loss None\n",
      "batch time cost: 5.257368803024292\n",
      "Epoch: 0, batch: 2947\n",
      "loss None\n",
      "batch time cost: 5.383265972137451\n",
      "Epoch: 0, batch: 2948\n",
      "loss None\n",
      "batch time cost: 5.272479295730591\n",
      "Epoch: 0, batch: 2949\n",
      "loss None\n",
      "batch time cost: 5.334334850311279\n",
      "Epoch: 0, batch: 2950\n",
      "loss None\n",
      "batch time cost: 5.236871957778931\n",
      "Relu Train Epoch: 0 [188800/318582 (1%)]\tLoss: 0.628853\n",
      "Epoch: 0, batch: 2951\n",
      "loss None\n",
      "batch time cost: 5.555151700973511\n",
      "Epoch: 0, batch: 2952\n",
      "loss None\n",
      "batch time cost: 5.265019178390503\n",
      "Epoch: 0, batch: 2953\n",
      "loss None\n",
      "batch time cost: 5.245965003967285\n",
      "Epoch: 0, batch: 2954\n",
      "loss None\n",
      "batch time cost: 5.234572887420654\n",
      "Epoch: 0, batch: 2955\n",
      "loss None\n",
      "batch time cost: 5.2515459060668945\n",
      "Epoch: 0, batch: 2956\n",
      "loss None\n",
      "batch time cost: 5.290700197219849\n",
      "Epoch: 0, batch: 2957\n",
      "loss None\n",
      "batch time cost: 5.236257076263428\n",
      "Epoch: 0, batch: 2958\n",
      "loss None\n",
      "batch time cost: 5.587337970733643\n",
      "Epoch: 0, batch: 2959\n",
      "loss None\n",
      "batch time cost: 5.365722179412842\n",
      "Epoch: 0, batch: 2960\n",
      "loss None\n",
      "batch time cost: 5.244029998779297\n",
      "Relu Train Epoch: 0 [189440/318582 (1%)]\tLoss: 0.817207\n",
      "Epoch: 0, batch: 2961\n",
      "loss None\n",
      "batch time cost: 5.302908182144165\n",
      "Epoch: 0, batch: 2962\n",
      "loss None\n",
      "batch time cost: 5.26712703704834\n",
      "Epoch: 0, batch: 2963\n",
      "loss None\n",
      "batch time cost: 5.275882005691528\n",
      "Epoch: 0, batch: 2964\n",
      "loss None\n",
      "batch time cost: 5.261868953704834\n",
      "Epoch: 0, batch: 2965\n",
      "loss None\n",
      "batch time cost: 5.557718992233276\n",
      "Epoch: 0, batch: 2966\n",
      "loss None\n",
      "batch time cost: 5.299267053604126\n",
      "Epoch: 0, batch: 2967\n",
      "loss None\n",
      "batch time cost: 5.253229141235352\n",
      "Epoch: 0, batch: 2968\n",
      "loss None\n",
      "batch time cost: 5.281955003738403\n",
      "Epoch: 0, batch: 2969\n",
      "loss None\n",
      "batch time cost: 5.286874055862427\n",
      "Epoch: 0, batch: 2970\n",
      "loss None\n",
      "batch time cost: 5.2953269481658936\n",
      "Relu Train Epoch: 0 [190080/318582 (1%)]\tLoss: 0.835546\n",
      "Epoch: 0, batch: 2971\n",
      "loss None\n",
      "batch time cost: 5.322494983673096\n",
      "Epoch: 0, batch: 2972\n",
      "loss None\n",
      "batch time cost: 5.264941930770874\n",
      "Epoch: 0, batch: 2973\n",
      "loss None\n",
      "batch time cost: 5.596531867980957\n",
      "Epoch: 0, batch: 2974\n",
      "loss None\n",
      "batch time cost: 5.308671951293945\n",
      "Epoch: 0, batch: 2975\n",
      "loss None\n",
      "batch time cost: 5.320142030715942\n",
      "Epoch: 0, batch: 2976\n",
      "loss None\n",
      "batch time cost: 5.274425983428955\n",
      "Epoch: 0, batch: 2977\n",
      "loss None\n",
      "batch time cost: 5.27591609954834\n",
      "Epoch: 0, batch: 2978\n",
      "loss None\n",
      "batch time cost: 5.269673109054565\n",
      "Epoch: 0, batch: 2979\n",
      "loss None\n",
      "batch time cost: 5.262372970581055\n",
      "Epoch: 0, batch: 2980\n",
      "loss None\n",
      "batch time cost: 5.622851610183716\n",
      "Relu Train Epoch: 0 [190720/318582 (1%)]\tLoss: 0.936631\n",
      "Epoch: 0, batch: 2981\n",
      "loss None\n",
      "batch time cost: 5.257979869842529\n",
      "Epoch: 0, batch: 2982\n",
      "loss None\n",
      "batch time cost: 5.2858240604400635\n",
      "Epoch: 0, batch: 2983\n",
      "loss None\n",
      "batch time cost: 5.237304210662842\n",
      "Epoch: 0, batch: 2984\n",
      "loss None\n",
      "batch time cost: 5.304925918579102\n",
      "Epoch: 0, batch: 2985\n",
      "loss None\n",
      "batch time cost: 5.315280199050903\n",
      "Epoch: 0, batch: 2986\n",
      "loss None\n",
      "batch time cost: 5.2873899936676025\n",
      "Epoch: 0, batch: 2987\n",
      "loss None\n",
      "batch time cost: 5.6176598072052\n",
      "Epoch: 0, batch: 2988\n",
      "loss None\n",
      "batch time cost: 5.2998669147491455\n",
      "Epoch: 0, batch: 2989\n",
      "loss None\n",
      "batch time cost: 5.310847997665405\n",
      "Epoch: 0, batch: 2990\n",
      "loss None\n",
      "batch time cost: 5.3716371059417725\n",
      "Relu Train Epoch: 0 [191360/318582 (1%)]\tLoss: 0.817250\n",
      "Epoch: 0, batch: 2991\n",
      "loss None\n",
      "batch time cost: 5.354024887084961\n",
      "Epoch: 0, batch: 2992\n",
      "loss None\n",
      "batch time cost: 5.312554836273193\n",
      "Epoch: 0, batch: 2993\n",
      "loss None\n",
      "batch time cost: 5.257299900054932\n",
      "Epoch: 0, batch: 2994\n",
      "loss None\n",
      "batch time cost: 5.605041027069092\n",
      "Epoch: 0, batch: 2995\n",
      "loss None\n",
      "batch time cost: 5.285828113555908\n",
      "Epoch: 0, batch: 2996\n",
      "loss None\n",
      "batch time cost: 5.259727954864502\n",
      "Epoch: 0, batch: 2997\n",
      "loss None\n",
      "batch time cost: 5.267319917678833\n",
      "Epoch: 0, batch: 2998\n",
      "loss None\n",
      "batch time cost: 5.2502501010894775\n",
      "Epoch: 0, batch: 2999\n",
      "loss None\n",
      "batch time cost: 5.266566276550293\n",
      "Epoch: 0, batch: 3000\n",
      "loss None\n",
      "batch time cost: 5.287300109863281\n",
      "Relu Train Epoch: 0 [192000/318582 (1%)]\tLoss: 0.695170\n",
      "Epoch: 0, batch: 3001\n",
      "loss None\n",
      "batch time cost: 5.623875141143799\n",
      "Epoch: 0, batch: 3002\n",
      "loss None\n",
      "batch time cost: 5.290066719055176\n",
      "Epoch: 0, batch: 3003\n",
      "loss None\n",
      "batch time cost: 5.364348888397217\n",
      "Epoch: 0, batch: 3004\n",
      "loss None\n",
      "batch time cost: 5.3248701095581055\n",
      "Epoch: 0, batch: 3005\n",
      "loss None\n",
      "batch time cost: 5.302865982055664\n",
      "Epoch: 0, batch: 3006\n",
      "loss None\n",
      "batch time cost: 5.21632719039917\n",
      "Epoch: 0, batch: 3007\n",
      "loss None\n",
      "batch time cost: 5.245792865753174\n",
      "Epoch: 0, batch: 3008\n",
      "loss None\n",
      "batch time cost: 5.270922899246216\n",
      "Epoch: 0, batch: 3009\n",
      "loss None\n",
      "batch time cost: 5.59900689125061\n",
      "Epoch: 0, batch: 3010\n",
      "loss None\n",
      "batch time cost: 5.219225883483887\n",
      "Relu Train Epoch: 0 [192640/318582 (1%)]\tLoss: 0.868242\n",
      "Epoch: 0, batch: 3011\n",
      "loss None\n",
      "batch time cost: 5.226417064666748\n",
      "Epoch: 0, batch: 3012\n",
      "loss None\n",
      "batch time cost: 5.2832722663879395\n",
      "Epoch: 0, batch: 3013\n",
      "loss None\n",
      "batch time cost: 5.254349231719971\n",
      "Epoch: 0, batch: 3014\n",
      "loss None\n",
      "batch time cost: 5.285260915756226\n",
      "Epoch: 0, batch: 3015\n",
      "loss None\n",
      "batch time cost: 5.254502058029175\n",
      "Epoch: 0, batch: 3016\n",
      "loss None\n",
      "batch time cost: 5.5349462032318115\n",
      "Epoch: 0, batch: 3017\n",
      "loss None\n",
      "batch time cost: 5.29065203666687\n",
      "Epoch: 0, batch: 3018\n",
      "loss None\n",
      "batch time cost: 5.256924867630005\n",
      "Epoch: 0, batch: 3019\n",
      "loss None\n",
      "batch time cost: 5.288969278335571\n",
      "Epoch: 0, batch: 3020\n",
      "loss None\n",
      "batch time cost: 5.25016188621521\n",
      "Relu Train Epoch: 0 [193280/318582 (1%)]\tLoss: 0.701779\n",
      "Epoch: 0, batch: 3021\n",
      "loss None\n",
      "batch time cost: 5.27418327331543\n",
      "Epoch: 0, batch: 3022\n",
      "loss None\n",
      "batch time cost: 5.308143854141235\n",
      "Epoch: 0, batch: 3023\n",
      "loss None\n",
      "batch time cost: 5.564553260803223\n",
      "Epoch: 0, batch: 3024\n",
      "loss None\n",
      "batch time cost: 5.2662787437438965\n",
      "Epoch: 0, batch: 3025\n",
      "loss None\n",
      "batch time cost: 5.294442892074585\n",
      "Epoch: 0, batch: 3026\n",
      "loss None\n",
      "batch time cost: 5.274492025375366\n",
      "Epoch: 0, batch: 3027\n",
      "loss None\n",
      "batch time cost: 5.275907278060913\n",
      "Epoch: 0, batch: 3028\n",
      "loss None\n",
      "batch time cost: 5.261234998703003\n",
      "Epoch: 0, batch: 3029\n",
      "loss None\n",
      "batch time cost: 5.2835469245910645\n",
      "Epoch: 0, batch: 3030\n",
      "loss None\n",
      "batch time cost: 5.553880929946899\n",
      "Relu Train Epoch: 0 [193920/318582 (1%)]\tLoss: 0.799142\n",
      "Epoch: 0, batch: 3031\n",
      "loss None\n",
      "batch time cost: 5.239995718002319\n",
      "Epoch: 0, batch: 3032\n",
      "loss None\n",
      "batch time cost: 5.29561972618103\n",
      "Epoch: 0, batch: 3033\n",
      "loss None\n",
      "batch time cost: 5.282679080963135\n",
      "Epoch: 0, batch: 3034\n",
      "loss None\n",
      "batch time cost: 5.265956878662109\n",
      "Epoch: 0, batch: 3035\n",
      "loss None\n",
      "batch time cost: 5.286771774291992\n",
      "Epoch: 0, batch: 3036\n",
      "loss None\n",
      "batch time cost: 5.236530065536499\n",
      "Epoch: 0, batch: 3037\n",
      "loss None\n",
      "batch time cost: 5.2688682079315186\n",
      "Epoch: 0, batch: 3038\n",
      "loss None\n",
      "batch time cost: 5.537455081939697\n",
      "Epoch: 0, batch: 3039\n",
      "loss None\n",
      "batch time cost: 5.253201007843018\n",
      "Epoch: 0, batch: 3040\n",
      "loss None\n",
      "batch time cost: 5.24180793762207\n",
      "Relu Train Epoch: 0 [194560/318582 (1%)]\tLoss: 0.759791\n",
      "Epoch: 0, batch: 3041\n",
      "loss None\n",
      "batch time cost: 5.289255142211914\n",
      "Epoch: 0, batch: 3042\n",
      "loss None\n",
      "batch time cost: 5.27836799621582\n",
      "Epoch: 0, batch: 3043\n",
      "loss None\n",
      "batch time cost: 5.312530755996704\n",
      "Epoch: 0, batch: 3044\n",
      "loss None\n",
      "batch time cost: 5.311259984970093\n",
      "Epoch: 0, batch: 3045\n",
      "loss None\n",
      "batch time cost: 5.580773830413818\n",
      "Epoch: 0, batch: 3046\n",
      "loss None\n",
      "batch time cost: 5.243387937545776\n",
      "Epoch: 0, batch: 3047\n",
      "loss None\n",
      "batch time cost: 5.290629863739014\n",
      "Epoch: 0, batch: 3048\n",
      "loss None\n",
      "batch time cost: 5.345191955566406\n",
      "Epoch: 0, batch: 3049\n",
      "loss None\n",
      "batch time cost: 5.296834230422974\n",
      "Epoch: 0, batch: 3050\n",
      "loss None\n",
      "batch time cost: 5.281248092651367\n",
      "Relu Train Epoch: 0 [195200/318582 (1%)]\tLoss: 0.946401\n",
      "Epoch: 0, batch: 3051\n",
      "loss None\n",
      "batch time cost: 5.2530128955841064\n",
      "Epoch: 0, batch: 3052\n",
      "loss None\n",
      "batch time cost: 5.622827053070068\n",
      "Epoch: 0, batch: 3053\n",
      "loss None\n",
      "batch time cost: 5.326876163482666\n",
      "Epoch: 0, batch: 3054\n",
      "loss None\n",
      "batch time cost: 5.24987006187439\n",
      "Epoch: 0, batch: 3055\n",
      "loss None\n",
      "batch time cost: 5.2340428829193115\n",
      "Epoch: 0, batch: 3056\n",
      "loss None\n",
      "batch time cost: 5.269721746444702\n",
      "Epoch: 0, batch: 3057\n",
      "loss None\n",
      "batch time cost: 5.289031267166138\n",
      "Epoch: 0, batch: 3058\n",
      "loss None\n",
      "batch time cost: 5.292106866836548\n",
      "Epoch: 0, batch: 3059\n",
      "loss None\n",
      "batch time cost: 5.612947940826416\n",
      "Epoch: 0, batch: 3060\n",
      "loss None\n",
      "batch time cost: 5.211190223693848\n",
      "Relu Train Epoch: 0 [195840/318582 (1%)]\tLoss: 0.831902\n",
      "Epoch: 0, batch: 3061\n",
      "loss None\n",
      "batch time cost: 5.306737184524536\n",
      "Epoch: 0, batch: 3062\n",
      "loss None\n",
      "batch time cost: 5.2516419887542725\n",
      "Epoch: 0, batch: 3063\n",
      "loss None\n",
      "batch time cost: 5.250896692276001\n",
      "Epoch: 0, batch: 3064\n",
      "loss None\n",
      "batch time cost: 5.360637903213501\n",
      "Epoch: 0, batch: 3065\n",
      "loss None\n",
      "batch time cost: 5.305879831314087\n",
      "Epoch: 0, batch: 3066\n",
      "loss None\n",
      "batch time cost: 5.603571891784668\n",
      "Epoch: 0, batch: 3067\n",
      "loss None\n",
      "batch time cost: 5.262956142425537\n",
      "Epoch: 0, batch: 3068\n",
      "loss None\n",
      "batch time cost: 5.2493250370025635\n",
      "Epoch: 0, batch: 3069\n",
      "loss None\n",
      "batch time cost: 5.320779085159302\n",
      "Epoch: 0, batch: 3070\n",
      "loss None\n",
      "batch time cost: 5.233366966247559\n",
      "Relu Train Epoch: 0 [196480/318582 (1%)]\tLoss: 0.663556\n",
      "Epoch: 0, batch: 3071\n",
      "loss None\n",
      "batch time cost: 5.328680038452148\n",
      "Epoch: 0, batch: 3072\n",
      "loss None\n",
      "batch time cost: 5.311530828475952\n",
      "Epoch: 0, batch: 3073\n",
      "loss None\n",
      "batch time cost: 5.286123991012573\n",
      "Epoch: 0, batch: 3074\n",
      "loss None\n",
      "batch time cost: 5.600818872451782\n",
      "Epoch: 0, batch: 3075\n",
      "loss None\n",
      "batch time cost: 5.246238946914673\n",
      "Epoch: 0, batch: 3076\n",
      "loss None\n",
      "batch time cost: 5.253258943557739\n",
      "Epoch: 0, batch: 3077\n",
      "loss None\n",
      "batch time cost: 5.236411094665527\n",
      "Epoch: 0, batch: 3078\n",
      "loss None\n",
      "batch time cost: 5.30792498588562\n",
      "Epoch: 0, batch: 3079\n",
      "loss None\n",
      "batch time cost: 5.303926706314087\n",
      "Epoch: 0, batch: 3080\n",
      "loss None\n",
      "batch time cost: 5.2605719566345215\n",
      "Relu Train Epoch: 0 [197120/318582 (1%)]\tLoss: 0.782285\n",
      "Epoch: 0, batch: 3081\n",
      "loss None\n",
      "batch time cost: 5.587348937988281\n",
      "Epoch: 0, batch: 3082\n",
      "loss None\n",
      "batch time cost: 5.314496040344238\n",
      "Epoch: 0, batch: 3083\n",
      "loss None\n",
      "batch time cost: 5.285916090011597\n",
      "Epoch: 0, batch: 3084\n",
      "loss None\n",
      "batch time cost: 5.2595741748809814\n",
      "Epoch: 0, batch: 3085\n",
      "loss None\n",
      "batch time cost: 5.264822006225586\n",
      "Epoch: 0, batch: 3086\n",
      "loss None\n",
      "batch time cost: 5.3667638301849365\n",
      "Epoch: 0, batch: 3087\n",
      "loss None\n",
      "batch time cost: 5.2303619384765625\n",
      "Epoch: 0, batch: 3088\n",
      "loss None\n",
      "batch time cost: 5.636254072189331\n",
      "Epoch: 0, batch: 3089\n",
      "loss None\n",
      "batch time cost: 5.2711639404296875\n",
      "Epoch: 0, batch: 3090\n",
      "loss None\n",
      "batch time cost: 5.279827833175659\n",
      "Relu Train Epoch: 0 [197760/318582 (1%)]\tLoss: 0.868582\n",
      "Epoch: 0, batch: 3091\n",
      "loss None\n",
      "batch time cost: 5.246395826339722\n",
      "Epoch: 0, batch: 3092\n",
      "loss None\n",
      "batch time cost: 5.258714914321899\n",
      "Epoch: 0, batch: 3093\n",
      "loss None\n",
      "batch time cost: 5.360889911651611\n",
      "Epoch: 0, batch: 3094\n",
      "loss None\n",
      "batch time cost: 5.346028089523315\n",
      "Epoch: 0, batch: 3095\n",
      "loss None\n",
      "batch time cost: 5.605132818222046\n",
      "Epoch: 0, batch: 3096\n",
      "loss None\n",
      "batch time cost: 5.229875087738037\n",
      "Epoch: 0, batch: 3097\n",
      "loss None\n",
      "batch time cost: 5.271888971328735\n",
      "Epoch: 0, batch: 3098\n",
      "loss None\n",
      "batch time cost: 5.244144916534424\n",
      "Epoch: 0, batch: 3099\n",
      "loss None\n",
      "batch time cost: 5.245321989059448\n",
      "Epoch: 0, batch: 3100\n",
      "loss None\n",
      "batch time cost: 5.238314151763916\n",
      "Relu Train Epoch: 0 [198400/318582 (1%)]\tLoss: 0.949669\n",
      "Epoch: 0, batch: 3101\n",
      "loss None\n",
      "batch time cost: 5.248542070388794\n",
      "Epoch: 0, batch: 3102\n",
      "loss None\n",
      "batch time cost: 5.256871938705444\n",
      "Epoch: 0, batch: 3103\n",
      "loss None\n",
      "batch time cost: 5.581912994384766\n",
      "Epoch: 0, batch: 3104\n",
      "loss None\n",
      "batch time cost: 5.268604278564453\n",
      "Epoch: 0, batch: 3105\n",
      "loss None\n",
      "batch time cost: 5.305131196975708\n",
      "Epoch: 0, batch: 3106\n",
      "loss None\n",
      "batch time cost: 5.301944255828857\n",
      "Epoch: 0, batch: 3107\n",
      "loss None\n",
      "batch time cost: 5.24249792098999\n",
      "Epoch: 0, batch: 3108\n",
      "loss None\n",
      "batch time cost: 5.192133188247681\n",
      "Epoch: 0, batch: 3109\n",
      "loss None\n",
      "batch time cost: 5.27283787727356\n",
      "Epoch: 0, batch: 3110\n",
      "loss None\n",
      "batch time cost: 5.599956035614014\n",
      "Relu Train Epoch: 0 [199040/318582 (1%)]\tLoss: 0.731700\n",
      "Epoch: 0, batch: 3111\n",
      "loss None\n",
      "batch time cost: 5.273716926574707\n",
      "Epoch: 0, batch: 3112\n",
      "loss None\n",
      "batch time cost: 5.264065980911255\n",
      "Epoch: 0, batch: 3113\n",
      "loss None\n",
      "batch time cost: 5.385738134384155\n",
      "Epoch: 0, batch: 3114\n",
      "loss None\n",
      "batch time cost: 5.225787878036499\n",
      "Epoch: 0, batch: 3115\n",
      "loss None\n",
      "batch time cost: 5.324084997177124\n",
      "Epoch: 0, batch: 3116\n",
      "loss None\n",
      "batch time cost: 5.2895143032073975\n",
      "Epoch: 0, batch: 3117\n",
      "loss None\n",
      "batch time cost: 5.570935010910034\n",
      "Epoch: 0, batch: 3118\n",
      "loss None\n",
      "batch time cost: 5.319273948669434\n",
      "Epoch: 0, batch: 3119\n",
      "loss None\n",
      "batch time cost: 5.286919116973877\n",
      "Epoch: 0, batch: 3120\n",
      "loss None\n",
      "batch time cost: 5.261267900466919\n",
      "Relu Train Epoch: 0 [199680/318582 (1%)]\tLoss: 1.009135\n",
      "Epoch: 0, batch: 3121\n",
      "loss None\n",
      "batch time cost: 5.251737117767334\n",
      "Epoch: 0, batch: 3122\n",
      "loss None\n",
      "batch time cost: 5.239699125289917\n",
      "Epoch: 0, batch: 3123\n",
      "loss None\n",
      "batch time cost: 5.2609498500823975\n",
      "Epoch: 0, batch: 3124\n",
      "loss None\n",
      "batch time cost: 5.614772081375122\n",
      "Epoch: 0, batch: 3125\n",
      "loss None\n",
      "batch time cost: 5.264002799987793\n",
      "Epoch: 0, batch: 3126\n",
      "loss None\n",
      "batch time cost: 5.258386850357056\n",
      "Epoch: 0, batch: 3127\n",
      "loss None\n",
      "batch time cost: 5.302324056625366\n",
      "Epoch: 0, batch: 3128\n",
      "loss None\n",
      "batch time cost: 5.281959056854248\n",
      "Epoch: 0, batch: 3129\n",
      "loss None\n",
      "batch time cost: 5.313594102859497\n",
      "Epoch: 0, batch: 3130\n",
      "loss None\n",
      "batch time cost: 5.313326120376587\n",
      "Relu Train Epoch: 0 [200320/318582 (1%)]\tLoss: 0.943157\n",
      "Epoch: 0, batch: 3131\n",
      "loss None\n",
      "batch time cost: 5.625509023666382\n",
      "Epoch: 0, batch: 3132\n",
      "loss None\n",
      "batch time cost: 5.289708852767944\n",
      "Epoch: 0, batch: 3133\n",
      "loss None\n",
      "batch time cost: 5.2450830936431885\n",
      "Epoch: 0, batch: 3134\n",
      "loss None\n",
      "batch time cost: 5.299783945083618\n",
      "Epoch: 0, batch: 3135\n",
      "loss None\n",
      "batch time cost: 5.305165767669678\n",
      "Epoch: 0, batch: 3136\n",
      "loss None\n",
      "batch time cost: 5.2896950244903564\n",
      "Epoch: 0, batch: 3137\n",
      "loss None\n",
      "batch time cost: 5.245877027511597\n",
      "Epoch: 0, batch: 3138\n",
      "loss None\n",
      "batch time cost: 5.304471969604492\n",
      "Epoch: 0, batch: 3139\n",
      "loss None\n",
      "batch time cost: 5.61523699760437\n",
      "Epoch: 0, batch: 3140\n",
      "loss None\n",
      "batch time cost: 5.343472957611084\n",
      "Relu Train Epoch: 0 [200960/318582 (1%)]\tLoss: 0.740338\n",
      "Epoch: 0, batch: 3141\n",
      "loss None\n",
      "batch time cost: 5.268509864807129\n",
      "Epoch: 0, batch: 3142\n",
      "loss None\n",
      "batch time cost: 5.262546062469482\n",
      "Epoch: 0, batch: 3143\n",
      "loss None\n",
      "batch time cost: 5.22762393951416\n",
      "Epoch: 0, batch: 3144\n",
      "loss None\n",
      "batch time cost: 5.240034103393555\n",
      "Epoch: 0, batch: 3145\n",
      "loss None\n",
      "batch time cost: 5.2169153690338135\n",
      "Epoch: 0, batch: 3146\n",
      "loss None\n",
      "batch time cost: 5.590238094329834\n",
      "Epoch: 0, batch: 3147\n",
      "loss None\n",
      "batch time cost: 5.2503111362457275\n",
      "Epoch: 0, batch: 3148\n",
      "loss None\n",
      "batch time cost: 5.266166687011719\n",
      "Epoch: 0, batch: 3149\n",
      "loss None\n",
      "batch time cost: 5.28118109703064\n",
      "Epoch: 0, batch: 3150\n",
      "loss None\n",
      "batch time cost: 5.242829084396362\n",
      "Relu Train Epoch: 0 [201600/318582 (1%)]\tLoss: 0.995370\n",
      "Epoch: 0, batch: 3151\n",
      "loss None\n",
      "batch time cost: 5.259063959121704\n",
      "Epoch: 0, batch: 3152\n",
      "loss None\n",
      "batch time cost: 5.280009984970093\n",
      "Epoch: 0, batch: 3153\n",
      "loss None\n",
      "batch time cost: 5.611440896987915\n",
      "Epoch: 0, batch: 3154\n",
      "loss None\n",
      "batch time cost: 5.228687763214111\n",
      "Epoch: 0, batch: 3155\n",
      "loss None\n",
      "batch time cost: 5.216161012649536\n",
      "Epoch: 0, batch: 3156\n",
      "loss None\n",
      "batch time cost: 5.255274057388306\n",
      "Epoch: 0, batch: 3157\n",
      "loss None\n",
      "batch time cost: 5.273181915283203\n",
      "Epoch: 0, batch: 3158\n",
      "loss None\n",
      "batch time cost: 5.342652797698975\n",
      "Epoch: 0, batch: 3159\n",
      "loss None\n",
      "batch time cost: 5.328310012817383\n",
      "Epoch: 0, batch: 3160\n",
      "loss None\n",
      "batch time cost: 5.5984930992126465\n",
      "Relu Train Epoch: 0 [202240/318582 (1%)]\tLoss: 0.801725\n",
      "Epoch: 0, batch: 3161\n",
      "loss None\n",
      "batch time cost: 5.312713146209717\n",
      "Epoch: 0, batch: 3162\n",
      "loss None\n",
      "batch time cost: 5.278864860534668\n",
      "Epoch: 0, batch: 3163\n",
      "loss None\n",
      "batch time cost: 5.240020990371704\n",
      "Epoch: 0, batch: 3164\n",
      "loss None\n",
      "batch time cost: 5.2425758838653564\n",
      "Epoch: 0, batch: 3165\n",
      "loss None\n",
      "batch time cost: 5.275609970092773\n",
      "Epoch: 0, batch: 3166\n",
      "loss None\n",
      "batch time cost: 5.270282983779907\n",
      "Epoch: 0, batch: 3167\n",
      "loss None\n",
      "batch time cost: 5.280090808868408\n",
      "Epoch: 0, batch: 3168\n",
      "loss None\n",
      "batch time cost: 5.55278205871582\n",
      "Epoch: 0, batch: 3169\n",
      "loss None\n",
      "batch time cost: 5.239051103591919\n",
      "Epoch: 0, batch: 3170\n",
      "loss None\n",
      "batch time cost: 5.287526845932007\n",
      "Relu Train Epoch: 0 [202880/318582 (1%)]\tLoss: 0.880961\n",
      "Epoch: 0, batch: 3171\n",
      "loss None\n",
      "batch time cost: 5.241511106491089\n",
      "Epoch: 0, batch: 3172\n",
      "loss None\n",
      "batch time cost: 5.348800897598267\n",
      "Epoch: 0, batch: 3173\n",
      "loss None\n",
      "batch time cost: 5.2722718715667725\n",
      "Epoch: 0, batch: 3174\n",
      "loss None\n",
      "batch time cost: 5.253231048583984\n",
      "Epoch: 0, batch: 3175\n",
      "loss None\n",
      "batch time cost: 5.599328994750977\n",
      "Epoch: 0, batch: 3176\n",
      "loss None\n",
      "batch time cost: 5.2697038650512695\n",
      "Epoch: 0, batch: 3177\n",
      "loss None\n",
      "batch time cost: 5.313271760940552\n",
      "Epoch: 0, batch: 3178\n",
      "loss None\n",
      "batch time cost: 5.270479917526245\n",
      "Epoch: 0, batch: 3179\n",
      "loss None\n",
      "batch time cost: 5.208868980407715\n",
      "Epoch: 0, batch: 3180\n",
      "loss None\n",
      "batch time cost: 5.2579991817474365\n",
      "Relu Train Epoch: 0 [203520/318582 (1%)]\tLoss: 1.055986\n",
      "Epoch: 0, batch: 3181\n",
      "loss None\n",
      "batch time cost: 5.261337757110596\n",
      "Epoch: 0, batch: 3182\n",
      "loss None\n",
      "batch time cost: 5.554502964019775\n",
      "Epoch: 0, batch: 3183\n",
      "loss None\n",
      "batch time cost: 5.27842116355896\n",
      "Epoch: 0, batch: 3184\n",
      "loss None\n",
      "batch time cost: 5.264654159545898\n",
      "Epoch: 0, batch: 3185\n",
      "loss None\n",
      "batch time cost: 5.2797770500183105\n",
      "Epoch: 0, batch: 3186\n",
      "loss None\n",
      "batch time cost: 5.258139133453369\n",
      "Epoch: 0, batch: 3187\n",
      "loss None\n",
      "batch time cost: 5.254790782928467\n",
      "Epoch: 0, batch: 3188\n",
      "loss None\n",
      "batch time cost: 5.273274898529053\n",
      "Epoch: 0, batch: 3189\n",
      "loss None\n",
      "batch time cost: 5.547290086746216\n",
      "Epoch: 0, batch: 3190\n",
      "loss None\n",
      "batch time cost: 5.279841899871826\n",
      "Relu Train Epoch: 0 [204160/318582 (1%)]\tLoss: 0.754430\n",
      "Epoch: 0, batch: 3191\n",
      "loss None\n",
      "batch time cost: 5.215481281280518\n",
      "Epoch: 0, batch: 3192\n",
      "loss None\n",
      "batch time cost: 5.241649150848389\n",
      "Epoch: 0, batch: 3193\n",
      "loss None\n",
      "batch time cost: 5.243539094924927\n",
      "Epoch: 0, batch: 3194\n",
      "loss None\n",
      "batch time cost: 5.380582094192505\n",
      "Epoch: 0, batch: 3195\n",
      "loss None\n",
      "batch time cost: 5.34223484992981\n",
      "Epoch: 0, batch: 3196\n",
      "loss None\n",
      "batch time cost: 5.599354028701782\n",
      "Epoch: 0, batch: 3197\n",
      "loss None\n",
      "batch time cost: 5.238931894302368\n",
      "Epoch: 0, batch: 3198\n",
      "loss None\n",
      "batch time cost: 5.289812326431274\n",
      "Epoch: 0, batch: 3199\n",
      "loss None\n",
      "batch time cost: 5.228418827056885\n",
      "Epoch: 0, batch: 3200\n",
      "loss None\n",
      "batch time cost: 5.235302925109863\n",
      "Relu Train Epoch: 0 [204800/318582 (1%)]\tLoss: 0.819556\n",
      "Epoch: 0, batch: 3201\n",
      "loss None\n",
      "batch time cost: 5.262981176376343\n",
      "Epoch: 0, batch: 3202\n",
      "loss None\n",
      "batch time cost: 5.276764869689941\n",
      "Epoch: 0, batch: 3203\n",
      "loss None\n",
      "batch time cost: 5.2445900440216064\n",
      "Epoch: 0, batch: 3204\n",
      "loss None\n",
      "batch time cost: 5.618063926696777\n",
      "Epoch: 0, batch: 3205\n",
      "loss None\n",
      "batch time cost: 5.269010066986084\n",
      "Epoch: 0, batch: 3206\n",
      "loss None\n",
      "batch time cost: 5.460163831710815\n",
      "Epoch: 0, batch: 3207\n",
      "loss None\n",
      "batch time cost: 5.254812955856323\n",
      "Epoch: 0, batch: 3208\n",
      "loss None\n",
      "batch time cost: 5.310480833053589\n",
      "Epoch: 0, batch: 3209\n",
      "loss None\n",
      "batch time cost: 5.221527814865112\n",
      "Epoch: 0, batch: 3210\n",
      "loss None\n",
      "batch time cost: 5.287911891937256\n",
      "Relu Train Epoch: 0 [205440/318582 (1%)]\tLoss: 0.857920\n",
      "Epoch: 0, batch: 3211\n",
      "loss None\n",
      "batch time cost: 5.581279039382935\n",
      "Epoch: 0, batch: 3212\n",
      "loss None\n",
      "batch time cost: 5.267791986465454\n",
      "Epoch: 0, batch: 3213\n",
      "loss None\n",
      "batch time cost: 5.247259140014648\n",
      "Epoch: 0, batch: 3214\n",
      "loss None\n",
      "batch time cost: 5.260722875595093\n",
      "Epoch: 0, batch: 3215\n",
      "loss None\n",
      "batch time cost: 5.267220973968506\n",
      "Epoch: 0, batch: 3216\n",
      "loss None\n",
      "batch time cost: 5.238480806350708\n",
      "Epoch: 0, batch: 3217\n",
      "loss None\n",
      "batch time cost: 5.320922136306763\n",
      "Epoch: 0, batch: 3218\n",
      "loss None\n",
      "batch time cost: 5.630929231643677\n",
      "Epoch: 0, batch: 3219\n",
      "loss None\n",
      "batch time cost: 5.257680892944336\n",
      "Epoch: 0, batch: 3220\n",
      "loss None\n",
      "batch time cost: 5.353317022323608\n",
      "Relu Train Epoch: 0 [206080/318582 (1%)]\tLoss: 0.719203\n",
      "Epoch: 0, batch: 3221\n",
      "loss None\n",
      "batch time cost: 5.262936115264893\n",
      "Epoch: 0, batch: 3222\n",
      "loss None\n",
      "batch time cost: 5.266142845153809\n",
      "Epoch: 0, batch: 3223\n",
      "loss None\n",
      "batch time cost: 5.25442910194397\n",
      "Epoch: 0, batch: 3224\n",
      "loss None\n",
      "batch time cost: 5.271694183349609\n",
      "Epoch: 0, batch: 3225\n",
      "loss None\n",
      "batch time cost: 5.554182767868042\n",
      "Epoch: 0, batch: 3226\n",
      "loss None\n",
      "batch time cost: 5.21934700012207\n",
      "Epoch: 0, batch: 3227\n",
      "loss None\n",
      "batch time cost: 5.320163011550903\n",
      "Epoch: 0, batch: 3228\n",
      "loss None\n",
      "batch time cost: 5.319443941116333\n",
      "Epoch: 0, batch: 3229\n",
      "loss None\n",
      "batch time cost: 5.258522033691406\n",
      "Epoch: 0, batch: 3230\n",
      "loss None\n",
      "batch time cost: 5.303167104721069\n",
      "Relu Train Epoch: 0 [206720/318582 (1%)]\tLoss: 0.785920\n",
      "Epoch: 0, batch: 3231\n",
      "loss None\n",
      "batch time cost: 5.24432897567749\n",
      "Epoch: 0, batch: 3232\n",
      "loss None\n",
      "batch time cost: 5.249739170074463\n",
      "Epoch: 0, batch: 3233\n",
      "loss None\n",
      "batch time cost: 5.596808910369873\n",
      "Epoch: 0, batch: 3234\n",
      "loss None\n",
      "batch time cost: 5.282203912734985\n",
      "Epoch: 0, batch: 3235\n",
      "loss None\n",
      "batch time cost: 5.285319089889526\n",
      "Epoch: 0, batch: 3236\n",
      "loss None\n",
      "batch time cost: 5.270465135574341\n",
      "Epoch: 0, batch: 3237\n",
      "loss None\n",
      "batch time cost: 5.2368080615997314\n",
      "Epoch: 0, batch: 3238\n",
      "loss None\n",
      "batch time cost: 5.257178783416748\n",
      "Epoch: 0, batch: 3239\n",
      "loss None\n",
      "batch time cost: 5.244004964828491\n",
      "Epoch: 0, batch: 3240\n",
      "loss None\n",
      "batch time cost: 5.582066059112549\n",
      "Relu Train Epoch: 0 [207360/318582 (1%)]\tLoss: 0.919641\n",
      "Epoch: 0, batch: 3241\n",
      "loss None\n",
      "batch time cost: 5.27213716506958\n",
      "Epoch: 0, batch: 3242\n",
      "loss None\n",
      "batch time cost: 5.261007070541382\n",
      "Epoch: 0, batch: 3243\n",
      "loss None\n",
      "batch time cost: 5.267096042633057\n",
      "Epoch: 0, batch: 3244\n",
      "loss None\n",
      "batch time cost: 5.294250249862671\n",
      "Epoch: 0, batch: 3245\n",
      "loss None\n",
      "batch time cost: 5.329472064971924\n",
      "Epoch: 0, batch: 3246\n",
      "loss None\n",
      "batch time cost: 5.2934699058532715\n",
      "Epoch: 0, batch: 3247\n",
      "loss None\n",
      "batch time cost: 5.6321799755096436\n",
      "Epoch: 0, batch: 3248\n",
      "loss None\n",
      "batch time cost: 5.288839817047119\n",
      "Epoch: 0, batch: 3249\n",
      "loss None\n",
      "batch time cost: 5.2289040088653564\n",
      "Epoch: 0, batch: 3250\n",
      "loss None\n",
      "batch time cost: 5.26943302154541\n",
      "Relu Train Epoch: 0 [208000/318582 (1%)]\tLoss: 1.032751\n",
      "Epoch: 0, batch: 3251\n",
      "loss None\n",
      "batch time cost: 5.292393922805786\n",
      "Epoch: 0, batch: 3252\n",
      "loss None\n",
      "batch time cost: 5.266324996948242\n",
      "Epoch: 0, batch: 3253\n",
      "loss None\n",
      "batch time cost: 5.234990119934082\n",
      "Epoch: 0, batch: 3254\n",
      "loss None\n",
      "batch time cost: 5.743469953536987\n",
      "Epoch: 0, batch: 3255\n",
      "loss None\n",
      "batch time cost: 5.729609966278076\n",
      "Epoch: 0, batch: 3256\n",
      "loss None\n",
      "batch time cost: 5.289513111114502\n",
      "Epoch: 0, batch: 3257\n",
      "loss None\n",
      "batch time cost: 5.31115198135376\n",
      "Epoch: 0, batch: 3258\n",
      "loss None\n",
      "batch time cost: 5.263708829879761\n",
      "Epoch: 0, batch: 3259\n",
      "loss None\n",
      "batch time cost: 5.247159957885742\n",
      "Epoch: 0, batch: 3260\n",
      "loss None\n",
      "batch time cost: 5.246521234512329\n",
      "Relu Train Epoch: 0 [208640/318582 (1%)]\tLoss: 0.791997\n",
      "Epoch: 0, batch: 3261\n",
      "loss None\n",
      "batch time cost: 5.586427211761475\n",
      "Epoch: 0, batch: 3262\n",
      "loss None\n",
      "batch time cost: 5.241466283798218\n",
      "Epoch: 0, batch: 3263\n",
      "loss None\n",
      "batch time cost: 5.346551179885864\n",
      "Epoch: 0, batch: 3264\n",
      "loss None\n",
      "batch time cost: 7.6281561851501465\n",
      "Epoch: 0, batch: 3265\n",
      "loss None\n",
      "batch time cost: 5.317117214202881\n",
      "Epoch: 0, batch: 3266\n",
      "loss None\n",
      "batch time cost: 5.284633159637451\n",
      "Epoch: 0, batch: 3267\n",
      "loss None\n",
      "batch time cost: 5.241556882858276\n",
      "Epoch: 0, batch: 3268\n",
      "loss None\n",
      "batch time cost: 5.246744632720947\n",
      "Epoch: 0, batch: 3269\n",
      "loss None\n",
      "batch time cost: 5.566437005996704\n",
      "Epoch: 0, batch: 3270\n",
      "loss None\n",
      "batch time cost: 5.237156867980957\n",
      "Relu Train Epoch: 0 [209280/318582 (1%)]\tLoss: 0.858564\n",
      "Epoch: 0, batch: 3271\n",
      "loss None\n",
      "batch time cost: 5.285488128662109\n",
      "Epoch: 0, batch: 3272\n",
      "loss None\n",
      "batch time cost: 5.315832853317261\n",
      "Epoch: 0, batch: 3273\n",
      "loss None\n",
      "batch time cost: 5.272709131240845\n",
      "Epoch: 0, batch: 3274\n",
      "loss None\n",
      "batch time cost: 5.301095008850098\n",
      "Epoch: 0, batch: 3275\n",
      "loss None\n",
      "batch time cost: 5.314218997955322\n",
      "Epoch: 0, batch: 3276\n",
      "loss None\n",
      "batch time cost: 5.5732691287994385\n",
      "Epoch: 0, batch: 3277\n",
      "loss None\n",
      "batch time cost: 5.253868818283081\n",
      "Epoch: 0, batch: 3278\n",
      "loss None\n",
      "batch time cost: 5.313009738922119\n",
      "Epoch: 0, batch: 3279\n",
      "loss None\n",
      "batch time cost: 5.194048166275024\n",
      "Epoch: 0, batch: 3280\n",
      "loss None\n",
      "batch time cost: 5.271404981613159\n",
      "Relu Train Epoch: 0 [209920/318582 (1%)]\tLoss: 0.657904\n",
      "Epoch: 0, batch: 3281\n",
      "loss None\n",
      "batch time cost: 5.2784647941589355\n",
      "Epoch: 0, batch: 3282\n",
      "loss None\n",
      "batch time cost: 5.300455808639526\n",
      "Epoch: 0, batch: 3283\n",
      "loss None\n",
      "batch time cost: 5.570175886154175\n",
      "Epoch: 0, batch: 3284\n",
      "loss None\n",
      "batch time cost: 5.326222896575928\n",
      "Epoch: 0, batch: 3285\n",
      "loss None\n",
      "batch time cost: 5.30151891708374\n",
      "Epoch: 0, batch: 3286\n",
      "loss None\n",
      "batch time cost: 5.344310760498047\n",
      "Epoch: 0, batch: 3287\n",
      "loss None\n",
      "batch time cost: 5.2823779582977295\n",
      "Epoch: 0, batch: 3288\n",
      "loss None\n",
      "batch time cost: 5.3088250160217285\n",
      "Epoch: 0, batch: 3289\n",
      "loss None\n",
      "batch time cost: 5.291561841964722\n",
      "Epoch: 0, batch: 3290\n",
      "loss None\n",
      "batch time cost: 5.5780041217803955\n",
      "Relu Train Epoch: 0 [210560/318582 (1%)]\tLoss: 0.940637\n",
      "Epoch: 0, batch: 3291\n",
      "loss None\n",
      "batch time cost: 5.250224828720093\n",
      "Epoch: 0, batch: 3292\n",
      "loss None\n",
      "batch time cost: 5.256984233856201\n",
      "Epoch: 0, batch: 3293\n",
      "loss None\n",
      "batch time cost: 5.224498987197876\n",
      "Epoch: 0, batch: 3294\n",
      "loss None\n",
      "batch time cost: 5.2532570362091064\n",
      "Epoch: 0, batch: 3295\n",
      "loss None\n",
      "batch time cost: 5.362203121185303\n",
      "Epoch: 0, batch: 3296\n",
      "loss None\n",
      "batch time cost: 5.342266082763672\n",
      "Epoch: 0, batch: 3297\n",
      "loss None\n",
      "batch time cost: 5.255868911743164\n",
      "Epoch: 0, batch: 3298\n",
      "loss None\n",
      "batch time cost: 5.580664873123169\n",
      "Epoch: 0, batch: 3299\n",
      "loss None\n",
      "batch time cost: 5.261722087860107\n",
      "Epoch: 0, batch: 3300\n",
      "loss None\n",
      "batch time cost: 5.28348708152771\n",
      "Relu Train Epoch: 0 [211200/318582 (1%)]\tLoss: 0.758417\n",
      "Epoch: 0, batch: 3301\n",
      "loss None\n",
      "batch time cost: 5.266287088394165\n",
      "Epoch: 0, batch: 3302\n",
      "loss None\n",
      "batch time cost: 5.27300500869751\n",
      "Epoch: 0, batch: 3303\n",
      "loss None\n",
      "batch time cost: 5.291531085968018\n",
      "Epoch: 0, batch: 3304\n",
      "loss None\n",
      "batch time cost: 5.29921293258667\n",
      "Epoch: 0, batch: 3305\n",
      "loss None\n",
      "batch time cost: 5.5732128620147705\n",
      "Epoch: 0, batch: 3306\n",
      "loss None\n",
      "batch time cost: 5.338464975357056\n",
      "Epoch: 0, batch: 3307\n",
      "loss None\n",
      "batch time cost: 5.323746919631958\n",
      "Epoch: 0, batch: 3308\n",
      "loss None\n",
      "batch time cost: 5.280935049057007\n",
      "Epoch: 0, batch: 3309\n",
      "loss None\n",
      "batch time cost: 5.281272649765015\n",
      "Epoch: 0, batch: 3310\n",
      "loss None\n",
      "batch time cost: 5.287487983703613\n",
      "Relu Train Epoch: 0 [211840/318582 (1%)]\tLoss: 0.717579\n",
      "Epoch: 0, batch: 3311\n",
      "loss None\n",
      "batch time cost: 5.330787181854248\n",
      "Epoch: 0, batch: 3312\n",
      "loss None\n",
      "batch time cost: 5.701372861862183\n",
      "Epoch: 0, batch: 3313\n",
      "loss None\n",
      "batch time cost: 5.287720203399658\n",
      "Epoch: 0, batch: 3314\n",
      "loss None\n",
      "batch time cost: 5.259648084640503\n",
      "Epoch: 0, batch: 3315\n",
      "loss None\n",
      "batch time cost: 5.276215076446533\n",
      "Epoch: 0, batch: 3316\n",
      "loss None\n",
      "batch time cost: 5.345376014709473\n",
      "Epoch: 0, batch: 3317\n",
      "loss None\n",
      "batch time cost: 5.274672269821167\n",
      "Epoch: 0, batch: 3318\n",
      "loss None\n",
      "batch time cost: 5.316604137420654\n",
      "Epoch: 0, batch: 3319\n",
      "loss None\n",
      "batch time cost: 5.738172769546509\n",
      "Epoch: 0, batch: 3320\n",
      "loss None\n",
      "batch time cost: 5.320969104766846\n",
      "Relu Train Epoch: 0 [212480/318582 (1%)]\tLoss: 0.779273\n",
      "Epoch: 0, batch: 3321\n",
      "loss None\n",
      "batch time cost: 5.2553253173828125\n",
      "Epoch: 0, batch: 3322\n",
      "loss None\n",
      "batch time cost: 5.287931203842163\n",
      "Epoch: 0, batch: 3323\n",
      "loss None\n",
      "batch time cost: 5.300228834152222\n",
      "Epoch: 0, batch: 3324\n",
      "loss None\n",
      "batch time cost: 5.269018888473511\n",
      "Epoch: 0, batch: 3325\n",
      "loss None\n",
      "batch time cost: 5.242743730545044\n",
      "Epoch: 0, batch: 3326\n",
      "loss None\n",
      "batch time cost: 5.628229856491089\n",
      "Epoch: 0, batch: 3327\n",
      "loss None\n",
      "batch time cost: 5.2583909034729\n",
      "Epoch: 0, batch: 3328\n",
      "loss None\n",
      "batch time cost: 5.246436834335327\n",
      "Epoch: 0, batch: 3329\n",
      "loss None\n",
      "batch time cost: 5.308588027954102\n",
      "Epoch: 0, batch: 3330\n",
      "loss None\n",
      "batch time cost: 5.35722804069519\n",
      "Relu Train Epoch: 0 [213120/318582 (1%)]\tLoss: 0.786646\n",
      "Epoch: 0, batch: 3331\n",
      "loss None\n",
      "batch time cost: 5.233828067779541\n",
      "Epoch: 0, batch: 3332\n",
      "loss None\n",
      "batch time cost: 5.287874698638916\n",
      "Epoch: 0, batch: 3333\n",
      "loss None\n",
      "batch time cost: 5.325480937957764\n",
      "Epoch: 0, batch: 3334\n",
      "loss None\n",
      "batch time cost: 5.5601208209991455\n",
      "Epoch: 0, batch: 3335\n",
      "loss None\n",
      "batch time cost: 5.317769289016724\n",
      "Epoch: 0, batch: 3336\n",
      "loss None\n",
      "batch time cost: 5.271950721740723\n",
      "Epoch: 0, batch: 3337\n",
      "loss None\n",
      "batch time cost: 5.285597801208496\n",
      "Epoch: 0, batch: 3338\n",
      "loss None\n",
      "batch time cost: 5.311514139175415\n",
      "Epoch: 0, batch: 3339\n",
      "loss None\n",
      "batch time cost: 5.280696868896484\n",
      "Epoch: 0, batch: 3340\n",
      "loss None\n",
      "batch time cost: 5.274256944656372\n",
      "Relu Train Epoch: 0 [213760/318582 (1%)]\tLoss: 0.808640\n",
      "Epoch: 0, batch: 3341\n",
      "loss None\n",
      "batch time cost: 7.154480934143066\n",
      "Epoch: 0, batch: 3342\n",
      "loss None\n",
      "batch time cost: 5.328217029571533\n",
      "Epoch: 0, batch: 3343\n",
      "loss None\n",
      "batch time cost: 5.322683095932007\n",
      "Epoch: 0, batch: 3344\n",
      "loss None\n",
      "batch time cost: 5.261335849761963\n",
      "Epoch: 0, batch: 3345\n",
      "loss None\n",
      "batch time cost: 5.266891956329346\n",
      "Epoch: 0, batch: 3346\n",
      "loss None\n",
      "batch time cost: 5.263529062271118\n",
      "Epoch: 0, batch: 3347\n",
      "loss None\n",
      "batch time cost: 5.201478958129883\n",
      "Epoch: 0, batch: 3348\n",
      "loss None\n",
      "batch time cost: 5.755094051361084\n",
      "Epoch: 0, batch: 3349\n",
      "loss None\n",
      "batch time cost: 5.2224977016448975\n",
      "Epoch: 0, batch: 3350\n",
      "loss None\n",
      "batch time cost: 5.250426292419434\n",
      "Relu Train Epoch: 0 [214400/318582 (1%)]\tLoss: 0.702886\n",
      "Epoch: 0, batch: 3351\n",
      "loss None\n",
      "batch time cost: 5.392579078674316\n",
      "Epoch: 0, batch: 3352\n",
      "loss None\n",
      "batch time cost: 5.438321828842163\n",
      "Epoch: 0, batch: 3353\n",
      "loss None\n",
      "batch time cost: 5.340494155883789\n",
      "Epoch: 0, batch: 3354\n",
      "loss None\n",
      "batch time cost: 5.332736015319824\n",
      "Epoch: 0, batch: 3355\n",
      "loss None\n",
      "batch time cost: 5.624953031539917\n",
      "Epoch: 0, batch: 3356\n",
      "loss None\n",
      "batch time cost: 5.304833173751831\n",
      "Epoch: 0, batch: 3357\n",
      "loss None\n",
      "batch time cost: 5.2498650550842285\n",
      "Epoch: 0, batch: 3358\n",
      "loss None\n",
      "batch time cost: 5.294059991836548\n",
      "Epoch: 0, batch: 3359\n",
      "loss None\n",
      "batch time cost: 5.378335952758789\n",
      "Epoch: 0, batch: 3360\n",
      "loss None\n",
      "batch time cost: 5.253486156463623\n",
      "Relu Train Epoch: 0 [215040/318582 (1%)]\tLoss: 0.664259\n",
      "Epoch: 0, batch: 3361\n",
      "loss None\n",
      "batch time cost: 5.311797142028809\n",
      "Epoch: 0, batch: 3362\n",
      "loss None\n",
      "batch time cost: 5.270813941955566\n",
      "Epoch: 0, batch: 3363\n",
      "loss None\n",
      "batch time cost: 5.5825910568237305\n",
      "Epoch: 0, batch: 3364\n",
      "loss None\n",
      "batch time cost: 5.313149929046631\n",
      "Epoch: 0, batch: 3365\n",
      "loss None\n",
      "batch time cost: 5.193548917770386\n",
      "Epoch: 0, batch: 3366\n",
      "loss None\n",
      "batch time cost: 5.277014970779419\n",
      "Epoch: 0, batch: 3367\n",
      "loss None\n",
      "batch time cost: 5.242131948471069\n",
      "Epoch: 0, batch: 3368\n",
      "loss None\n",
      "batch time cost: 5.249969005584717\n",
      "Epoch: 0, batch: 3369\n",
      "loss None\n",
      "batch time cost: 5.247842073440552\n",
      "Epoch: 0, batch: 3370\n",
      "loss None\n",
      "batch time cost: 5.57325291633606\n",
      "Relu Train Epoch: 0 [215680/318582 (1%)]\tLoss: 0.852624\n",
      "Epoch: 0, batch: 3371\n",
      "loss None\n",
      "batch time cost: 5.280850172042847\n",
      "Epoch: 0, batch: 3372\n",
      "loss None\n",
      "batch time cost: 5.261938810348511\n",
      "Epoch: 0, batch: 3373\n",
      "loss None\n",
      "batch time cost: 5.296329021453857\n",
      "Epoch: 0, batch: 3374\n",
      "loss None\n",
      "batch time cost: 5.770934104919434\n",
      "Epoch: 0, batch: 3375\n",
      "loss None\n",
      "batch time cost: 5.322240114212036\n",
      "Epoch: 0, batch: 3376\n",
      "loss None\n",
      "batch time cost: 5.28928804397583\n",
      "Epoch: 0, batch: 3377\n",
      "loss None\n",
      "batch time cost: 5.682729959487915\n",
      "Epoch: 0, batch: 3378\n",
      "loss None\n",
      "batch time cost: 5.224843978881836\n",
      "Epoch: 0, batch: 3379\n",
      "loss None\n",
      "batch time cost: 5.265637159347534\n",
      "Epoch: 0, batch: 3380\n",
      "loss None\n",
      "batch time cost: 5.279011964797974\n",
      "Relu Train Epoch: 0 [216320/318582 (1%)]\tLoss: 0.818716\n",
      "Epoch: 0, batch: 3381\n",
      "loss None\n",
      "batch time cost: 5.260379076004028\n",
      "Epoch: 0, batch: 3382\n",
      "loss None\n",
      "batch time cost: 5.273690223693848\n",
      "Epoch: 0, batch: 3383\n",
      "loss None\n",
      "batch time cost: 5.1913230419158936\n",
      "Epoch: 0, batch: 3384\n",
      "loss None\n",
      "batch time cost: 5.6027679443359375\n",
      "Epoch: 0, batch: 3385\n",
      "loss None\n",
      "batch time cost: 5.328885793685913\n",
      "Epoch: 0, batch: 3386\n",
      "loss None\n",
      "batch time cost: 5.288438081741333\n",
      "Epoch: 0, batch: 3387\n",
      "loss None\n",
      "batch time cost: 5.2936670780181885\n",
      "Epoch: 0, batch: 3388\n",
      "loss None\n",
      "batch time cost: 5.31687593460083\n",
      "Epoch: 0, batch: 3389\n",
      "loss None\n",
      "batch time cost: 5.27739691734314\n",
      "Epoch: 0, batch: 3390\n",
      "loss None\n",
      "batch time cost: 5.295032739639282\n",
      "Relu Train Epoch: 0 [216960/318582 (1%)]\tLoss: 0.933449\n",
      "Epoch: 0, batch: 3391\n",
      "loss None\n",
      "batch time cost: 5.558024883270264\n",
      "Epoch: 0, batch: 3392\n",
      "loss None\n",
      "batch time cost: 5.24606728553772\n",
      "Epoch: 0, batch: 3393\n",
      "loss None\n",
      "batch time cost: 5.220059871673584\n",
      "Epoch: 0, batch: 3394\n",
      "loss None\n",
      "batch time cost: 5.256510972976685\n",
      "Epoch: 0, batch: 3395\n",
      "loss None\n",
      "batch time cost: 5.344909191131592\n",
      "Epoch: 0, batch: 3396\n",
      "loss None\n",
      "batch time cost: 5.2796831130981445\n",
      "Epoch: 0, batch: 3397\n",
      "loss None\n",
      "batch time cost: 5.299316883087158\n",
      "Epoch: 0, batch: 3398\n",
      "loss None\n",
      "batch time cost: 5.326872110366821\n",
      "Epoch: 0, batch: 3399\n",
      "loss None\n",
      "batch time cost: 5.565027236938477\n",
      "Epoch: 0, batch: 3400\n",
      "loss None\n",
      "batch time cost: 5.331272840499878\n",
      "Relu Train Epoch: 0 [217600/318582 (1%)]\tLoss: 0.845480\n",
      "Epoch: 0, batch: 3401\n",
      "loss None\n",
      "batch time cost: 5.331682205200195\n",
      "Epoch: 0, batch: 3402\n",
      "loss None\n",
      "batch time cost: 5.359761953353882\n",
      "Epoch: 0, batch: 3403\n",
      "loss None\n",
      "batch time cost: 5.318731069564819\n",
      "Epoch: 0, batch: 3404\n",
      "loss None\n",
      "batch time cost: 5.304610013961792\n",
      "Epoch: 0, batch: 3405\n",
      "loss None\n",
      "batch time cost: 5.343013763427734\n",
      "Epoch: 0, batch: 3406\n",
      "loss None\n",
      "batch time cost: 5.5636889934539795\n",
      "Epoch: 0, batch: 3407\n",
      "loss None\n",
      "batch time cost: 5.308756113052368\n",
      "Epoch: 0, batch: 3408\n",
      "loss None\n",
      "batch time cost: 5.294320106506348\n",
      "Epoch: 0, batch: 3409\n",
      "loss None\n",
      "batch time cost: 5.251646995544434\n",
      "Epoch: 0, batch: 3410\n",
      "loss None\n",
      "batch time cost: 5.225464105606079\n",
      "Relu Train Epoch: 0 [218240/318582 (1%)]\tLoss: 1.118840\n",
      "Epoch: 0, batch: 3411\n",
      "loss None\n",
      "batch time cost: 5.264795780181885\n",
      "Epoch: 0, batch: 3412\n",
      "loss None\n",
      "batch time cost: 5.338609933853149\n",
      "Epoch: 0, batch: 3413\n",
      "loss None\n",
      "batch time cost: 5.626204252243042\n",
      "Epoch: 0, batch: 3414\n",
      "loss None\n",
      "batch time cost: 5.277503967285156\n",
      "Epoch: 0, batch: 3415\n",
      "loss None\n",
      "batch time cost: 5.220082998275757\n",
      "Epoch: 0, batch: 3416\n",
      "loss None\n",
      "batch time cost: 5.276882886886597\n",
      "Epoch: 0, batch: 3417\n",
      "loss None\n",
      "batch time cost: 5.271401882171631\n",
      "Epoch: 0, batch: 3418\n",
      "loss None\n",
      "batch time cost: 5.269927978515625\n",
      "Epoch: 0, batch: 3419\n",
      "loss None\n",
      "batch time cost: 5.357395887374878\n",
      "Epoch: 0, batch: 3420\n",
      "loss None\n",
      "batch time cost: 5.6140711307525635\n",
      "Relu Train Epoch: 0 [218880/318582 (1%)]\tLoss: 0.792834\n",
      "Epoch: 0, batch: 3421\n",
      "loss None\n",
      "batch time cost: 5.284015893936157\n",
      "Epoch: 0, batch: 3422\n",
      "loss None\n",
      "batch time cost: 5.24001407623291\n",
      "Epoch: 0, batch: 3423\n",
      "loss None\n",
      "batch time cost: 5.274129152297974\n",
      "Epoch: 0, batch: 3424\n",
      "loss None\n",
      "batch time cost: 5.305836915969849\n",
      "Epoch: 0, batch: 3425\n",
      "loss None\n",
      "batch time cost: 5.24386191368103\n",
      "Epoch: 0, batch: 3426\n",
      "loss None\n",
      "batch time cost: 5.235473155975342\n",
      "Epoch: 0, batch: 3427\n",
      "loss None\n",
      "batch time cost: 5.2841339111328125\n",
      "Epoch: 0, batch: 3428\n",
      "loss None\n",
      "batch time cost: 5.532318830490112\n",
      "Epoch: 0, batch: 3429\n",
      "loss None\n",
      "batch time cost: 5.324148893356323\n",
      "Epoch: 0, batch: 3430\n",
      "loss None\n",
      "batch time cost: 5.255009174346924\n",
      "Relu Train Epoch: 0 [219520/318582 (1%)]\tLoss: 0.792929\n",
      "Epoch: 0, batch: 3431\n",
      "loss None\n",
      "batch time cost: 5.262316942214966\n",
      "Epoch: 0, batch: 3432\n",
      "loss None\n",
      "batch time cost: 5.365894794464111\n",
      "Epoch: 0, batch: 3433\n",
      "loss None\n",
      "batch time cost: 5.251672029495239\n",
      "Epoch: 0, batch: 3434\n",
      "loss None\n",
      "batch time cost: 5.305025100708008\n",
      "Epoch: 0, batch: 3435\n",
      "loss None\n",
      "batch time cost: 5.540184736251831\n",
      "Epoch: 0, batch: 3436\n",
      "loss None\n",
      "batch time cost: 5.291724920272827\n",
      "Epoch: 0, batch: 3437\n",
      "loss None\n",
      "batch time cost: 5.243496894836426\n",
      "Epoch: 0, batch: 3438\n",
      "loss None\n",
      "batch time cost: 5.291201114654541\n",
      "Epoch: 0, batch: 3439\n",
      "loss None\n",
      "batch time cost: 5.330472230911255\n",
      "Epoch: 0, batch: 3440\n",
      "loss None\n",
      "batch time cost: 5.276601791381836\n",
      "Relu Train Epoch: 0 [220160/318582 (1%)]\tLoss: 0.630683\n",
      "Epoch: 0, batch: 3441\n",
      "loss None\n",
      "batch time cost: 5.26359486579895\n",
      "Epoch: 0, batch: 3442\n",
      "loss None\n",
      "batch time cost: 5.620367050170898\n",
      "Epoch: 0, batch: 3443\n",
      "loss None\n",
      "batch time cost: 5.223771095275879\n",
      "Epoch: 0, batch: 3444\n",
      "loss None\n",
      "batch time cost: 5.27950382232666\n",
      "Epoch: 0, batch: 3445\n",
      "loss None\n",
      "batch time cost: 5.238050222396851\n",
      "Epoch: 0, batch: 3446\n",
      "loss None\n",
      "batch time cost: 5.253598213195801\n",
      "Epoch: 0, batch: 3447\n",
      "loss None\n",
      "batch time cost: 5.285181999206543\n",
      "Epoch: 0, batch: 3448\n",
      "loss None\n",
      "batch time cost: 5.35505485534668\n",
      "Epoch: 0, batch: 3449\n",
      "loss None\n",
      "batch time cost: 5.5671491622924805\n",
      "Epoch: 0, batch: 3450\n",
      "loss None\n",
      "batch time cost: 5.20849609375\n",
      "Relu Train Epoch: 0 [220800/318582 (1%)]\tLoss: 0.888261\n",
      "Epoch: 0, batch: 3451\n",
      "loss None\n",
      "batch time cost: 5.26345682144165\n",
      "Epoch: 0, batch: 3452\n",
      "loss None\n",
      "batch time cost: 5.217281818389893\n",
      "Epoch: 0, batch: 3453\n",
      "loss None\n",
      "batch time cost: 5.398556232452393\n",
      "Epoch: 0, batch: 3454\n",
      "loss None\n",
      "batch time cost: 5.361632823944092\n",
      "Epoch: 0, batch: 3455\n",
      "loss None\n",
      "batch time cost: 5.280916929244995\n",
      "Epoch: 0, batch: 3456\n",
      "loss None\n",
      "batch time cost: 5.576978921890259\n",
      "Epoch: 0, batch: 3457\n",
      "loss None\n",
      "batch time cost: 5.263530015945435\n",
      "Epoch: 0, batch: 3458\n",
      "loss None\n",
      "batch time cost: 5.2631800174713135\n",
      "Epoch: 0, batch: 3459\n",
      "loss None\n",
      "batch time cost: 5.274027109146118\n",
      "Epoch: 0, batch: 3460\n",
      "loss None\n",
      "batch time cost: 5.3113226890563965\n",
      "Relu Train Epoch: 0 [221440/318582 (1%)]\tLoss: 0.875961\n",
      "Epoch: 0, batch: 3461\n",
      "loss None\n",
      "batch time cost: 5.263699769973755\n",
      "Epoch: 0, batch: 3462\n",
      "loss None\n",
      "batch time cost: 5.33938193321228\n",
      "Epoch: 0, batch: 3463\n",
      "loss None\n",
      "batch time cost: 5.276309013366699\n",
      "Epoch: 0, batch: 3464\n",
      "loss None\n",
      "batch time cost: 5.946365118026733\n",
      "Epoch: 0, batch: 3465\n",
      "loss None\n",
      "batch time cost: 5.3099470138549805\n",
      "Epoch: 0, batch: 3466\n",
      "loss None\n",
      "batch time cost: 5.307214975357056\n",
      "Epoch: 0, batch: 3467\n",
      "loss None\n",
      "batch time cost: 5.22931981086731\n",
      "Epoch: 0, batch: 3468\n",
      "loss None\n",
      "batch time cost: 5.291974067687988\n",
      "Epoch: 0, batch: 3469\n",
      "loss None\n",
      "batch time cost: 5.3113322257995605\n",
      "Epoch: 0, batch: 3470\n",
      "loss None\n",
      "batch time cost: 5.272694110870361\n",
      "Relu Train Epoch: 0 [222080/318582 (1%)]\tLoss: 0.923023\n",
      "Epoch: 0, batch: 3471\n",
      "loss None\n",
      "batch time cost: 5.569413900375366\n",
      "Epoch: 0, batch: 3472\n",
      "loss None\n",
      "batch time cost: 5.318667888641357\n",
      "Epoch: 0, batch: 3473\n",
      "loss None\n",
      "batch time cost: 5.2707359790802\n",
      "Epoch: 0, batch: 3474\n",
      "loss None\n",
      "batch time cost: 5.251599073410034\n",
      "Epoch: 0, batch: 3475\n",
      "loss None\n",
      "batch time cost: 5.313253879547119\n",
      "Epoch: 0, batch: 3476\n",
      "loss None\n",
      "batch time cost: 5.342068910598755\n",
      "Epoch: 0, batch: 3477\n",
      "loss None\n",
      "batch time cost: 5.324481964111328\n",
      "Epoch: 0, batch: 3478\n",
      "loss None\n",
      "batch time cost: 5.634710073471069\n",
      "Epoch: 0, batch: 3479\n",
      "loss None\n",
      "batch time cost: 5.295197010040283\n",
      "Epoch: 0, batch: 3480\n",
      "loss None\n",
      "batch time cost: 5.314901113510132\n",
      "Relu Train Epoch: 0 [222720/318582 (1%)]\tLoss: 0.888822\n",
      "Epoch: 0, batch: 3481\n",
      "loss None\n",
      "batch time cost: 5.277112245559692\n",
      "Epoch: 0, batch: 3482\n",
      "loss None\n",
      "batch time cost: 5.2775468826293945\n",
      "Epoch: 0, batch: 3483\n",
      "loss None\n",
      "batch time cost: 5.281116008758545\n",
      "Epoch: 0, batch: 3484\n",
      "loss None\n",
      "batch time cost: 5.309719800949097\n",
      "Epoch: 0, batch: 3485\n",
      "loss None\n",
      "batch time cost: 5.589972019195557\n",
      "Epoch: 0, batch: 3486\n",
      "loss None\n",
      "batch time cost: 5.283988952636719\n",
      "Epoch: 0, batch: 3487\n",
      "loss None\n",
      "batch time cost: 5.326900005340576\n",
      "Epoch: 0, batch: 3488\n",
      "loss None\n",
      "batch time cost: 5.302302837371826\n",
      "Epoch: 0, batch: 3489\n",
      "loss None\n",
      "batch time cost: 5.286749362945557\n",
      "Epoch: 0, batch: 3490\n",
      "loss None\n",
      "batch time cost: 5.276160955429077\n",
      "Relu Train Epoch: 0 [223360/318582 (1%)]\tLoss: 0.823463\n",
      "Epoch: 0, batch: 3491\n",
      "loss None\n",
      "batch time cost: 5.278645992279053\n",
      "Epoch: 0, batch: 3492\n",
      "loss None\n",
      "batch time cost: 5.306120157241821\n",
      "Epoch: 0, batch: 3493\n",
      "loss None\n",
      "batch time cost: 5.593145132064819\n",
      "Epoch: 0, batch: 3494\n",
      "loss None\n",
      "batch time cost: 5.263935089111328\n",
      "Epoch: 0, batch: 3495\n",
      "loss None\n",
      "batch time cost: 7.152246952056885\n",
      "Epoch: 0, batch: 3496\n",
      "loss None\n",
      "batch time cost: 5.3420350551605225\n",
      "Epoch: 0, batch: 3497\n",
      "loss None\n",
      "batch time cost: 5.396517753601074\n",
      "Epoch: 0, batch: 3498\n",
      "loss None\n",
      "batch time cost: 5.279628038406372\n",
      "Epoch: 0, batch: 3499\n",
      "loss None\n",
      "batch time cost: 5.232730150222778\n",
      "Epoch: 0, batch: 3500\n",
      "loss None\n",
      "batch time cost: 5.669773817062378\n",
      "Relu Train Epoch: 0 [224000/318582 (1%)]\tLoss: 0.824802\n",
      "Epoch: 0, batch: 3501\n",
      "loss None\n",
      "batch time cost: 5.349699974060059\n",
      "Epoch: 0, batch: 3502\n",
      "loss None\n",
      "batch time cost: 5.270200729370117\n",
      "Epoch: 0, batch: 3503\n",
      "loss None\n",
      "batch time cost: 5.256695985794067\n",
      "Epoch: 0, batch: 3504\n",
      "loss None\n",
      "batch time cost: 5.251180648803711\n",
      "Epoch: 0, batch: 3505\n",
      "loss None\n",
      "batch time cost: 5.246487140655518\n",
      "Epoch: 0, batch: 3506\n",
      "loss None\n",
      "batch time cost: 5.278985977172852\n",
      "Epoch: 0, batch: 3507\n",
      "loss None\n",
      "batch time cost: 5.541420221328735\n",
      "Epoch: 0, batch: 3508\n",
      "loss None\n",
      "batch time cost: 5.231796979904175\n",
      "Epoch: 0, batch: 3509\n",
      "loss None\n",
      "batch time cost: 5.335932970046997\n",
      "Epoch: 0, batch: 3510\n",
      "loss None\n",
      "batch time cost: 5.313344717025757\n",
      "Relu Train Epoch: 0 [224640/318582 (1%)]\tLoss: 0.400972\n",
      "Epoch: 0, batch: 3511\n",
      "loss None\n",
      "batch time cost: 5.280968904495239\n",
      "Epoch: 0, batch: 3512\n",
      "loss None\n",
      "batch time cost: 5.316385984420776\n",
      "Epoch: 0, batch: 3513\n",
      "loss None\n",
      "batch time cost: 5.323822021484375\n",
      "Epoch: 0, batch: 3514\n",
      "loss None\n",
      "batch time cost: 5.568204164505005\n",
      "Epoch: 0, batch: 3515\n",
      "loss None\n",
      "batch time cost: 5.259886741638184\n",
      "Epoch: 0, batch: 3516\n",
      "loss None\n",
      "batch time cost: 5.294786691665649\n",
      "Epoch: 0, batch: 3517\n",
      "loss None\n",
      "batch time cost: 5.292466878890991\n",
      "Epoch: 0, batch: 3518\n",
      "loss None\n",
      "batch time cost: 5.275238037109375\n",
      "Epoch: 0, batch: 3519\n",
      "loss None\n",
      "batch time cost: 5.253047943115234\n",
      "Epoch: 0, batch: 3520\n",
      "loss None\n",
      "batch time cost: 5.390057325363159\n",
      "Relu Train Epoch: 0 [225280/318582 (1%)]\tLoss: 0.788641\n",
      "Epoch: 0, batch: 3521\n",
      "loss None\n",
      "batch time cost: 5.70120906829834\n",
      "Epoch: 0, batch: 3522\n",
      "loss None\n",
      "batch time cost: 5.290258169174194\n",
      "Epoch: 0, batch: 3523\n",
      "loss None\n",
      "batch time cost: 5.238269805908203\n",
      "Epoch: 0, batch: 3524\n",
      "loss None\n",
      "batch time cost: 5.279917001724243\n",
      "Epoch: 0, batch: 3525\n",
      "loss None\n",
      "batch time cost: 5.264309883117676\n",
      "Epoch: 0, batch: 3526\n",
      "loss None\n",
      "batch time cost: 5.270794868469238\n",
      "Epoch: 0, batch: 3527\n",
      "loss None\n",
      "batch time cost: 5.227912902832031\n",
      "Epoch: 0, batch: 3528\n",
      "loss None\n",
      "batch time cost: 5.242036819458008\n",
      "Epoch: 0, batch: 3529\n",
      "loss None\n",
      "batch time cost: 5.567279815673828\n",
      "Epoch: 0, batch: 3530\n",
      "loss None\n",
      "batch time cost: 5.357676029205322\n",
      "Relu Train Epoch: 0 [225920/318582 (1%)]\tLoss: 0.608143\n",
      "Epoch: 0, batch: 3531\n",
      "loss None\n",
      "batch time cost: 5.331921100616455\n",
      "Epoch: 0, batch: 3532\n",
      "loss None\n",
      "batch time cost: 5.338803052902222\n",
      "Epoch: 0, batch: 3533\n",
      "loss None\n",
      "batch time cost: 5.258623838424683\n",
      "Epoch: 0, batch: 3534\n",
      "loss None\n",
      "batch time cost: 5.250432014465332\n",
      "Epoch: 0, batch: 3535\n",
      "loss None\n",
      "batch time cost: 5.247057914733887\n",
      "Epoch: 0, batch: 3536\n",
      "loss None\n",
      "batch time cost: 5.640748023986816\n",
      "Epoch: 0, batch: 3537\n",
      "loss None\n",
      "batch time cost: 5.250277996063232\n",
      "Epoch: 0, batch: 3538\n",
      "loss None\n",
      "batch time cost: 5.254286050796509\n",
      "Epoch: 0, batch: 3539\n",
      "loss None\n",
      "batch time cost: 5.281268835067749\n",
      "Epoch: 0, batch: 3540\n",
      "loss None\n",
      "batch time cost: 5.249580144882202\n",
      "Relu Train Epoch: 0 [226560/318582 (1%)]\tLoss: 0.751413\n",
      "Epoch: 0, batch: 3541\n",
      "loss None\n",
      "batch time cost: 5.268324851989746\n",
      "Epoch: 0, batch: 3542\n",
      "loss None\n",
      "batch time cost: 5.265094041824341\n",
      "Epoch: 0, batch: 3543\n",
      "loss None\n",
      "batch time cost: 5.5912933349609375\n",
      "Epoch: 0, batch: 3544\n",
      "loss None\n",
      "batch time cost: 5.282442092895508\n",
      "Epoch: 0, batch: 3545\n",
      "loss None\n",
      "batch time cost: 5.269821882247925\n",
      "Epoch: 0, batch: 3546\n",
      "loss None\n",
      "batch time cost: 5.237997770309448\n",
      "Epoch: 0, batch: 3547\n",
      "loss None\n",
      "batch time cost: 5.275870084762573\n",
      "Epoch: 0, batch: 3548\n",
      "loss None\n",
      "batch time cost: 5.235578775405884\n",
      "Epoch: 0, batch: 3549\n",
      "loss None\n",
      "batch time cost: 5.266278028488159\n",
      "Epoch: 0, batch: 3550\n",
      "loss None\n",
      "batch time cost: 5.644093990325928\n",
      "Relu Train Epoch: 0 [227200/318582 (1%)]\tLoss: 0.997391\n",
      "Epoch: 0, batch: 3551\n",
      "loss None\n",
      "batch time cost: 5.242888927459717\n",
      "Epoch: 0, batch: 3552\n",
      "loss None\n",
      "batch time cost: 5.31978178024292\n",
      "Epoch: 0, batch: 3553\n",
      "loss None\n",
      "batch time cost: 5.322878837585449\n",
      "Epoch: 0, batch: 3554\n",
      "loss None\n",
      "batch time cost: 5.324145078659058\n",
      "Epoch: 0, batch: 3555\n",
      "loss None\n",
      "batch time cost: 5.277235984802246\n",
      "Epoch: 0, batch: 3556\n",
      "loss None\n",
      "batch time cost: 5.303731918334961\n",
      "Epoch: 0, batch: 3557\n",
      "loss None\n",
      "batch time cost: 5.296441078186035\n",
      "Epoch: 0, batch: 3558\n",
      "loss None\n",
      "batch time cost: 5.57343316078186\n",
      "Epoch: 0, batch: 3559\n",
      "loss None\n",
      "batch time cost: 5.302680015563965\n",
      "Epoch: 0, batch: 3560\n",
      "loss None\n",
      "batch time cost: 5.275983095169067\n",
      "Relu Train Epoch: 0 [227840/318582 (1%)]\tLoss: 0.636360\n",
      "Epoch: 0, batch: 3561\n",
      "loss None\n",
      "batch time cost: 5.248608112335205\n",
      "Epoch: 0, batch: 3562\n",
      "loss None\n",
      "batch time cost: 5.341247081756592\n",
      "Epoch: 0, batch: 3563\n",
      "loss None\n",
      "batch time cost: 5.256184101104736\n",
      "Epoch: 0, batch: 3564\n",
      "loss None\n",
      "batch time cost: 5.281286001205444\n",
      "Epoch: 0, batch: 3565\n",
      "loss None\n",
      "batch time cost: 5.713623762130737\n",
      "Epoch: 0, batch: 3566\n",
      "loss None\n",
      "batch time cost: 5.2527759075164795\n",
      "Epoch: 0, batch: 3567\n",
      "loss None\n",
      "batch time cost: 5.308274030685425\n",
      "Epoch: 0, batch: 3568\n",
      "loss None\n",
      "batch time cost: 5.259241104125977\n",
      "Epoch: 0, batch: 3569\n",
      "loss None\n",
      "batch time cost: 5.222844123840332\n",
      "Epoch: 0, batch: 3570\n",
      "loss None\n",
      "batch time cost: 5.227351665496826\n",
      "Relu Train Epoch: 0 [228480/318582 (1%)]\tLoss: 0.852320\n",
      "Epoch: 0, batch: 3571\n",
      "loss None\n",
      "batch time cost: 5.2555530071258545\n",
      "Epoch: 0, batch: 3572\n",
      "loss None\n",
      "batch time cost: 5.551631212234497\n",
      "Epoch: 0, batch: 3573\n",
      "loss None\n",
      "batch time cost: 5.224273204803467\n",
      "Epoch: 0, batch: 3574\n",
      "loss None\n",
      "batch time cost: 5.278532981872559\n",
      "Epoch: 0, batch: 3575\n",
      "loss None\n",
      "batch time cost: 5.328688144683838\n",
      "Epoch: 0, batch: 3576\n",
      "loss None\n",
      "batch time cost: 5.356007099151611\n",
      "Epoch: 0, batch: 3577\n",
      "loss None\n",
      "batch time cost: 5.280223846435547\n",
      "Epoch: 0, batch: 3578\n",
      "loss None\n",
      "batch time cost: 5.295289754867554\n",
      "Epoch: 0, batch: 3579\n",
      "loss None\n",
      "batch time cost: 5.597224950790405\n",
      "Epoch: 0, batch: 3580\n",
      "loss None\n",
      "batch time cost: 5.341079950332642\n",
      "Relu Train Epoch: 0 [229120/318582 (1%)]\tLoss: 0.724524\n",
      "Epoch: 0, batch: 3581\n",
      "loss None\n",
      "batch time cost: 5.300373077392578\n",
      "Epoch: 0, batch: 3582\n",
      "loss None\n",
      "batch time cost: 5.270290851593018\n",
      "Epoch: 0, batch: 3583\n",
      "loss None\n",
      "batch time cost: 5.276679039001465\n",
      "Epoch: 0, batch: 3584\n",
      "loss None\n",
      "batch time cost: 5.244147062301636\n",
      "Epoch: 0, batch: 3585\n",
      "loss None\n",
      "batch time cost: 5.307944059371948\n",
      "Epoch: 0, batch: 3586\n",
      "loss None\n",
      "batch time cost: 5.631798028945923\n",
      "Epoch: 0, batch: 3587\n",
      "loss None\n",
      "batch time cost: 5.303719997406006\n",
      "Epoch: 0, batch: 3588\n",
      "loss None\n",
      "batch time cost: 5.336329936981201\n",
      "Epoch: 0, batch: 3589\n",
      "loss None\n",
      "batch time cost: 5.2840659618377686\n",
      "Epoch: 0, batch: 3590\n",
      "loss None\n",
      "batch time cost: 5.2310850620269775\n",
      "Relu Train Epoch: 0 [229760/318582 (1%)]\tLoss: 0.850067\n",
      "Epoch: 0, batch: 3591\n",
      "loss None\n",
      "batch time cost: 5.285988807678223\n",
      "Epoch: 0, batch: 3592\n",
      "loss None\n",
      "batch time cost: 5.235996246337891\n",
      "Epoch: 0, batch: 3593\n",
      "loss None\n",
      "batch time cost: 5.265012979507446\n",
      "Epoch: 0, batch: 3594\n",
      "loss None\n",
      "batch time cost: 5.588497877120972\n",
      "Epoch: 0, batch: 3595\n",
      "loss None\n",
      "batch time cost: 5.331374883651733\n",
      "Epoch: 0, batch: 3596\n",
      "loss None\n",
      "batch time cost: 5.320085048675537\n",
      "Epoch: 0, batch: 3597\n",
      "loss None\n",
      "batch time cost: 5.265965938568115\n",
      "Epoch: 0, batch: 3598\n",
      "loss None\n",
      "batch time cost: 5.282076835632324\n",
      "Epoch: 0, batch: 3599\n",
      "loss None\n",
      "batch time cost: 5.333456754684448\n",
      "Epoch: 0, batch: 3600\n",
      "loss None\n",
      "batch time cost: 5.285442113876343\n",
      "Relu Train Epoch: 0 [230400/318582 (1%)]\tLoss: 0.617395\n",
      "Epoch: 0, batch: 3601\n",
      "loss None\n",
      "batch time cost: 5.600841999053955\n",
      "Epoch: 0, batch: 3602\n",
      "loss None\n",
      "batch time cost: 5.260835886001587\n",
      "Epoch: 0, batch: 3603\n",
      "loss None\n",
      "batch time cost: 5.302367210388184\n",
      "Epoch: 0, batch: 3604\n",
      "loss None\n",
      "batch time cost: 5.260730266571045\n",
      "Epoch: 0, batch: 3605\n",
      "loss None\n",
      "batch time cost: 5.265538930892944\n",
      "Epoch: 0, batch: 3606\n",
      "loss None\n",
      "batch time cost: 5.286741018295288\n",
      "Epoch: 0, batch: 3607\n",
      "loss None\n",
      "batch time cost: 5.334038972854614\n",
      "Epoch: 0, batch: 3608\n",
      "loss None\n",
      "batch time cost: 5.553431987762451\n",
      "Epoch: 0, batch: 3609\n",
      "loss None\n",
      "batch time cost: 5.215571880340576\n",
      "Epoch: 0, batch: 3610\n",
      "loss None\n",
      "batch time cost: 5.322428941726685\n",
      "Relu Train Epoch: 0 [231040/318582 (1%)]\tLoss: 0.895083\n",
      "Epoch: 0, batch: 3611\n",
      "loss None\n",
      "batch time cost: 5.2720067501068115\n",
      "Epoch: 0, batch: 3612\n",
      "loss None\n",
      "batch time cost: 5.282740831375122\n",
      "Epoch: 0, batch: 3613\n",
      "loss None\n",
      "batch time cost: 5.208070755004883\n",
      "Epoch: 0, batch: 3614\n",
      "loss None\n",
      "batch time cost: 5.289552688598633\n",
      "Epoch: 0, batch: 3615\n",
      "loss None\n",
      "batch time cost: 5.601582288742065\n",
      "Epoch: 0, batch: 3616\n",
      "loss None\n",
      "batch time cost: 5.2908501625061035\n",
      "Epoch: 0, batch: 3617\n",
      "loss None\n",
      "batch time cost: 5.215698003768921\n",
      "Epoch: 0, batch: 3618\n",
      "loss None\n",
      "batch time cost: 5.281936168670654\n",
      "Epoch: 0, batch: 3619\n",
      "loss None\n",
      "batch time cost: 5.280949115753174\n",
      "Epoch: 0, batch: 3620\n",
      "loss None\n",
      "batch time cost: 5.2990710735321045\n",
      "Relu Train Epoch: 0 [231680/318582 (1%)]\tLoss: 1.021808\n",
      "Epoch: 0, batch: 3621\n",
      "loss None\n",
      "batch time cost: 5.347229957580566\n",
      "Epoch: 0, batch: 3622\n",
      "loss None\n",
      "batch time cost: 5.2760748863220215\n",
      "Epoch: 0, batch: 3623\n",
      "loss None\n",
      "batch time cost: 5.576306104660034\n",
      "Epoch: 0, batch: 3624\n",
      "loss None\n",
      "batch time cost: 5.361199855804443\n",
      "Epoch: 0, batch: 3625\n",
      "loss None\n",
      "batch time cost: 5.333200693130493\n",
      "Epoch: 0, batch: 3626\n",
      "loss None\n",
      "batch time cost: 5.319091796875\n",
      "Epoch: 0, batch: 3627\n",
      "loss None\n",
      "batch time cost: 5.249418020248413\n",
      "Epoch: 0, batch: 3628\n",
      "loss None\n",
      "batch time cost: 5.257897853851318\n",
      "Epoch: 0, batch: 3629\n",
      "loss None\n",
      "batch time cost: 5.266472101211548\n",
      "Epoch: 0, batch: 3630\n",
      "loss None\n",
      "batch time cost: 5.644384145736694\n",
      "Relu Train Epoch: 0 [232320/318582 (1%)]\tLoss: 0.610552\n",
      "Epoch: 0, batch: 3631\n",
      "loss None\n",
      "batch time cost: 5.2733941078186035\n",
      "Epoch: 0, batch: 3632\n",
      "loss None\n",
      "batch time cost: 5.2687156200408936\n",
      "Epoch: 0, batch: 3633\n",
      "loss None\n",
      "batch time cost: 5.254274129867554\n",
      "Epoch: 0, batch: 3634\n",
      "loss None\n",
      "batch time cost: 5.2749550342559814\n",
      "Epoch: 0, batch: 3635\n",
      "loss None\n",
      "batch time cost: 5.2393059730529785\n",
      "Epoch: 0, batch: 3636\n",
      "loss None\n",
      "batch time cost: 7.4273059368133545\n",
      "Epoch: 0, batch: 3637\n",
      "loss None\n",
      "batch time cost: 7.756550073623657\n",
      "Epoch: 0, batch: 3638\n",
      "loss None\n",
      "batch time cost: 6.010839939117432\n",
      "Epoch: 0, batch: 3639\n",
      "loss None\n",
      "batch time cost: 5.343324899673462\n",
      "Epoch: 0, batch: 3640\n",
      "loss None\n",
      "batch time cost: 5.289515018463135\n",
      "Relu Train Epoch: 0 [232960/318582 (1%)]\tLoss: 0.828993\n",
      "Epoch: 0, batch: 3641\n",
      "loss None\n",
      "batch time cost: 5.257842302322388\n",
      "Epoch: 0, batch: 3642\n",
      "loss None\n",
      "batch time cost: 5.252522945404053\n",
      "Epoch: 0, batch: 3643\n",
      "loss None\n",
      "batch time cost: 5.338604927062988\n",
      "Epoch: 0, batch: 3644\n",
      "loss None\n",
      "batch time cost: 5.700574159622192\n",
      "Epoch: 0, batch: 3645\n",
      "loss None\n",
      "batch time cost: 5.288455009460449\n",
      "Epoch: 0, batch: 3646\n",
      "loss None\n",
      "batch time cost: 5.267579078674316\n",
      "Epoch: 0, batch: 3647\n",
      "loss None\n",
      "batch time cost: 5.315812826156616\n",
      "Epoch: 0, batch: 3648\n",
      "loss None\n",
      "batch time cost: 5.3154308795928955\n",
      "Epoch: 0, batch: 3649\n",
      "loss None\n",
      "batch time cost: 5.227427959442139\n",
      "Epoch: 0, batch: 3650\n",
      "loss None\n",
      "batch time cost: 5.270312786102295\n",
      "Relu Train Epoch: 0 [233600/318582 (1%)]\tLoss: 0.824026\n",
      "Epoch: 0, batch: 3651\n",
      "loss None\n",
      "batch time cost: 5.580517768859863\n",
      "Epoch: 0, batch: 3652\n",
      "loss None\n",
      "batch time cost: 5.262999057769775\n",
      "Epoch: 0, batch: 3653\n",
      "loss None\n",
      "batch time cost: 5.339787721633911\n",
      "Epoch: 0, batch: 3654\n",
      "loss None\n",
      "batch time cost: 5.458296775817871\n",
      "Epoch: 0, batch: 3655\n",
      "loss None\n",
      "batch time cost: 5.364622116088867\n",
      "Epoch: 0, batch: 3656\n",
      "loss None\n",
      "batch time cost: 5.287898778915405\n",
      "Epoch: 0, batch: 3657\n",
      "loss None\n",
      "batch time cost: 5.309289932250977\n",
      "Epoch: 0, batch: 3658\n",
      "loss None\n",
      "batch time cost: 5.31926703453064\n",
      "Epoch: 0, batch: 3659\n",
      "loss None\n",
      "batch time cost: 5.585540056228638\n",
      "Epoch: 0, batch: 3660\n",
      "loss None\n",
      "batch time cost: 5.259089946746826\n",
      "Relu Train Epoch: 0 [234240/318582 (1%)]\tLoss: 0.753139\n",
      "Epoch: 0, batch: 3661\n",
      "loss None\n",
      "batch time cost: 5.2660839557647705\n",
      "Epoch: 0, batch: 3662\n",
      "loss None\n",
      "batch time cost: 5.311547756195068\n",
      "Epoch: 0, batch: 3663\n",
      "loss None\n",
      "batch time cost: 5.21301794052124\n",
      "Epoch: 0, batch: 3664\n",
      "loss None\n",
      "batch time cost: 5.280609130859375\n",
      "Epoch: 0, batch: 3665\n",
      "loss None\n",
      "batch time cost: 5.322536945343018\n",
      "Epoch: 0, batch: 3666\n",
      "loss None\n",
      "batch time cost: 5.6217522621154785\n",
      "Epoch: 0, batch: 3667\n",
      "loss None\n",
      "batch time cost: 5.2520668506622314\n",
      "Epoch: 0, batch: 3668\n",
      "loss None\n",
      "batch time cost: 5.315131902694702\n",
      "Epoch: 0, batch: 3669\n",
      "loss None\n",
      "batch time cost: 5.3048200607299805\n",
      "Epoch: 0, batch: 3670\n",
      "loss None\n",
      "batch time cost: 5.259320974349976\n",
      "Relu Train Epoch: 0 [234880/318582 (1%)]\tLoss: 0.736819\n",
      "Epoch: 0, batch: 3671\n",
      "loss None\n",
      "batch time cost: 5.242331027984619\n",
      "Epoch: 0, batch: 3672\n",
      "loss None\n",
      "batch time cost: 5.277963876724243\n",
      "Epoch: 0, batch: 3673\n",
      "loss None\n",
      "batch time cost: 5.5823071002960205\n",
      "Epoch: 0, batch: 3674\n",
      "loss None\n",
      "batch time cost: 5.280416965484619\n",
      "Epoch: 0, batch: 3675\n",
      "loss None\n",
      "batch time cost: 5.244079828262329\n",
      "Epoch: 0, batch: 3676\n",
      "loss None\n",
      "batch time cost: 5.266403675079346\n",
      "Epoch: 0, batch: 3677\n",
      "loss None\n",
      "batch time cost: 5.256865978240967\n",
      "Epoch: 0, batch: 3678\n",
      "loss None\n",
      "batch time cost: 5.300644159317017\n",
      "Epoch: 0, batch: 3679\n",
      "loss None\n",
      "batch time cost: 5.270742654800415\n",
      "Epoch: 0, batch: 3680\n",
      "loss None\n",
      "batch time cost: 5.556607007980347\n",
      "Relu Train Epoch: 0 [235520/318582 (1%)]\tLoss: 0.850175\n",
      "Epoch: 0, batch: 3681\n",
      "loss None\n",
      "batch time cost: 5.255536079406738\n",
      "Epoch: 0, batch: 3682\n",
      "loss None\n",
      "batch time cost: 5.281766891479492\n",
      "Epoch: 0, batch: 3683\n",
      "loss None\n",
      "batch time cost: 5.311221122741699\n",
      "Epoch: 0, batch: 3684\n",
      "loss None\n",
      "batch time cost: 5.302798748016357\n",
      "Epoch: 0, batch: 3685\n",
      "loss None\n",
      "batch time cost: 5.3237786293029785\n",
      "Epoch: 0, batch: 3686\n",
      "loss None\n",
      "batch time cost: 5.297195911407471\n",
      "Epoch: 0, batch: 3687\n",
      "loss None\n",
      "batch time cost: 5.258217096328735\n",
      "Epoch: 0, batch: 3688\n",
      "loss None\n",
      "batch time cost: 5.927867889404297\n",
      "Epoch: 0, batch: 3689\n",
      "loss None\n",
      "batch time cost: 5.557323217391968\n",
      "Epoch: 0, batch: 3690\n",
      "loss None\n",
      "batch time cost: 5.300835132598877\n",
      "Relu Train Epoch: 0 [236160/318582 (1%)]\tLoss: 0.637242\n",
      "Epoch: 0, batch: 3691\n",
      "loss None\n",
      "batch time cost: 5.306181907653809\n",
      "Epoch: 0, batch: 3692\n",
      "loss None\n",
      "batch time cost: 5.279147624969482\n",
      "Epoch: 0, batch: 3693\n",
      "loss None\n",
      "batch time cost: 5.26815390586853\n",
      "Epoch: 0, batch: 3694\n",
      "loss None\n",
      "batch time cost: 5.23527717590332\n",
      "Epoch: 0, batch: 3695\n",
      "loss None\n",
      "batch time cost: 5.665719032287598\n",
      "Epoch: 0, batch: 3696\n",
      "loss None\n",
      "batch time cost: 5.354642152786255\n",
      "Epoch: 0, batch: 3697\n",
      "loss None\n",
      "batch time cost: 5.2592692375183105\n",
      "Epoch: 0, batch: 3698\n",
      "loss None\n",
      "batch time cost: 5.31198525428772\n",
      "Epoch: 0, batch: 3699\n",
      "loss None\n",
      "batch time cost: 5.384287118911743\n",
      "Epoch: 0, batch: 3700\n",
      "loss None\n",
      "batch time cost: 5.286531925201416\n",
      "Relu Train Epoch: 0 [236800/318582 (1%)]\tLoss: 0.847381\n",
      "Epoch: 0, batch: 3701\n",
      "loss None\n",
      "batch time cost: 5.2898969650268555\n",
      "Epoch: 0, batch: 3702\n",
      "loss None\n",
      "batch time cost: 5.579698801040649\n",
      "Epoch: 0, batch: 3703\n",
      "loss None\n",
      "batch time cost: 5.253453731536865\n",
      "Epoch: 0, batch: 3704\n",
      "loss None\n",
      "batch time cost: 5.449943780899048\n",
      "Epoch: 0, batch: 3705\n",
      "loss None\n",
      "batch time cost: 5.25557804107666\n",
      "Epoch: 0, batch: 3706\n",
      "loss None\n",
      "batch time cost: 5.261525869369507\n",
      "Epoch: 0, batch: 3707\n",
      "loss None\n",
      "batch time cost: 5.268064022064209\n",
      "Epoch: 0, batch: 3708\n",
      "loss None\n",
      "batch time cost: 5.249476909637451\n",
      "Epoch: 0, batch: 3709\n",
      "loss None\n",
      "batch time cost: 5.669059991836548\n",
      "Epoch: 0, batch: 3710\n",
      "loss None\n",
      "batch time cost: 5.324894905090332\n",
      "Relu Train Epoch: 0 [237440/318582 (1%)]\tLoss: 0.697939\n",
      "Epoch: 0, batch: 3711\n",
      "loss None\n",
      "batch time cost: 5.296573162078857\n",
      "Epoch: 0, batch: 3712\n",
      "loss None\n",
      "batch time cost: 5.25373101234436\n",
      "Epoch: 0, batch: 3713\n",
      "loss None\n",
      "batch time cost: 5.274388074874878\n",
      "Epoch: 0, batch: 3714\n",
      "loss None\n",
      "batch time cost: 5.273112058639526\n",
      "Epoch: 0, batch: 3715\n",
      "loss None\n",
      "batch time cost: 5.290276765823364\n",
      "Epoch: 0, batch: 3716\n",
      "loss None\n",
      "batch time cost: 5.613131046295166\n",
      "Epoch: 0, batch: 3717\n",
      "loss None\n",
      "batch time cost: 5.311295986175537\n",
      "Epoch: 0, batch: 3718\n",
      "loss None\n",
      "batch time cost: 5.288366079330444\n",
      "Epoch: 0, batch: 3719\n",
      "loss None\n",
      "batch time cost: 5.296660900115967\n",
      "Epoch: 0, batch: 3720\n",
      "loss None\n",
      "batch time cost: 5.234298944473267\n",
      "Relu Train Epoch: 0 [238080/318582 (1%)]\tLoss: 0.737753\n",
      "Epoch: 0, batch: 3721\n",
      "loss None\n",
      "batch time cost: 5.233881235122681\n",
      "Epoch: 0, batch: 3722\n",
      "loss None\n",
      "batch time cost: 5.267111301422119\n",
      "Epoch: 0, batch: 3723\n",
      "loss None\n",
      "batch time cost: 5.229218006134033\n",
      "Epoch: 0, batch: 3724\n",
      "loss None\n",
      "batch time cost: 5.563779830932617\n",
      "Epoch: 0, batch: 3725\n",
      "loss None\n",
      "batch time cost: 5.304363965988159\n",
      "Epoch: 0, batch: 3726\n",
      "loss None\n",
      "batch time cost: 5.2722179889678955\n",
      "Epoch: 0, batch: 3727\n",
      "loss None\n",
      "batch time cost: 5.302934885025024\n",
      "Epoch: 0, batch: 3728\n",
      "loss None\n",
      "batch time cost: 5.264233112335205\n",
      "Epoch: 0, batch: 3729\n",
      "loss None\n",
      "batch time cost: 5.303647041320801\n",
      "Epoch: 0, batch: 3730\n",
      "loss None\n",
      "batch time cost: 5.260046005249023\n",
      "Relu Train Epoch: 0 [238720/318582 (1%)]\tLoss: 0.763271\n",
      "Epoch: 0, batch: 3731\n",
      "loss None\n",
      "batch time cost: 5.562685966491699\n",
      "Epoch: 0, batch: 3732\n",
      "loss None\n",
      "batch time cost: 5.228193044662476\n",
      "Epoch: 0, batch: 3733\n",
      "loss None\n",
      "batch time cost: 5.480234861373901\n",
      "Epoch: 0, batch: 3734\n",
      "loss None\n",
      "batch time cost: 5.306095123291016\n",
      "Epoch: 0, batch: 3735\n",
      "loss None\n",
      "batch time cost: 5.296886682510376\n",
      "Epoch: 0, batch: 3736\n",
      "loss None\n",
      "batch time cost: 5.29496693611145\n",
      "Epoch: 0, batch: 3737\n",
      "loss None\n",
      "batch time cost: 5.291656017303467\n",
      "Epoch: 0, batch: 3738\n",
      "loss None\n",
      "batch time cost: 5.559010028839111\n",
      "Epoch: 0, batch: 3739\n",
      "loss None\n",
      "batch time cost: 5.32043194770813\n",
      "Epoch: 0, batch: 3740\n",
      "loss None\n",
      "batch time cost: 5.241034030914307\n",
      "Relu Train Epoch: 0 [239360/318582 (1%)]\tLoss: 0.797562\n",
      "Epoch: 0, batch: 3741\n",
      "loss None\n",
      "batch time cost: 5.263553857803345\n",
      "Epoch: 0, batch: 3742\n",
      "loss None\n",
      "batch time cost: 5.247804164886475\n",
      "Epoch: 0, batch: 3743\n",
      "loss None\n",
      "batch time cost: 5.27356481552124\n",
      "Epoch: 0, batch: 3744\n",
      "loss None\n",
      "batch time cost: 5.564562082290649\n",
      "Epoch: 0, batch: 3745\n",
      "loss None\n",
      "batch time cost: 5.59190034866333\n",
      "Epoch: 0, batch: 3746\n",
      "loss None\n",
      "batch time cost: 5.347052097320557\n",
      "Epoch: 0, batch: 3747\n",
      "loss None\n",
      "batch time cost: 5.257993936538696\n",
      "Epoch: 0, batch: 3748\n",
      "loss None\n",
      "batch time cost: 5.291916131973267\n",
      "Epoch: 0, batch: 3749\n",
      "loss None\n",
      "batch time cost: 5.242221832275391\n",
      "Epoch: 0, batch: 3750\n",
      "loss None\n",
      "batch time cost: 5.244055986404419\n",
      "Relu Train Epoch: 0 [240000/318582 (1%)]\tLoss: 0.645628\n",
      "Epoch: 0, batch: 3751\n",
      "loss None\n",
      "batch time cost: 5.27688193321228\n",
      "Epoch: 0, batch: 3752\n",
      "loss None\n",
      "batch time cost: 5.252664089202881\n",
      "Epoch: 0, batch: 3753\n",
      "loss None\n",
      "batch time cost: 5.575230121612549\n",
      "Epoch: 0, batch: 3754\n",
      "loss None\n",
      "batch time cost: 5.277108430862427\n",
      "Epoch: 0, batch: 3755\n",
      "loss None\n",
      "batch time cost: 5.398485898971558\n",
      "Epoch: 0, batch: 3756\n",
      "loss None\n",
      "batch time cost: 5.273308038711548\n",
      "Epoch: 0, batch: 3757\n",
      "loss None\n",
      "batch time cost: 5.283697128295898\n",
      "Epoch: 0, batch: 3758\n",
      "loss None\n",
      "batch time cost: 5.244237899780273\n",
      "Epoch: 0, batch: 3759\n",
      "loss None\n",
      "batch time cost: 5.324682712554932\n",
      "Epoch: 0, batch: 3760\n",
      "loss None\n",
      "batch time cost: 5.627732992172241\n",
      "Relu Train Epoch: 0 [240640/318582 (1%)]\tLoss: 0.929445\n",
      "Epoch: 0, batch: 3761\n",
      "loss None\n",
      "batch time cost: 5.364515781402588\n",
      "Epoch: 0, batch: 3762\n",
      "loss None\n",
      "batch time cost: 5.300122022628784\n",
      "Epoch: 0, batch: 3763\n",
      "loss None\n",
      "batch time cost: 5.257251024246216\n",
      "Epoch: 0, batch: 3764\n",
      "loss None\n",
      "batch time cost: 5.189917087554932\n",
      "Epoch: 0, batch: 3765\n",
      "loss None\n",
      "batch time cost: 5.306782245635986\n",
      "Epoch: 0, batch: 3766\n",
      "loss None\n",
      "batch time cost: 5.310567855834961\n",
      "Epoch: 0, batch: 3767\n",
      "loss None\n",
      "batch time cost: 5.604799032211304\n",
      "Epoch: 0, batch: 3768\n",
      "loss None\n",
      "batch time cost: 5.243981122970581\n",
      "Epoch: 0, batch: 3769\n",
      "loss None\n",
      "batch time cost: 5.296960115432739\n",
      "Epoch: 0, batch: 3770\n",
      "loss None\n",
      "batch time cost: 5.246896028518677\n",
      "Relu Train Epoch: 0 [241280/318582 (1%)]\tLoss: 0.968031\n",
      "Epoch: 0, batch: 3771\n",
      "loss None\n",
      "batch time cost: 5.274464130401611\n",
      "Epoch: 0, batch: 3772\n",
      "loss None\n",
      "batch time cost: 5.307005882263184\n",
      "Epoch: 0, batch: 3773\n",
      "loss None\n",
      "batch time cost: 5.306135892868042\n",
      "Epoch: 0, batch: 3774\n",
      "loss None\n",
      "batch time cost: 5.605382919311523\n",
      "Epoch: 0, batch: 3775\n",
      "loss None\n",
      "batch time cost: 5.298184156417847\n",
      "Epoch: 0, batch: 3776\n",
      "loss None\n",
      "batch time cost: 5.297948837280273\n",
      "Epoch: 0, batch: 3777\n",
      "loss None\n",
      "batch time cost: 5.22918701171875\n",
      "Epoch: 0, batch: 3778\n",
      "loss None\n",
      "batch time cost: 5.319076776504517\n",
      "Epoch: 0, batch: 3779\n",
      "loss None\n",
      "batch time cost: 5.2589709758758545\n",
      "Epoch: 0, batch: 3780\n",
      "loss None\n",
      "batch time cost: 5.285818815231323\n",
      "Relu Train Epoch: 0 [241920/318582 (1%)]\tLoss: 0.751367\n",
      "Epoch: 0, batch: 3781\n",
      "loss None\n",
      "batch time cost: 5.576966762542725\n",
      "Epoch: 0, batch: 3782\n",
      "loss None\n",
      "batch time cost: 5.257617950439453\n",
      "Epoch: 0, batch: 3783\n",
      "loss None\n",
      "batch time cost: 5.251346111297607\n",
      "Epoch: 0, batch: 3784\n",
      "loss None\n",
      "batch time cost: 5.263084888458252\n",
      "Epoch: 0, batch: 3785\n",
      "loss None\n",
      "batch time cost: 5.265177011489868\n",
      "Epoch: 0, batch: 3786\n",
      "loss None\n",
      "batch time cost: 5.237145662307739\n",
      "Epoch: 0, batch: 3787\n",
      "loss None\n",
      "batch time cost: 5.229783058166504\n",
      "Epoch: 0, batch: 3788\n",
      "loss None\n",
      "batch time cost: 5.333112001419067\n",
      "Epoch: 0, batch: 3789\n",
      "loss None\n",
      "batch time cost: 5.693459987640381\n",
      "Epoch: 0, batch: 3790\n",
      "loss None\n",
      "batch time cost: 5.294788122177124\n",
      "Relu Train Epoch: 0 [242560/318582 (1%)]\tLoss: 0.753097\n",
      "Epoch: 0, batch: 3791\n",
      "loss None\n",
      "batch time cost: 5.26143217086792\n",
      "Epoch: 0, batch: 3792\n",
      "loss None\n",
      "batch time cost: 5.282715082168579\n",
      "Epoch: 0, batch: 3793\n",
      "loss None\n",
      "batch time cost: 5.280034065246582\n",
      "Epoch: 0, batch: 3794\n",
      "loss None\n",
      "batch time cost: 5.2654876708984375\n",
      "Epoch: 0, batch: 3795\n",
      "loss None\n",
      "batch time cost: 5.3157219886779785\n",
      "Epoch: 0, batch: 3796\n",
      "loss None\n",
      "batch time cost: 5.581171989440918\n",
      "Epoch: 0, batch: 3797\n",
      "loss None\n",
      "batch time cost: 5.300238132476807\n",
      "Epoch: 0, batch: 3798\n",
      "loss None\n",
      "batch time cost: 5.272407054901123\n",
      "Epoch: 0, batch: 3799\n",
      "loss None\n",
      "batch time cost: 5.25452995300293\n",
      "Epoch: 0, batch: 3800\n",
      "loss None\n",
      "batch time cost: 5.391860008239746\n",
      "Relu Train Epoch: 0 [243200/318582 (1%)]\tLoss: 0.796411\n",
      "Epoch: 0, batch: 3801\n",
      "loss None\n",
      "batch time cost: 5.270075082778931\n",
      "Epoch: 0, batch: 3802\n",
      "loss None\n",
      "batch time cost: 5.2974090576171875\n",
      "Epoch: 0, batch: 3803\n",
      "loss None\n",
      "batch time cost: 5.662633180618286\n",
      "Epoch: 0, batch: 3804\n",
      "loss None\n",
      "batch time cost: 5.283322095870972\n",
      "Epoch: 0, batch: 3805\n",
      "loss None\n",
      "batch time cost: 5.312869071960449\n",
      "Epoch: 0, batch: 3806\n",
      "loss None\n",
      "batch time cost: 5.281656980514526\n",
      "Epoch: 0, batch: 3807\n",
      "loss None\n",
      "batch time cost: 5.267221927642822\n",
      "Epoch: 0, batch: 3808\n",
      "loss None\n",
      "batch time cost: 5.292388916015625\n",
      "Epoch: 0, batch: 3809\n",
      "loss None\n",
      "batch time cost: 5.2736499309539795\n",
      "Epoch: 0, batch: 3810\n",
      "loss None\n",
      "batch time cost: 5.625403881072998\n",
      "Relu Train Epoch: 0 [243840/318582 (1%)]\tLoss: 0.745741\n",
      "Epoch: 0, batch: 3811\n",
      "loss None\n",
      "batch time cost: 5.348888158798218\n",
      "Epoch: 0, batch: 3812\n",
      "loss None\n",
      "batch time cost: 5.281299829483032\n",
      "Epoch: 0, batch: 3813\n",
      "loss None\n",
      "batch time cost: 5.289838075637817\n",
      "Epoch: 0, batch: 3814\n",
      "loss None\n",
      "batch time cost: 5.309525966644287\n",
      "Epoch: 0, batch: 3815\n",
      "loss None\n",
      "batch time cost: 5.249173879623413\n",
      "Epoch: 0, batch: 3816\n",
      "loss None\n",
      "batch time cost: 5.240756034851074\n",
      "Epoch: 0, batch: 3817\n",
      "loss None\n",
      "batch time cost: 5.263020038604736\n",
      "Epoch: 0, batch: 3818\n",
      "loss None\n",
      "batch time cost: 5.63030481338501\n",
      "Epoch: 0, batch: 3819\n",
      "loss None\n",
      "batch time cost: 5.257014989852905\n",
      "Epoch: 0, batch: 3820\n",
      "loss None\n",
      "batch time cost: 5.288799047470093\n",
      "Relu Train Epoch: 0 [244480/318582 (1%)]\tLoss: 0.856664\n",
      "Epoch: 0, batch: 3821\n",
      "loss None\n",
      "batch time cost: 5.276587009429932\n",
      "Epoch: 0, batch: 3822\n",
      "loss None\n",
      "batch time cost: 5.2931599617004395\n",
      "Epoch: 0, batch: 3823\n",
      "loss None\n",
      "batch time cost: 5.36635684967041\n",
      "Epoch: 0, batch: 3824\n",
      "loss None\n",
      "batch time cost: 5.254627227783203\n",
      "Epoch: 0, batch: 3825\n",
      "loss None\n",
      "batch time cost: 5.510643005371094\n",
      "Epoch: 0, batch: 3826\n",
      "loss None\n",
      "batch time cost: 5.226855993270874\n",
      "Epoch: 0, batch: 3827\n",
      "loss None\n",
      "batch time cost: 5.28324294090271\n",
      "Epoch: 0, batch: 3828\n",
      "loss None\n",
      "batch time cost: 5.275457143783569\n",
      "Epoch: 0, batch: 3829\n",
      "loss None\n",
      "batch time cost: 5.24197793006897\n",
      "Epoch: 0, batch: 3830\n",
      "loss None\n",
      "batch time cost: 5.2806220054626465\n",
      "Relu Train Epoch: 0 [245120/318582 (1%)]\tLoss: 0.804515\n",
      "Epoch: 0, batch: 3831\n",
      "loss None\n",
      "batch time cost: 5.2455408573150635\n",
      "Epoch: 0, batch: 3832\n",
      "loss None\n",
      "batch time cost: 5.623572111129761\n",
      "Epoch: 0, batch: 3833\n",
      "loss None\n",
      "batch time cost: 5.2669501304626465\n",
      "Epoch: 0, batch: 3834\n",
      "loss None\n",
      "batch time cost: 5.46409797668457\n",
      "Epoch: 0, batch: 3835\n",
      "loss None\n",
      "batch time cost: 5.293949842453003\n",
      "Epoch: 0, batch: 3836\n",
      "loss None\n",
      "batch time cost: 5.261453866958618\n",
      "Epoch: 0, batch: 3837\n",
      "loss None\n",
      "batch time cost: 5.283381938934326\n",
      "Epoch: 0, batch: 3838\n",
      "loss None\n",
      "batch time cost: 5.366116046905518\n",
      "Epoch: 0, batch: 3839\n",
      "loss None\n",
      "batch time cost: 5.634428977966309\n",
      "Epoch: 0, batch: 3840\n",
      "loss None\n",
      "batch time cost: 5.286662817001343\n",
      "Relu Train Epoch: 0 [245760/318582 (1%)]\tLoss: 0.769375\n",
      "Epoch: 0, batch: 3841\n",
      "loss None\n",
      "batch time cost: 5.234531879425049\n",
      "Epoch: 0, batch: 3842\n",
      "loss None\n",
      "batch time cost: 5.256531000137329\n",
      "Epoch: 0, batch: 3843\n",
      "loss None\n",
      "batch time cost: 5.248603820800781\n",
      "Epoch: 0, batch: 3844\n",
      "loss None\n",
      "batch time cost: 5.299066066741943\n",
      "Epoch: 0, batch: 3845\n",
      "loss None\n",
      "batch time cost: 5.309506893157959\n",
      "Epoch: 0, batch: 3846\n",
      "loss None\n",
      "batch time cost: 5.619251012802124\n",
      "Epoch: 0, batch: 3847\n",
      "loss None\n",
      "batch time cost: 5.30102801322937\n",
      "Epoch: 0, batch: 3848\n",
      "loss None\n",
      "batch time cost: 5.266669988632202\n",
      "Epoch: 0, batch: 3849\n",
      "loss None\n",
      "batch time cost: 5.308667182922363\n",
      "Epoch: 0, batch: 3850\n",
      "loss None\n",
      "batch time cost: 5.26708197593689\n",
      "Relu Train Epoch: 0 [246400/318582 (1%)]\tLoss: 0.771467\n",
      "Epoch: 0, batch: 3851\n",
      "loss None\n",
      "batch time cost: 5.252448081970215\n",
      "Epoch: 0, batch: 3852\n",
      "loss None\n",
      "batch time cost: 5.264013051986694\n",
      "Epoch: 0, batch: 3853\n",
      "loss None\n",
      "batch time cost: 5.303956985473633\n",
      "Epoch: 0, batch: 3854\n",
      "loss None\n",
      "batch time cost: 5.5733091831207275\n",
      "Epoch: 0, batch: 3855\n",
      "loss None\n",
      "batch time cost: 5.324833869934082\n",
      "Epoch: 0, batch: 3856\n",
      "loss None\n",
      "batch time cost: 5.275870084762573\n",
      "Epoch: 0, batch: 3857\n",
      "loss None\n",
      "batch time cost: 5.364160060882568\n",
      "Epoch: 0, batch: 3858\n",
      "loss None\n",
      "batch time cost: 5.3014020919799805\n",
      "Epoch: 0, batch: 3859\n",
      "loss None\n",
      "batch time cost: 5.3806538581848145\n",
      "Epoch: 0, batch: 3860\n",
      "loss None\n",
      "batch time cost: 5.283178091049194\n",
      "Relu Train Epoch: 0 [247040/318582 (1%)]\tLoss: 0.783351\n",
      "Epoch: 0, batch: 3861\n",
      "loss None\n",
      "batch time cost: 5.649313926696777\n",
      "Epoch: 0, batch: 3862\n",
      "loss None\n",
      "batch time cost: 5.279020071029663\n",
      "Epoch: 0, batch: 3863\n",
      "loss None\n",
      "batch time cost: 5.298971176147461\n",
      "Epoch: 0, batch: 3864\n",
      "loss None\n",
      "batch time cost: 5.31687593460083\n",
      "Epoch: 0, batch: 3865\n",
      "loss None\n",
      "batch time cost: 5.281239032745361\n",
      "Epoch: 0, batch: 3866\n",
      "loss None\n",
      "batch time cost: 5.250729322433472\n",
      "Epoch: 0, batch: 3867\n",
      "loss None\n",
      "batch time cost: 5.24004602432251\n",
      "Epoch: 0, batch: 3868\n",
      "loss None\n",
      "batch time cost: 5.685271978378296\n",
      "Epoch: 0, batch: 3869\n",
      "loss None\n",
      "batch time cost: 5.259803056716919\n",
      "Epoch: 0, batch: 3870\n",
      "loss None\n",
      "batch time cost: 5.261487245559692\n",
      "Relu Train Epoch: 0 [247680/318582 (1%)]\tLoss: 0.652155\n",
      "Epoch: 0, batch: 3871\n",
      "loss None\n",
      "batch time cost: 5.261651992797852\n",
      "Epoch: 0, batch: 3872\n",
      "loss None\n",
      "batch time cost: 5.244352102279663\n",
      "Epoch: 0, batch: 3873\n",
      "loss None\n",
      "batch time cost: 5.2124762535095215\n",
      "Epoch: 0, batch: 3874\n",
      "loss None\n",
      "batch time cost: 5.2519261837005615\n",
      "Epoch: 0, batch: 3875\n",
      "loss None\n",
      "batch time cost: 5.562246799468994\n",
      "Epoch: 0, batch: 3876\n",
      "loss None\n",
      "batch time cost: 5.235481023788452\n",
      "Epoch: 0, batch: 3877\n",
      "loss None\n",
      "batch time cost: 5.321218013763428\n",
      "Epoch: 0, batch: 3878\n",
      "loss None\n",
      "batch time cost: 5.29203200340271\n",
      "Epoch: 0, batch: 3879\n",
      "loss None\n",
      "batch time cost: 5.4562389850616455\n",
      "Epoch: 0, batch: 3880\n",
      "loss None\n",
      "batch time cost: 5.283628940582275\n",
      "Relu Train Epoch: 0 [248320/318582 (1%)]\tLoss: 0.584086\n",
      "Epoch: 0, batch: 3881\n",
      "loss None\n",
      "batch time cost: 5.281175851821899\n",
      "Epoch: 0, batch: 3882\n",
      "loss None\n",
      "batch time cost: 5.276367902755737\n",
      "Epoch: 0, batch: 3883\n",
      "loss None\n",
      "batch time cost: 5.57462215423584\n",
      "Epoch: 0, batch: 3884\n",
      "loss None\n",
      "batch time cost: 5.265192031860352\n",
      "Epoch: 0, batch: 3885\n",
      "loss None\n",
      "batch time cost: 5.258945941925049\n",
      "Epoch: 0, batch: 3886\n",
      "loss None\n",
      "batch time cost: 5.262736082077026\n",
      "Epoch: 0, batch: 3887\n",
      "loss None\n",
      "batch time cost: 5.275456190109253\n",
      "Epoch: 0, batch: 3888\n",
      "loss None\n",
      "batch time cost: 5.249319791793823\n",
      "Epoch: 0, batch: 3889\n",
      "loss None\n",
      "batch time cost: 5.2826759815216064\n",
      "Epoch: 0, batch: 3890\n",
      "loss None\n",
      "batch time cost: 5.650882005691528\n",
      "Relu Train Epoch: 0 [248960/318582 (1%)]\tLoss: 0.851280\n",
      "Epoch: 0, batch: 3891\n",
      "loss None\n",
      "batch time cost: 5.334938049316406\n",
      "Epoch: 0, batch: 3892\n",
      "loss None\n",
      "batch time cost: 5.255271911621094\n",
      "Epoch: 0, batch: 3893\n",
      "loss None\n",
      "batch time cost: 5.275874137878418\n",
      "Epoch: 0, batch: 3894\n",
      "loss None\n",
      "batch time cost: 5.309067010879517\n",
      "Epoch: 0, batch: 3895\n",
      "loss None\n",
      "batch time cost: 5.288772821426392\n",
      "Epoch: 0, batch: 3896\n",
      "loss None\n",
      "batch time cost: 5.29423189163208\n",
      "Epoch: 0, batch: 3897\n",
      "loss None\n",
      "batch time cost: 5.579517841339111\n",
      "Epoch: 0, batch: 3898\n",
      "loss None\n",
      "batch time cost: 5.281042814254761\n",
      "Epoch: 0, batch: 3899\n",
      "loss None\n",
      "batch time cost: 5.240677118301392\n",
      "Epoch: 0, batch: 3900\n",
      "loss None\n",
      "batch time cost: 5.220868825912476\n",
      "Relu Train Epoch: 0 [249600/318582 (1%)]\tLoss: 0.637316\n",
      "Epoch: 0, batch: 3901\n",
      "loss None\n",
      "batch time cost: 5.217252969741821\n",
      "Epoch: 0, batch: 3902\n",
      "loss None\n",
      "batch time cost: 5.411783933639526\n",
      "Epoch: 0, batch: 3903\n",
      "loss None\n",
      "batch time cost: 5.304239273071289\n",
      "Epoch: 0, batch: 3904\n",
      "loss None\n",
      "batch time cost: 5.620410203933716\n",
      "Epoch: 0, batch: 3905\n",
      "loss None\n",
      "batch time cost: 5.239258766174316\n",
      "Epoch: 0, batch: 3906\n",
      "loss None\n",
      "batch time cost: 5.2542150020599365\n",
      "Epoch: 0, batch: 3907\n",
      "loss None\n",
      "batch time cost: 5.245261907577515\n",
      "Epoch: 0, batch: 3908\n",
      "loss None\n",
      "batch time cost: 5.286800861358643\n",
      "Epoch: 0, batch: 3909\n",
      "loss None\n",
      "batch time cost: 5.2121710777282715\n",
      "Epoch: 0, batch: 3910\n",
      "loss None\n",
      "batch time cost: 5.368674039840698\n",
      "Relu Train Epoch: 0 [250240/318582 (1%)]\tLoss: 0.873829\n",
      "Epoch: 0, batch: 3911\n",
      "loss None\n",
      "batch time cost: 5.6107141971588135\n",
      "Epoch: 0, batch: 3912\n",
      "loss None\n",
      "batch time cost: 5.266240119934082\n",
      "Epoch: 0, batch: 3913\n",
      "loss None\n",
      "batch time cost: 5.32726788520813\n",
      "Epoch: 0, batch: 3914\n",
      "loss None\n",
      "batch time cost: 5.291209936141968\n",
      "Epoch: 0, batch: 3915\n",
      "loss None\n",
      "batch time cost: 5.245381116867065\n",
      "Epoch: 0, batch: 3916\n",
      "loss None\n",
      "batch time cost: 5.3180999755859375\n",
      "Epoch: 0, batch: 3917\n",
      "loss None\n",
      "batch time cost: 5.253826141357422\n",
      "Epoch: 0, batch: 3918\n",
      "loss None\n",
      "batch time cost: 5.275306224822998\n",
      "Epoch: 0, batch: 3919\n",
      "loss None\n",
      "batch time cost: 5.56452202796936\n",
      "Epoch: 0, batch: 3920\n",
      "loss None\n",
      "batch time cost: 5.314404010772705\n",
      "Relu Train Epoch: 0 [250880/318582 (1%)]\tLoss: 0.846349\n",
      "Epoch: 0, batch: 3921\n",
      "loss None\n",
      "batch time cost: 5.276845216751099\n",
      "Epoch: 0, batch: 3922\n",
      "loss None\n",
      "batch time cost: 5.281249046325684\n",
      "Epoch: 0, batch: 3923\n",
      "loss None\n",
      "batch time cost: 5.275829076766968\n",
      "Epoch: 0, batch: 3924\n",
      "loss None\n",
      "batch time cost: 5.826873064041138\n",
      "Epoch: 0, batch: 3925\n",
      "loss None\n",
      "batch time cost: 5.305437803268433\n",
      "Epoch: 0, batch: 3926\n",
      "loss None\n",
      "batch time cost: 5.657083034515381\n",
      "Epoch: 0, batch: 3927\n",
      "loss None\n",
      "batch time cost: 5.25334620475769\n",
      "Epoch: 0, batch: 3928\n",
      "loss None\n",
      "batch time cost: 5.2469611167907715\n",
      "Epoch: 0, batch: 3929\n",
      "loss None\n",
      "batch time cost: 5.269362211227417\n",
      "Epoch: 0, batch: 3930\n",
      "loss None\n",
      "batch time cost: 5.278046369552612\n",
      "Relu Train Epoch: 0 [251520/318582 (1%)]\tLoss: 0.728722\n",
      "Epoch: 0, batch: 3931\n",
      "loss None\n",
      "batch time cost: 5.3427228927612305\n",
      "Epoch: 0, batch: 3932\n",
      "loss None\n",
      "batch time cost: 5.283041954040527\n",
      "Epoch: 0, batch: 3933\n",
      "loss None\n",
      "batch time cost: 5.522967100143433\n",
      "Epoch: 0, batch: 3934\n",
      "loss None\n",
      "batch time cost: 5.238922119140625\n",
      "Epoch: 0, batch: 3935\n",
      "loss None\n",
      "batch time cost: 5.406493902206421\n",
      "Epoch: 0, batch: 3936\n",
      "loss None\n",
      "batch time cost: 5.28731107711792\n",
      "Epoch: 0, batch: 3937\n",
      "loss None\n",
      "batch time cost: 5.2587127685546875\n",
      "Epoch: 0, batch: 3938\n",
      "loss None\n",
      "batch time cost: 5.290116310119629\n",
      "Epoch: 0, batch: 3939\n",
      "loss None\n",
      "batch time cost: 5.270437002182007\n",
      "Epoch: 0, batch: 3940\n",
      "loss None\n",
      "batch time cost: 5.58332085609436\n",
      "Relu Train Epoch: 0 [252160/318582 (1%)]\tLoss: 0.869766\n",
      "Epoch: 0, batch: 3941\n",
      "loss None\n",
      "batch time cost: 5.267212867736816\n",
      "Epoch: 0, batch: 3942\n",
      "loss None\n",
      "batch time cost: 5.2678492069244385\n",
      "Epoch: 0, batch: 3943\n",
      "loss None\n",
      "batch time cost: 5.280659914016724\n",
      "Epoch: 0, batch: 3944\n",
      "loss None\n",
      "batch time cost: 5.240691900253296\n",
      "Epoch: 0, batch: 3945\n",
      "loss None\n",
      "batch time cost: 5.3088698387146\n",
      "Epoch: 0, batch: 3946\n",
      "loss None\n",
      "batch time cost: 5.345685005187988\n",
      "Epoch: 0, batch: 3947\n",
      "loss None\n",
      "batch time cost: 5.257925987243652\n",
      "Epoch: 0, batch: 3948\n",
      "loss None\n",
      "batch time cost: 5.596503973007202\n",
      "Epoch: 0, batch: 3949\n",
      "loss None\n",
      "batch time cost: 5.270071983337402\n",
      "Epoch: 0, batch: 3950\n",
      "loss None\n",
      "batch time cost: 5.215252876281738\n",
      "Relu Train Epoch: 0 [252800/318582 (1%)]\tLoss: 0.820371\n",
      "Epoch: 0, batch: 3951\n",
      "loss None\n",
      "batch time cost: 5.266639232635498\n",
      "Epoch: 0, batch: 3952\n",
      "loss None\n",
      "batch time cost: 5.262840032577515\n",
      "Epoch: 0, batch: 3953\n",
      "loss None\n",
      "batch time cost: 5.265278100967407\n",
      "Epoch: 0, batch: 3954\n",
      "loss None\n",
      "batch time cost: 5.290457725524902\n",
      "Epoch: 0, batch: 3955\n",
      "loss None\n",
      "batch time cost: 5.5794291496276855\n",
      "Epoch: 0, batch: 3956\n",
      "loss None\n",
      "batch time cost: 5.277160406112671\n",
      "Epoch: 0, batch: 3957\n",
      "loss None\n",
      "batch time cost: 5.31401801109314\n",
      "Epoch: 0, batch: 3958\n",
      "loss None\n",
      "batch time cost: 5.294818878173828\n",
      "Epoch: 0, batch: 3959\n",
      "loss None\n",
      "batch time cost: 5.330181837081909\n",
      "Epoch: 0, batch: 3960\n",
      "loss None\n",
      "batch time cost: 5.251913070678711\n",
      "Relu Train Epoch: 0 [253440/318582 (1%)]\tLoss: 0.696746\n",
      "Epoch: 0, batch: 3961\n",
      "loss None\n",
      "batch time cost: 5.280900716781616\n",
      "Epoch: 0, batch: 3962\n",
      "loss None\n",
      "batch time cost: 5.570677995681763\n",
      "Epoch: 0, batch: 3963\n",
      "loss None\n",
      "batch time cost: 5.2893548011779785\n",
      "Epoch: 0, batch: 3964\n",
      "loss None\n",
      "batch time cost: 5.278509140014648\n",
      "Epoch: 0, batch: 3965\n",
      "loss None\n",
      "batch time cost: 5.278579950332642\n",
      "Epoch: 0, batch: 3966\n",
      "loss None\n",
      "batch time cost: 5.248953819274902\n",
      "Epoch: 0, batch: 3967\n",
      "loss None\n",
      "batch time cost: 5.252702951431274\n",
      "Epoch: 0, batch: 3968\n",
      "loss None\n",
      "batch time cost: 5.320616960525513\n",
      "Epoch: 0, batch: 3969\n",
      "loss None\n",
      "batch time cost: 5.982563018798828\n",
      "Epoch: 0, batch: 3970\n",
      "loss None\n",
      "batch time cost: 5.2744951248168945\n",
      "Relu Train Epoch: 0 [254080/318582 (1%)]\tLoss: 0.926035\n",
      "Epoch: 0, batch: 3971\n",
      "loss None\n",
      "batch time cost: 5.284548997879028\n",
      "Epoch: 0, batch: 3972\n",
      "loss None\n",
      "batch time cost: 5.232881307601929\n",
      "Epoch: 0, batch: 3973\n",
      "loss None\n",
      "batch time cost: 5.240182161331177\n",
      "Epoch: 0, batch: 3974\n",
      "loss None\n",
      "batch time cost: 5.254555940628052\n",
      "Epoch: 0, batch: 3975\n",
      "loss None\n",
      "batch time cost: 5.279744863510132\n",
      "Epoch: 0, batch: 3976\n",
      "loss None\n",
      "batch time cost: 5.7022058963775635\n",
      "Epoch: 0, batch: 3977\n",
      "loss None\n",
      "batch time cost: 5.282104730606079\n",
      "Epoch: 0, batch: 3978\n",
      "loss None\n",
      "batch time cost: 5.293885946273804\n",
      "Epoch: 0, batch: 3979\n",
      "loss None\n",
      "batch time cost: 5.2425782680511475\n",
      "Epoch: 0, batch: 3980\n",
      "loss None\n",
      "batch time cost: 5.404410123825073\n",
      "Relu Train Epoch: 0 [254720/318582 (1%)]\tLoss: 0.833271\n",
      "Epoch: 0, batch: 3981\n",
      "loss None\n",
      "batch time cost: 5.250298023223877\n",
      "Epoch: 0, batch: 3982\n",
      "loss None\n",
      "batch time cost: 5.276433229446411\n",
      "Epoch: 0, batch: 3983\n",
      "loss None\n",
      "batch time cost: 5.286228895187378\n",
      "Epoch: 0, batch: 3984\n",
      "loss None\n",
      "batch time cost: 5.687408924102783\n",
      "Epoch: 0, batch: 3985\n",
      "loss None\n",
      "batch time cost: 5.345963001251221\n",
      "Epoch: 0, batch: 3986\n",
      "loss None\n",
      "batch time cost: 5.281416893005371\n",
      "Epoch: 0, batch: 3987\n",
      "loss None\n",
      "batch time cost: 5.285820007324219\n",
      "Epoch: 0, batch: 3988\n",
      "loss None\n",
      "batch time cost: 5.286190986633301\n",
      "Epoch: 0, batch: 3989\n",
      "loss None\n",
      "batch time cost: 5.269133806228638\n",
      "Epoch: 0, batch: 3990\n",
      "loss None\n",
      "batch time cost: 5.3208513259887695\n",
      "Relu Train Epoch: 0 [255360/318582 (1%)]\tLoss: 0.648620\n",
      "Epoch: 0, batch: 3991\n",
      "loss None\n",
      "batch time cost: 5.585449934005737\n",
      "Epoch: 0, batch: 3992\n",
      "loss None\n",
      "batch time cost: 5.287009000778198\n",
      "Epoch: 0, batch: 3993\n",
      "loss None\n",
      "batch time cost: 5.259065866470337\n",
      "Epoch: 0, batch: 3994\n",
      "loss None\n",
      "batch time cost: 5.273845911026001\n",
      "Epoch: 0, batch: 3995\n",
      "loss None\n",
      "batch time cost: 5.313720703125\n",
      "Epoch: 0, batch: 3996\n",
      "loss None\n",
      "batch time cost: 5.255208969116211\n",
      "Epoch: 0, batch: 3997\n",
      "loss None\n",
      "batch time cost: 5.257504940032959\n",
      "Epoch: 0, batch: 3998\n",
      "loss None\n",
      "batch time cost: 5.621671915054321\n",
      "Epoch: 0, batch: 3999\n",
      "loss None\n",
      "batch time cost: 5.283419847488403\n",
      "Epoch: 0, batch: 4000\n",
      "loss None\n",
      "batch time cost: 5.26369309425354\n",
      "Relu Train Epoch: 0 [256000/318582 (1%)]\tLoss: 0.762282\n",
      "Epoch: 0, batch: 4001\n",
      "loss None\n",
      "batch time cost: 5.2802839279174805\n",
      "Epoch: 0, batch: 4002\n",
      "loss None\n",
      "batch time cost: 5.244840860366821\n",
      "Epoch: 0, batch: 4003\n",
      "loss None\n",
      "batch time cost: 5.315266132354736\n",
      "Epoch: 0, batch: 4004\n",
      "loss None\n",
      "batch time cost: 5.27512001991272\n",
      "Epoch: 0, batch: 4005\n",
      "loss None\n",
      "batch time cost: 5.564884901046753\n",
      "Epoch: 0, batch: 4006\n",
      "loss None\n",
      "batch time cost: 5.208777904510498\n",
      "Epoch: 0, batch: 4007\n",
      "loss None\n",
      "batch time cost: 5.258526086807251\n",
      "Epoch: 0, batch: 4008\n",
      "loss None\n",
      "batch time cost: 5.244883060455322\n",
      "Epoch: 0, batch: 4009\n",
      "loss None\n",
      "batch time cost: 5.277527093887329\n",
      "Epoch: 0, batch: 4010\n",
      "loss None\n",
      "batch time cost: 5.310180187225342\n",
      "Relu Train Epoch: 0 [256640/318582 (1%)]\tLoss: 0.785212\n",
      "Epoch: 0, batch: 4011\n",
      "loss None\n",
      "batch time cost: 5.304579973220825\n",
      "Epoch: 0, batch: 4012\n",
      "loss None\n",
      "batch time cost: 5.204121828079224\n",
      "Epoch: 0, batch: 4013\n",
      "loss None\n",
      "batch time cost: 5.639288902282715\n",
      "Epoch: 0, batch: 4014\n",
      "loss None\n",
      "batch time cost: 5.693731784820557\n",
      "Epoch: 0, batch: 4015\n",
      "loss None\n",
      "batch time cost: 5.273900747299194\n",
      "Epoch: 0, batch: 4016\n",
      "loss None\n",
      "batch time cost: 5.2479729652404785\n",
      "Epoch: 0, batch: 4017\n",
      "loss None\n",
      "batch time cost: 5.291892051696777\n",
      "Epoch: 0, batch: 4018\n",
      "loss None\n",
      "batch time cost: 5.324110269546509\n",
      "Epoch: 0, batch: 4019\n",
      "loss None\n",
      "batch time cost: 5.326026916503906\n",
      "Epoch: 0, batch: 4020\n",
      "loss None\n",
      "batch time cost: 5.649607181549072\n",
      "Relu Train Epoch: 0 [257280/318582 (1%)]\tLoss: 0.980262\n",
      "Epoch: 0, batch: 4021\n",
      "loss None\n",
      "batch time cost: 5.3178489208221436\n",
      "Epoch: 0, batch: 4022\n",
      "loss None\n",
      "batch time cost: 5.328906059265137\n",
      "Epoch: 0, batch: 4023\n",
      "loss None\n",
      "batch time cost: 5.303743124008179\n",
      "Epoch: 0, batch: 4024\n",
      "loss None\n",
      "batch time cost: 5.263782978057861\n",
      "Epoch: 0, batch: 4025\n",
      "loss None\n",
      "batch time cost: 5.302845239639282\n",
      "Epoch: 0, batch: 4026\n",
      "loss None\n",
      "batch time cost: 5.223286867141724\n",
      "Epoch: 0, batch: 4027\n",
      "loss None\n",
      "batch time cost: 5.664816856384277\n",
      "Epoch: 0, batch: 4028\n",
      "loss None\n",
      "batch time cost: 5.274121999740601\n",
      "Epoch: 0, batch: 4029\n",
      "loss None\n",
      "batch time cost: 5.307846784591675\n",
      "Epoch: 0, batch: 4030\n",
      "loss None\n",
      "batch time cost: 5.206990003585815\n",
      "Relu Train Epoch: 0 [257920/318582 (1%)]\tLoss: 0.644840\n",
      "Epoch: 0, batch: 4031\n",
      "loss None\n",
      "batch time cost: 5.244656801223755\n",
      "Epoch: 0, batch: 4032\n",
      "loss None\n",
      "batch time cost: 5.210567235946655\n",
      "Epoch: 0, batch: 4033\n",
      "loss None\n",
      "batch time cost: 5.2355780601501465\n",
      "Epoch: 0, batch: 4034\n",
      "loss None\n",
      "batch time cost: 5.597453832626343\n",
      "Epoch: 0, batch: 4035\n",
      "loss None\n",
      "batch time cost: 5.248323917388916\n",
      "Epoch: 0, batch: 4036\n",
      "loss None\n",
      "batch time cost: 5.266368865966797\n",
      "Epoch: 0, batch: 4037\n",
      "loss None\n",
      "batch time cost: 5.287400960922241\n",
      "Epoch: 0, batch: 4038\n",
      "loss None\n",
      "batch time cost: 5.271273851394653\n",
      "Epoch: 0, batch: 4039\n",
      "loss None\n",
      "batch time cost: 5.291110992431641\n",
      "Epoch: 0, batch: 4040\n",
      "loss None\n",
      "batch time cost: 5.290304899215698\n",
      "Relu Train Epoch: 0 [258560/318582 (1%)]\tLoss: 0.712991\n",
      "Epoch: 0, batch: 4041\n",
      "loss None\n",
      "batch time cost: 5.642115831375122\n",
      "Epoch: 0, batch: 4042\n",
      "loss None\n",
      "batch time cost: 5.266252040863037\n",
      "Epoch: 0, batch: 4043\n",
      "loss None\n",
      "batch time cost: 5.257343053817749\n",
      "Epoch: 0, batch: 4044\n",
      "loss None\n",
      "batch time cost: 5.253612995147705\n",
      "Epoch: 0, batch: 4045\n",
      "loss None\n",
      "batch time cost: 5.296299934387207\n",
      "Epoch: 0, batch: 4046\n",
      "loss None\n",
      "batch time cost: 5.245425224304199\n",
      "Epoch: 0, batch: 4047\n",
      "loss None\n",
      "batch time cost: 5.282520055770874\n",
      "Epoch: 0, batch: 4048\n",
      "loss None\n",
      "batch time cost: 5.296669006347656\n",
      "Epoch: 0, batch: 4049\n",
      "loss None\n",
      "batch time cost: 5.5882649421691895\n",
      "Epoch: 0, batch: 4050\n",
      "loss None\n",
      "batch time cost: 5.237009048461914\n",
      "Relu Train Epoch: 0 [259200/318582 (1%)]\tLoss: 0.750986\n",
      "Epoch: 0, batch: 4051\n",
      "loss None\n",
      "batch time cost: 5.328260183334351\n",
      "Epoch: 0, batch: 4052\n",
      "loss None\n",
      "batch time cost: 5.31630277633667\n",
      "Epoch: 0, batch: 4053\n",
      "loss None\n",
      "batch time cost: 5.2871880531311035\n",
      "Epoch: 0, batch: 4054\n",
      "loss None\n",
      "batch time cost: 5.2505810260772705\n",
      "Epoch: 0, batch: 4055\n",
      "loss None\n",
      "batch time cost: 5.274829149246216\n",
      "Epoch: 0, batch: 4056\n",
      "loss None\n",
      "batch time cost: 5.596163749694824\n",
      "Epoch: 0, batch: 4057\n",
      "loss None\n",
      "batch time cost: 5.265964031219482\n",
      "Epoch: 0, batch: 4058\n",
      "loss None\n",
      "batch time cost: 5.2725300788879395\n",
      "Epoch: 0, batch: 4059\n",
      "loss None\n",
      "batch time cost: 5.4889490604400635\n",
      "Epoch: 0, batch: 4060\n",
      "loss None\n",
      "batch time cost: 5.263014793395996\n",
      "Relu Train Epoch: 0 [259840/318582 (1%)]\tLoss: 0.731374\n",
      "Epoch: 0, batch: 4061\n",
      "loss None\n",
      "batch time cost: 5.289559841156006\n",
      "Epoch: 0, batch: 4062\n",
      "loss None\n",
      "batch time cost: 5.2710700035095215\n",
      "Epoch: 0, batch: 4063\n",
      "loss None\n",
      "batch time cost: 5.6264259815216064\n",
      "Epoch: 0, batch: 4064\n",
      "loss None\n",
      "batch time cost: 5.277051210403442\n",
      "Epoch: 0, batch: 4065\n",
      "loss None\n",
      "batch time cost: 5.273019790649414\n",
      "Epoch: 0, batch: 4066\n",
      "loss None\n",
      "batch time cost: 5.237344980239868\n",
      "Epoch: 0, batch: 4067\n",
      "loss None\n",
      "batch time cost: 5.2795000076293945\n",
      "Epoch: 0, batch: 4068\n",
      "loss None\n",
      "batch time cost: 5.259742259979248\n",
      "Epoch: 0, batch: 4069\n",
      "loss None\n",
      "batch time cost: 5.280937910079956\n",
      "Epoch: 0, batch: 4070\n",
      "loss None\n",
      "batch time cost: 5.73173189163208\n",
      "Relu Train Epoch: 0 [260480/318582 (1%)]\tLoss: 0.674410\n",
      "Epoch: 0, batch: 4071\n",
      "loss None\n",
      "batch time cost: 5.285764932632446\n",
      "Epoch: 0, batch: 4072\n",
      "loss None\n",
      "batch time cost: 5.345762014389038\n",
      "Epoch: 0, batch: 4073\n",
      "loss None\n",
      "batch time cost: 5.2912890911102295\n",
      "Epoch: 0, batch: 4074\n",
      "loss None\n",
      "batch time cost: 5.297469854354858\n",
      "Epoch: 0, batch: 4075\n",
      "loss None\n",
      "batch time cost: 5.26795506477356\n",
      "Epoch: 0, batch: 4076\n",
      "loss None\n",
      "batch time cost: 5.312331914901733\n",
      "Epoch: 0, batch: 4077\n",
      "loss None\n",
      "batch time cost: 5.248826742172241\n",
      "Epoch: 0, batch: 4078\n",
      "loss None\n",
      "batch time cost: 5.622051239013672\n",
      "Epoch: 0, batch: 4079\n",
      "loss None\n",
      "batch time cost: 5.2725138664245605\n",
      "Epoch: 0, batch: 4080\n",
      "loss None\n",
      "batch time cost: 5.302134037017822\n",
      "Relu Train Epoch: 0 [261120/318582 (1%)]\tLoss: 0.669579\n",
      "Epoch: 0, batch: 4081\n",
      "loss None\n",
      "batch time cost: 5.314146995544434\n",
      "Epoch: 0, batch: 4082\n",
      "loss None\n",
      "batch time cost: 5.32033109664917\n",
      "Epoch: 0, batch: 4083\n",
      "loss None\n",
      "batch time cost: 5.288722038269043\n",
      "Epoch: 0, batch: 4084\n",
      "loss None\n",
      "batch time cost: 5.279560089111328\n",
      "Epoch: 0, batch: 4085\n",
      "loss None\n",
      "batch time cost: 5.557579040527344\n",
      "Epoch: 0, batch: 4086\n",
      "loss None\n",
      "batch time cost: 5.345901966094971\n",
      "Epoch: 0, batch: 4087\n",
      "loss None\n",
      "batch time cost: 5.267247915267944\n",
      "Epoch: 0, batch: 4088\n",
      "loss None\n",
      "batch time cost: 5.342801809310913\n",
      "Epoch: 0, batch: 4089\n",
      "loss None\n",
      "batch time cost: 5.22003698348999\n",
      "Epoch: 0, batch: 4090\n",
      "loss None\n",
      "batch time cost: 5.250336170196533\n",
      "Relu Train Epoch: 0 [261760/318582 (1%)]\tLoss: 0.772903\n",
      "Epoch: 0, batch: 4091\n",
      "loss None\n",
      "batch time cost: 5.194772958755493\n",
      "Epoch: 0, batch: 4092\n",
      "loss None\n",
      "batch time cost: 5.655025005340576\n",
      "Epoch: 0, batch: 4093\n",
      "loss None\n",
      "batch time cost: 5.444362163543701\n",
      "Epoch: 0, batch: 4094\n",
      "loss None\n",
      "batch time cost: 5.357436895370483\n",
      "Epoch: 0, batch: 4095\n",
      "loss None\n",
      "batch time cost: 5.2627482414245605\n",
      "Epoch: 0, batch: 4096\n",
      "loss None\n",
      "batch time cost: 5.306907892227173\n",
      "Epoch: 0, batch: 4097\n",
      "loss None\n",
      "batch time cost: 5.322184085845947\n",
      "Epoch: 0, batch: 4098\n",
      "loss None\n",
      "batch time cost: 5.359037160873413\n",
      "Epoch: 0, batch: 4099\n",
      "loss None\n",
      "batch time cost: 5.580449104309082\n",
      "Epoch: 0, batch: 4100\n",
      "loss None\n",
      "batch time cost: 5.318822860717773\n",
      "Relu Train Epoch: 0 [262400/318582 (1%)]\tLoss: 0.835324\n",
      "Epoch: 0, batch: 4101\n",
      "loss None\n",
      "batch time cost: 5.349948167800903\n",
      "Epoch: 0, batch: 4102\n",
      "loss None\n",
      "batch time cost: 5.285836935043335\n",
      "Epoch: 0, batch: 4103\n",
      "loss None\n",
      "batch time cost: 5.290388107299805\n",
      "Epoch: 0, batch: 4104\n",
      "loss None\n",
      "batch time cost: 5.315515041351318\n",
      "Epoch: 0, batch: 4105\n",
      "loss None\n",
      "batch time cost: 5.318173885345459\n",
      "Epoch: 0, batch: 4106\n",
      "loss None\n",
      "batch time cost: 5.571444034576416\n",
      "Epoch: 0, batch: 4107\n",
      "loss None\n",
      "batch time cost: 5.27053427696228\n",
      "Epoch: 0, batch: 4108\n",
      "loss None\n",
      "batch time cost: 5.266980886459351\n",
      "Epoch: 0, batch: 4109\n",
      "loss None\n",
      "batch time cost: 5.34119439125061\n",
      "Epoch: 0, batch: 4110\n",
      "loss None\n",
      "batch time cost: 5.239578008651733\n",
      "Relu Train Epoch: 0 [263040/318582 (1%)]\tLoss: 0.852375\n",
      "Epoch: 0, batch: 4111\n",
      "loss None\n",
      "batch time cost: 5.221820116043091\n",
      "Epoch: 0, batch: 4112\n",
      "loss None\n",
      "batch time cost: 5.264636754989624\n",
      "Epoch: 0, batch: 4113\n",
      "loss None\n",
      "batch time cost: 5.279771089553833\n",
      "Epoch: 0, batch: 4114\n",
      "loss None\n",
      "batch time cost: 5.589557886123657\n",
      "Epoch: 0, batch: 4115\n",
      "loss None\n",
      "batch time cost: 5.295375823974609\n",
      "Epoch: 0, batch: 4116\n",
      "loss None\n",
      "batch time cost: 5.3379669189453125\n",
      "Epoch: 0, batch: 4117\n",
      "loss None\n",
      "batch time cost: 5.358738899230957\n",
      "Epoch: 0, batch: 4118\n",
      "loss None\n",
      "batch time cost: 5.294742107391357\n",
      "Epoch: 0, batch: 4119\n",
      "loss None\n",
      "batch time cost: 5.286890983581543\n",
      "Epoch: 0, batch: 4120\n",
      "loss None\n",
      "batch time cost: 5.254764080047607\n",
      "Relu Train Epoch: 0 [263680/318582 (1%)]\tLoss: 0.698495\n",
      "Epoch: 0, batch: 4121\n",
      "loss None\n",
      "batch time cost: 5.645542860031128\n",
      "Epoch: 0, batch: 4122\n",
      "loss None\n",
      "batch time cost: 5.313488006591797\n",
      "Epoch: 0, batch: 4123\n",
      "loss None\n",
      "batch time cost: 5.286789178848267\n",
      "Epoch: 0, batch: 4124\n",
      "loss None\n",
      "batch time cost: 5.2699689865112305\n",
      "Epoch: 0, batch: 4125\n",
      "loss None\n",
      "batch time cost: 5.270448207855225\n",
      "Epoch: 0, batch: 4126\n",
      "loss None\n",
      "batch time cost: 5.3035728931427\n",
      "Epoch: 0, batch: 4127\n",
      "loss None\n",
      "batch time cost: 5.325881242752075\n",
      "Epoch: 0, batch: 4128\n",
      "loss None\n",
      "batch time cost: 5.656503677368164\n",
      "Epoch: 0, batch: 4129\n",
      "loss None\n",
      "batch time cost: 5.268317222595215\n",
      "Epoch: 0, batch: 4130\n",
      "loss None\n",
      "batch time cost: 5.285127878189087\n",
      "Relu Train Epoch: 0 [264320/318582 (1%)]\tLoss: 0.758202\n",
      "Epoch: 0, batch: 4131\n",
      "loss None\n",
      "batch time cost: 5.267936944961548\n",
      "Epoch: 0, batch: 4132\n",
      "loss None\n",
      "batch time cost: 5.287778854370117\n",
      "Epoch: 0, batch: 4133\n",
      "loss None\n",
      "batch time cost: 5.251190900802612\n",
      "Epoch: 0, batch: 4134\n",
      "loss None\n",
      "batch time cost: 5.306729078292847\n",
      "Epoch: 0, batch: 4135\n",
      "loss None\n",
      "batch time cost: 5.6179821491241455\n",
      "Epoch: 0, batch: 4136\n",
      "loss None\n",
      "batch time cost: 5.24594783782959\n",
      "Epoch: 0, batch: 4137\n",
      "loss None\n",
      "batch time cost: 5.297335624694824\n",
      "Epoch: 0, batch: 4138\n",
      "loss None\n",
      "batch time cost: 5.273505210876465\n",
      "Epoch: 0, batch: 4139\n",
      "loss None\n",
      "batch time cost: 5.27061915397644\n",
      "Epoch: 0, batch: 4140\n",
      "loss None\n",
      "batch time cost: 5.2298500537872314\n",
      "Relu Train Epoch: 0 [264960/318582 (1%)]\tLoss: 0.750475\n",
      "Epoch: 0, batch: 4141\n",
      "loss None\n",
      "batch time cost: 5.325224876403809\n",
      "Epoch: 0, batch: 4142\n",
      "loss None\n",
      "batch time cost: 5.348143100738525\n",
      "Epoch: 0, batch: 4143\n",
      "loss None\n",
      "batch time cost: 5.591303825378418\n",
      "Epoch: 0, batch: 4144\n",
      "loss None\n",
      "batch time cost: 5.255131959915161\n",
      "Epoch: 0, batch: 4145\n",
      "loss None\n",
      "batch time cost: 5.306956052780151\n",
      "Epoch: 0, batch: 4146\n",
      "loss None\n",
      "batch time cost: 5.2595930099487305\n",
      "Epoch: 0, batch: 4147\n",
      "loss None\n",
      "batch time cost: 5.338172912597656\n",
      "Epoch: 0, batch: 4148\n",
      "loss None\n",
      "batch time cost: 5.27843976020813\n",
      "Epoch: 0, batch: 4149\n",
      "loss None\n",
      "batch time cost: 5.300900936126709\n",
      "Epoch: 0, batch: 4150\n",
      "loss None\n",
      "batch time cost: 5.602251052856445\n",
      "Relu Train Epoch: 0 [265600/318582 (1%)]\tLoss: 0.840796\n",
      "Epoch: 0, batch: 4151\n",
      "loss None\n",
      "batch time cost: 5.227953195571899\n",
      "Epoch: 0, batch: 4152\n",
      "loss None\n",
      "batch time cost: 5.268967151641846\n",
      "Epoch: 0, batch: 4153\n",
      "loss None\n",
      "batch time cost: 5.24038290977478\n",
      "Epoch: 0, batch: 4154\n",
      "loss None\n",
      "batch time cost: 5.218844890594482\n",
      "Epoch: 0, batch: 4155\n",
      "loss None\n",
      "batch time cost: 5.264520168304443\n",
      "Epoch: 0, batch: 4156\n",
      "loss None\n",
      "batch time cost: 5.251657962799072\n",
      "Epoch: 0, batch: 4157\n",
      "loss None\n",
      "batch time cost: 5.542513847351074\n",
      "Epoch: 0, batch: 4158\n",
      "loss None\n",
      "batch time cost: 5.310877084732056\n",
      "Epoch: 0, batch: 4159\n",
      "loss None\n",
      "batch time cost: 5.24884295463562\n",
      "Epoch: 0, batch: 4160\n",
      "loss None\n",
      "batch time cost: 5.344779014587402\n",
      "Relu Train Epoch: 0 [266240/318582 (1%)]\tLoss: 0.823275\n",
      "Epoch: 0, batch: 4161\n",
      "loss None\n",
      "batch time cost: 5.237100839614868\n",
      "Epoch: 0, batch: 4162\n",
      "loss None\n",
      "batch time cost: 5.2841551303863525\n",
      "Epoch: 0, batch: 4163\n",
      "loss None\n",
      "batch time cost: 5.262299299240112\n",
      "Epoch: 0, batch: 4164\n",
      "loss None\n",
      "batch time cost: 5.610225200653076\n",
      "Epoch: 0, batch: 4165\n",
      "loss None\n",
      "batch time cost: 5.2620532512664795\n",
      "Epoch: 0, batch: 4166\n",
      "loss None\n",
      "batch time cost: 5.272518157958984\n",
      "Epoch: 0, batch: 4167\n",
      "loss None\n",
      "batch time cost: 5.235527992248535\n",
      "Epoch: 0, batch: 4168\n",
      "loss None\n",
      "batch time cost: 5.226557016372681\n",
      "Epoch: 0, batch: 4169\n",
      "loss None\n",
      "batch time cost: 5.243276119232178\n",
      "Epoch: 0, batch: 4170\n",
      "loss None\n",
      "batch time cost: 5.257797956466675\n",
      "Relu Train Epoch: 0 [266880/318582 (1%)]\tLoss: 0.663499\n",
      "Epoch: 0, batch: 4171\n",
      "loss None\n",
      "batch time cost: 5.684599161148071\n",
      "Epoch: 0, batch: 4172\n",
      "loss None\n",
      "batch time cost: 5.2632668018341064\n",
      "Epoch: 0, batch: 4173\n",
      "loss None\n",
      "batch time cost: 5.295774936676025\n",
      "Epoch: 0, batch: 4174\n",
      "loss None\n",
      "batch time cost: 5.2894580364227295\n",
      "Epoch: 0, batch: 4175\n",
      "loss None\n",
      "batch time cost: 5.237659215927124\n",
      "Epoch: 0, batch: 4176\n",
      "loss None\n",
      "batch time cost: 5.285706043243408\n",
      "Epoch: 0, batch: 4177\n",
      "loss None\n",
      "batch time cost: 5.33105993270874\n",
      "Epoch: 0, batch: 4178\n",
      "loss None\n",
      "batch time cost: 5.38195013999939\n",
      "Epoch: 0, batch: 4179\n",
      "loss None\n",
      "batch time cost: 5.60844612121582\n",
      "Epoch: 0, batch: 4180\n",
      "loss None\n",
      "batch time cost: 5.269847869873047\n",
      "Relu Train Epoch: 0 [267520/318582 (1%)]\tLoss: 0.979076\n",
      "Epoch: 0, batch: 4181\n",
      "loss None\n",
      "batch time cost: 5.340968132019043\n",
      "Epoch: 0, batch: 4182\n",
      "loss None\n",
      "batch time cost: 5.281980037689209\n",
      "Epoch: 0, batch: 4183\n",
      "loss None\n",
      "batch time cost: 5.332059860229492\n",
      "Epoch: 0, batch: 4184\n",
      "loss None\n",
      "batch time cost: 5.284836769104004\n",
      "Epoch: 0, batch: 4185\n",
      "loss None\n",
      "batch time cost: 5.294155836105347\n",
      "Epoch: 0, batch: 4186\n",
      "loss None\n",
      "batch time cost: 5.6744749546051025\n",
      "Epoch: 0, batch: 4187\n",
      "loss None\n",
      "batch time cost: 5.262623071670532\n",
      "Epoch: 0, batch: 4188\n",
      "loss None\n",
      "batch time cost: 5.365600824356079\n",
      "Epoch: 0, batch: 4189\n",
      "loss None\n",
      "batch time cost: 5.2533087730407715\n",
      "Epoch: 0, batch: 4190\n",
      "loss None\n",
      "batch time cost: 5.241976976394653\n",
      "Relu Train Epoch: 0 [268160/318582 (1%)]\tLoss: 0.759626\n",
      "Epoch: 0, batch: 4191\n",
      "loss None\n",
      "batch time cost: 5.238656044006348\n",
      "Epoch: 0, batch: 4192\n",
      "loss None\n",
      "batch time cost: 5.284398078918457\n",
      "Epoch: 0, batch: 4193\n",
      "loss None\n",
      "batch time cost: 5.553805112838745\n",
      "Epoch: 0, batch: 4194\n",
      "loss None\n",
      "batch time cost: 5.634905815124512\n",
      "Epoch: 0, batch: 4195\n",
      "loss None\n",
      "batch time cost: 5.3977251052856445\n",
      "Epoch: 0, batch: 4196\n",
      "loss None\n",
      "batch time cost: 5.314990758895874\n",
      "Epoch: 0, batch: 4197\n",
      "loss None\n",
      "batch time cost: 5.43304967880249\n",
      "Epoch: 0, batch: 4198\n",
      "loss None\n",
      "batch time cost: 5.308300018310547\n",
      "Epoch: 0, batch: 4199\n",
      "loss None\n",
      "batch time cost: 5.386376857757568\n",
      "Epoch: 0, batch: 4200\n",
      "loss None\n",
      "batch time cost: 5.613512992858887\n",
      "Relu Train Epoch: 0 [268800/318582 (1%)]\tLoss: 0.819726\n",
      "Epoch: 0, batch: 4201\n",
      "loss None\n",
      "batch time cost: 5.254451036453247\n",
      "Epoch: 0, batch: 4202\n",
      "loss None\n",
      "batch time cost: 5.322717189788818\n",
      "Epoch: 0, batch: 4203\n",
      "loss None\n",
      "batch time cost: 5.2591211795806885\n",
      "Epoch: 0, batch: 4204\n",
      "loss None\n",
      "batch time cost: 5.275676965713501\n",
      "Epoch: 0, batch: 4205\n",
      "loss None\n",
      "batch time cost: 5.3590919971466064\n",
      "Epoch: 0, batch: 4206\n",
      "loss None\n",
      "batch time cost: 5.261247873306274\n",
      "Epoch: 0, batch: 4207\n",
      "loss None\n",
      "batch time cost: 5.2500927448272705\n",
      "Epoch: 0, batch: 4208\n",
      "loss None\n",
      "batch time cost: 5.915186882019043\n",
      "Epoch: 0, batch: 4209\n",
      "loss None\n",
      "batch time cost: 5.431509017944336\n",
      "Epoch: 0, batch: 4210\n",
      "loss None\n",
      "batch time cost: 5.3079822063446045\n",
      "Relu Train Epoch: 0 [269440/318582 (1%)]\tLoss: 0.833436\n",
      "Epoch: 0, batch: 4211\n",
      "loss None\n",
      "batch time cost: 5.301549911499023\n",
      "Epoch: 0, batch: 4212\n",
      "loss None\n",
      "batch time cost: 5.291230916976929\n",
      "Epoch: 0, batch: 4213\n",
      "loss None\n",
      "batch time cost: 5.299935817718506\n",
      "Epoch: 0, batch: 4214\n",
      "loss None\n",
      "batch time cost: 5.307685136795044\n",
      "Epoch: 0, batch: 4215\n",
      "loss None\n",
      "batch time cost: 5.602830171585083\n",
      "Epoch: 0, batch: 4216\n",
      "loss None\n",
      "batch time cost: 5.515917062759399\n",
      "Epoch: 0, batch: 4217\n",
      "loss None\n",
      "batch time cost: 5.306607246398926\n",
      "Epoch: 0, batch: 4218\n",
      "loss None\n",
      "batch time cost: 5.329604864120483\n",
      "Epoch: 0, batch: 4219\n",
      "loss None\n",
      "batch time cost: 5.309950113296509\n",
      "Epoch: 0, batch: 4220\n",
      "loss None\n",
      "batch time cost: 5.311411142349243\n",
      "Relu Train Epoch: 0 [270080/318582 (1%)]\tLoss: 0.812324\n",
      "Epoch: 0, batch: 4221\n",
      "loss None\n",
      "batch time cost: 5.282591104507446\n",
      "Epoch: 0, batch: 4222\n",
      "loss None\n",
      "batch time cost: 5.5584540367126465\n",
      "Epoch: 0, batch: 4223\n",
      "loss None\n",
      "batch time cost: 5.32625412940979\n",
      "Epoch: 0, batch: 4224\n",
      "loss None\n",
      "batch time cost: 5.260677814483643\n",
      "Epoch: 0, batch: 4225\n",
      "loss None\n",
      "batch time cost: 5.252210855484009\n",
      "Epoch: 0, batch: 4226\n",
      "loss None\n",
      "batch time cost: 5.279928207397461\n",
      "Epoch: 0, batch: 4227\n",
      "loss None\n",
      "batch time cost: 5.3315558433532715\n",
      "Epoch: 0, batch: 4228\n",
      "loss None\n",
      "batch time cost: 5.297853946685791\n",
      "Epoch: 0, batch: 4229\n",
      "loss None\n",
      "batch time cost: 5.5967631340026855\n",
      "Epoch: 0, batch: 4230\n",
      "loss None\n",
      "batch time cost: 5.2720959186553955\n",
      "Relu Train Epoch: 0 [270720/318582 (1%)]\tLoss: 0.772412\n",
      "Epoch: 0, batch: 4231\n",
      "loss None\n",
      "batch time cost: 5.2887492179870605\n",
      "Epoch: 0, batch: 4232\n",
      "loss None\n",
      "batch time cost: 5.2968127727508545\n",
      "Epoch: 0, batch: 4233\n",
      "loss None\n",
      "batch time cost: 5.272310018539429\n",
      "Epoch: 0, batch: 4234\n",
      "loss None\n",
      "batch time cost: 5.353675127029419\n",
      "Epoch: 0, batch: 4235\n",
      "loss None\n",
      "batch time cost: 5.284220933914185\n",
      "Epoch: 0, batch: 4236\n",
      "loss None\n",
      "batch time cost: 5.599862098693848\n",
      "Epoch: 0, batch: 4237\n",
      "loss None\n",
      "batch time cost: 5.273091077804565\n",
      "Epoch: 0, batch: 4238\n",
      "loss None\n",
      "batch time cost: 5.308288097381592\n",
      "Epoch: 0, batch: 4239\n",
      "loss None\n",
      "batch time cost: 5.3067216873168945\n",
      "Epoch: 0, batch: 4240\n",
      "loss None\n",
      "batch time cost: 5.326735973358154\n",
      "Relu Train Epoch: 0 [271360/318582 (1%)]\tLoss: 0.910561\n",
      "Epoch: 0, batch: 4241\n",
      "loss None\n",
      "batch time cost: 5.261850118637085\n",
      "Epoch: 0, batch: 4242\n",
      "loss None\n",
      "batch time cost: 5.23078989982605\n",
      "Epoch: 0, batch: 4243\n",
      "loss None\n",
      "batch time cost: 5.223419904708862\n",
      "Epoch: 0, batch: 4244\n",
      "loss None\n",
      "batch time cost: 5.60587215423584\n",
      "Epoch: 0, batch: 4245\n",
      "loss None\n",
      "batch time cost: 5.329547882080078\n",
      "Epoch: 0, batch: 4246\n",
      "loss None\n",
      "batch time cost: 5.292276859283447\n",
      "Epoch: 0, batch: 4247\n",
      "loss None\n",
      "batch time cost: 5.300401210784912\n",
      "Epoch: 0, batch: 4248\n",
      "loss None\n",
      "batch time cost: 5.306754112243652\n",
      "Epoch: 0, batch: 4249\n",
      "loss None\n",
      "batch time cost: 5.273918867111206\n",
      "Epoch: 0, batch: 4250\n",
      "loss None\n",
      "batch time cost: 5.416916131973267\n",
      "Relu Train Epoch: 0 [272000/318582 (1%)]\tLoss: 1.075425\n",
      "Epoch: 0, batch: 4251\n",
      "loss None\n",
      "batch time cost: 5.672302961349487\n",
      "Epoch: 0, batch: 4252\n",
      "loss None\n",
      "batch time cost: 5.331644058227539\n",
      "Epoch: 0, batch: 4253\n",
      "loss None\n",
      "batch time cost: 5.254889249801636\n",
      "Epoch: 0, batch: 4254\n",
      "loss None\n",
      "batch time cost: 5.29323410987854\n",
      "Epoch: 0, batch: 4255\n",
      "loss None\n",
      "batch time cost: 5.301393985748291\n",
      "Epoch: 0, batch: 4256\n",
      "loss None\n",
      "batch time cost: 5.26906681060791\n",
      "Epoch: 0, batch: 4257\n",
      "loss None\n",
      "batch time cost: 5.298261880874634\n",
      "Epoch: 0, batch: 4258\n",
      "loss None\n",
      "batch time cost: 5.61988091468811\n",
      "Epoch: 0, batch: 4259\n",
      "loss None\n",
      "batch time cost: 5.318188905715942\n",
      "Epoch: 0, batch: 4260\n",
      "loss None\n",
      "batch time cost: 5.2473978996276855\n",
      "Relu Train Epoch: 0 [272640/318582 (1%)]\tLoss: 0.906239\n",
      "Epoch: 0, batch: 4261\n",
      "loss None\n",
      "batch time cost: 5.348460912704468\n",
      "Epoch: 0, batch: 4262\n",
      "loss None\n",
      "batch time cost: 5.355047941207886\n",
      "Epoch: 0, batch: 4263\n",
      "loss None\n",
      "batch time cost: 5.299657106399536\n",
      "Epoch: 0, batch: 4264\n",
      "loss None\n",
      "batch time cost: 5.276877164840698\n",
      "Epoch: 0, batch: 4265\n",
      "loss None\n",
      "batch time cost: 5.557560205459595\n",
      "Epoch: 0, batch: 4266\n",
      "loss None\n",
      "batch time cost: 5.276160955429077\n",
      "Epoch: 0, batch: 4267\n",
      "loss None\n",
      "batch time cost: 5.230291843414307\n",
      "Epoch: 0, batch: 4268\n",
      "loss None\n",
      "batch time cost: 5.235837936401367\n",
      "Epoch: 0, batch: 4269\n",
      "loss None\n",
      "batch time cost: 5.350828170776367\n",
      "Epoch: 0, batch: 4270\n",
      "loss None\n",
      "batch time cost: 5.229043960571289\n",
      "Relu Train Epoch: 0 [273280/318582 (1%)]\tLoss: 0.699425\n",
      "Epoch: 0, batch: 4271\n",
      "loss None\n",
      "batch time cost: 5.243956804275513\n",
      "Epoch: 0, batch: 4272\n",
      "loss None\n",
      "batch time cost: 5.352878093719482\n",
      "Epoch: 0, batch: 4273\n",
      "loss None\n",
      "batch time cost: 5.683207035064697\n",
      "Epoch: 0, batch: 4274\n",
      "loss None\n",
      "batch time cost: 5.386929988861084\n",
      "Epoch: 0, batch: 4275\n",
      "loss None\n",
      "batch time cost: 5.252926826477051\n",
      "Epoch: 0, batch: 4276\n",
      "loss None\n",
      "batch time cost: 5.242664098739624\n",
      "Epoch: 0, batch: 4277\n",
      "loss None\n",
      "batch time cost: 5.266506195068359\n",
      "Epoch: 0, batch: 4278\n",
      "loss None\n",
      "batch time cost: 5.251489162445068\n",
      "Epoch: 0, batch: 4279\n",
      "loss None\n",
      "batch time cost: 5.294804334640503\n",
      "Epoch: 0, batch: 4280\n",
      "loss None\n",
      "batch time cost: 5.636634111404419\n",
      "Relu Train Epoch: 0 [273920/318582 (1%)]\tLoss: 1.024062\n",
      "Epoch: 0, batch: 4281\n",
      "loss None\n",
      "batch time cost: 5.294615030288696\n",
      "Epoch: 0, batch: 4282\n",
      "loss None\n",
      "batch time cost: 5.313605785369873\n",
      "Epoch: 0, batch: 4283\n",
      "loss None\n",
      "batch time cost: 5.247150182723999\n",
      "Epoch: 0, batch: 4284\n",
      "loss None\n",
      "batch time cost: 5.408203125\n",
      "Epoch: 0, batch: 4285\n",
      "loss None\n",
      "batch time cost: 5.240616083145142\n",
      "Epoch: 0, batch: 4286\n",
      "loss None\n",
      "batch time cost: 5.270803928375244\n",
      "Epoch: 0, batch: 4287\n",
      "loss None\n",
      "batch time cost: 5.608520984649658\n",
      "Epoch: 0, batch: 4288\n",
      "loss None\n",
      "batch time cost: 5.242218971252441\n",
      "Epoch: 0, batch: 4289\n",
      "loss None\n",
      "batch time cost: 5.260759115219116\n",
      "Epoch: 0, batch: 4290\n",
      "loss None\n",
      "batch time cost: 5.325780153274536\n",
      "Relu Train Epoch: 0 [274560/318582 (1%)]\tLoss: 0.666289\n",
      "Epoch: 0, batch: 4291\n",
      "loss None\n",
      "batch time cost: 5.325438022613525\n",
      "Epoch: 0, batch: 4292\n",
      "loss None\n",
      "batch time cost: 5.27074408531189\n",
      "Epoch: 0, batch: 4293\n",
      "loss None\n",
      "batch time cost: 5.319001913070679\n",
      "Epoch: 0, batch: 4294\n",
      "loss None\n",
      "batch time cost: 5.628807306289673\n",
      "Epoch: 0, batch: 4295\n",
      "loss None\n",
      "batch time cost: 5.703757047653198\n",
      "Epoch: 0, batch: 4296\n",
      "loss None\n",
      "batch time cost: 5.369829177856445\n",
      "Epoch: 0, batch: 4297\n",
      "loss None\n",
      "batch time cost: 5.244704723358154\n",
      "Epoch: 0, batch: 4298\n",
      "loss None\n",
      "batch time cost: 5.325178146362305\n",
      "Epoch: 0, batch: 4299\n",
      "loss None\n",
      "batch time cost: 5.26520299911499\n",
      "Epoch: 0, batch: 4300\n",
      "loss None\n",
      "batch time cost: 5.252775192260742\n",
      "Relu Train Epoch: 0 [275200/318582 (1%)]\tLoss: 0.828387\n",
      "Epoch: 0, batch: 4301\n",
      "loss None\n",
      "batch time cost: 5.579755067825317\n",
      "Epoch: 0, batch: 4302\n",
      "loss None\n",
      "batch time cost: 5.250173091888428\n",
      "Epoch: 0, batch: 4303\n",
      "loss None\n",
      "batch time cost: 5.229516983032227\n",
      "Epoch: 0, batch: 4304\n",
      "loss None\n",
      "batch time cost: 5.280408143997192\n",
      "Epoch: 0, batch: 4305\n",
      "loss None\n",
      "batch time cost: 5.261596918106079\n",
      "Epoch: 0, batch: 4306\n",
      "loss None\n",
      "batch time cost: 5.6428680419921875\n",
      "Epoch: 0, batch: 4307\n",
      "loss None\n",
      "batch time cost: 5.34018087387085\n",
      "Epoch: 0, batch: 4308\n",
      "loss None\n",
      "batch time cost: 5.274402141571045\n",
      "Epoch: 0, batch: 4309\n",
      "loss None\n",
      "batch time cost: 5.590296030044556\n",
      "Epoch: 0, batch: 4310\n",
      "loss None\n",
      "batch time cost: 5.308511018753052\n",
      "Relu Train Epoch: 0 [275840/318582 (1%)]\tLoss: 0.918201\n",
      "Epoch: 0, batch: 4311\n",
      "loss None\n",
      "batch time cost: 5.2633349895477295\n",
      "Epoch: 0, batch: 4312\n",
      "loss None\n",
      "batch time cost: 5.275670051574707\n",
      "Epoch: 0, batch: 4313\n",
      "loss None\n",
      "batch time cost: 5.289730787277222\n",
      "Epoch: 0, batch: 4314\n",
      "loss None\n",
      "batch time cost: 5.242197036743164\n",
      "Epoch: 0, batch: 4315\n",
      "loss None\n",
      "batch time cost: 5.3108296394348145\n",
      "Epoch: 0, batch: 4316\n",
      "loss None\n",
      "batch time cost: 5.610771894454956\n",
      "Epoch: 0, batch: 4317\n",
      "loss None\n",
      "batch time cost: 5.381873846054077\n",
      "Epoch: 0, batch: 4318\n",
      "loss None\n",
      "batch time cost: 5.276563882827759\n",
      "Epoch: 0, batch: 4319\n",
      "loss None\n",
      "batch time cost: 5.26708197593689\n",
      "Epoch: 0, batch: 4320\n",
      "loss None\n",
      "batch time cost: 5.28636622428894\n",
      "Relu Train Epoch: 0 [276480/318582 (1%)]\tLoss: 0.932983\n",
      "Epoch: 0, batch: 4321\n",
      "loss None\n",
      "batch time cost: 5.34211802482605\n",
      "Epoch: 0, batch: 4322\n",
      "loss None\n",
      "batch time cost: 5.251510858535767\n",
      "Epoch: 0, batch: 4323\n",
      "loss None\n",
      "batch time cost: 5.61153507232666\n",
      "Epoch: 0, batch: 4324\n",
      "loss None\n",
      "batch time cost: 5.256152153015137\n",
      "Epoch: 0, batch: 4325\n",
      "loss None\n",
      "batch time cost: 5.262933015823364\n",
      "Epoch: 0, batch: 4326\n",
      "loss None\n",
      "batch time cost: 5.26779580116272\n",
      "Epoch: 0, batch: 4327\n",
      "loss None\n",
      "batch time cost: 5.270157098770142\n",
      "Epoch: 0, batch: 4328\n",
      "loss None\n",
      "batch time cost: 5.303805112838745\n",
      "Epoch: 0, batch: 4329\n",
      "loss None\n",
      "batch time cost: 5.393941164016724\n",
      "Epoch: 0, batch: 4330\n",
      "loss None\n",
      "batch time cost: 5.60009503364563\n",
      "Relu Train Epoch: 0 [277120/318582 (1%)]\tLoss: 0.804448\n",
      "Epoch: 0, batch: 4331\n",
      "loss None\n",
      "batch time cost: 5.352541923522949\n",
      "Epoch: 0, batch: 4332\n",
      "loss None\n",
      "batch time cost: 5.294855117797852\n",
      "Epoch: 0, batch: 4333\n",
      "loss None\n",
      "batch time cost: 5.289252758026123\n",
      "Epoch: 0, batch: 4334\n",
      "loss None\n",
      "batch time cost: 5.270913124084473\n",
      "Epoch: 0, batch: 4335\n",
      "loss None\n",
      "batch time cost: 5.299077987670898\n",
      "Epoch: 0, batch: 4336\n",
      "loss None\n",
      "batch time cost: 5.329038143157959\n",
      "Epoch: 0, batch: 4337\n",
      "loss None\n",
      "batch time cost: 5.263947010040283\n",
      "Epoch: 0, batch: 4338\n",
      "loss None\n",
      "batch time cost: 5.5850889682769775\n",
      "Epoch: 0, batch: 4339\n",
      "loss None\n",
      "batch time cost: 5.261934757232666\n",
      "Epoch: 0, batch: 4340\n",
      "loss None\n",
      "batch time cost: 5.365966081619263\n",
      "Relu Train Epoch: 0 [277760/318582 (1%)]\tLoss: 0.783723\n",
      "Epoch: 0, batch: 4341\n",
      "loss None\n",
      "batch time cost: 5.315317153930664\n",
      "Epoch: 0, batch: 4342\n",
      "loss None\n",
      "batch time cost: 5.277275085449219\n",
      "Epoch: 0, batch: 4343\n",
      "loss None\n",
      "batch time cost: 5.34344482421875\n",
      "Epoch: 0, batch: 4344\n",
      "loss None\n",
      "batch time cost: 5.281429767608643\n",
      "Epoch: 0, batch: 4345\n",
      "loss None\n",
      "batch time cost: 5.5854105949401855\n",
      "Epoch: 0, batch: 4346\n",
      "loss None\n",
      "batch time cost: 5.258633852005005\n",
      "Epoch: 0, batch: 4347\n",
      "loss None\n",
      "batch time cost: 5.25637412071228\n",
      "Epoch: 0, batch: 4348\n",
      "loss None\n",
      "batch time cost: 5.292541027069092\n",
      "Epoch: 0, batch: 4349\n",
      "loss None\n",
      "batch time cost: 5.299347877502441\n",
      "Epoch: 0, batch: 4350\n",
      "loss None\n",
      "batch time cost: 5.336156845092773\n",
      "Relu Train Epoch: 0 [278400/318582 (1%)]\tLoss: 0.686007\n",
      "Epoch: 0, batch: 4351\n",
      "loss None\n",
      "batch time cost: 5.38386607170105\n",
      "Epoch: 0, batch: 4352\n",
      "loss None\n",
      "batch time cost: 5.593296051025391\n",
      "Epoch: 0, batch: 4353\n",
      "loss None\n",
      "batch time cost: 5.268390893936157\n",
      "Epoch: 0, batch: 4354\n",
      "loss None\n",
      "batch time cost: 5.262450933456421\n",
      "Epoch: 0, batch: 4355\n",
      "loss None\n",
      "batch time cost: 5.349978685379028\n",
      "Epoch: 0, batch: 4356\n",
      "loss None\n",
      "batch time cost: 5.2839720249176025\n",
      "Epoch: 0, batch: 4357\n",
      "loss None\n",
      "batch time cost: 5.266952037811279\n",
      "Epoch: 0, batch: 4358\n",
      "loss None\n",
      "batch time cost: 5.300055027008057\n",
      "Epoch: 0, batch: 4359\n",
      "loss None\n",
      "batch time cost: 5.647323846817017\n",
      "Epoch: 0, batch: 4360\n",
      "loss None\n",
      "batch time cost: 5.25855278968811\n",
      "Relu Train Epoch: 0 [279040/318582 (1%)]\tLoss: 0.685133\n",
      "Epoch: 0, batch: 4361\n",
      "loss None\n",
      "batch time cost: 5.196088075637817\n",
      "Epoch: 0, batch: 4362\n",
      "loss None\n",
      "batch time cost: 6.970326900482178\n",
      "Epoch: 0, batch: 4363\n",
      "loss None\n",
      "batch time cost: 5.919105768203735\n",
      "Epoch: 0, batch: 4364\n",
      "loss None\n",
      "batch time cost: 5.38300895690918\n",
      "Epoch: 0, batch: 4365\n",
      "loss None\n",
      "batch time cost: 5.235881805419922\n",
      "Epoch: 0, batch: 4366\n",
      "loss None\n",
      "batch time cost: 5.8577880859375\n",
      "Epoch: 0, batch: 4367\n",
      "loss None\n",
      "batch time cost: 5.3235368728637695\n",
      "Epoch: 0, batch: 4368\n",
      "loss None\n",
      "batch time cost: 5.2908501625061035\n",
      "Epoch: 0, batch: 4369\n",
      "loss None\n",
      "batch time cost: 5.258587837219238\n",
      "Epoch: 0, batch: 4370\n",
      "loss None\n",
      "batch time cost: 5.295819997787476\n",
      "Relu Train Epoch: 0 [279680/318582 (1%)]\tLoss: 0.757448\n",
      "Epoch: 0, batch: 4371\n",
      "loss None\n",
      "batch time cost: 5.291567087173462\n",
      "Epoch: 0, batch: 4372\n",
      "loss None\n",
      "batch time cost: 5.279900074005127\n",
      "Epoch: 0, batch: 4373\n",
      "loss None\n",
      "batch time cost: 5.439492225646973\n",
      "Epoch: 0, batch: 4374\n",
      "loss None\n",
      "batch time cost: 5.659265995025635\n",
      "Epoch: 0, batch: 4375\n",
      "loss None\n",
      "batch time cost: 5.295346975326538\n",
      "Epoch: 0, batch: 4376\n",
      "loss None\n",
      "batch time cost: 5.286550045013428\n",
      "Epoch: 0, batch: 4377\n",
      "loss None\n",
      "batch time cost: 5.270357847213745\n",
      "Epoch: 0, batch: 4378\n",
      "loss None\n",
      "batch time cost: 5.252496242523193\n",
      "Epoch: 0, batch: 4379\n",
      "loss None\n",
      "batch time cost: 5.283367395401001\n",
      "Epoch: 0, batch: 4380\n",
      "loss None\n",
      "batch time cost: 5.248823881149292\n",
      "Relu Train Epoch: 0 [280320/318582 (1%)]\tLoss: 0.975611\n",
      "Epoch: 0, batch: 4381\n",
      "loss None\n",
      "batch time cost: 5.669152021408081\n",
      "Epoch: 0, batch: 4382\n",
      "loss None\n",
      "batch time cost: 5.268963098526001\n",
      "Epoch: 0, batch: 4383\n",
      "loss None\n",
      "batch time cost: 5.301703929901123\n",
      "Epoch: 0, batch: 4384\n",
      "loss None\n",
      "batch time cost: 5.269776821136475\n",
      "Epoch: 0, batch: 4385\n",
      "loss None\n",
      "batch time cost: 5.248337984085083\n",
      "Epoch: 0, batch: 4386\n",
      "loss None\n",
      "batch time cost: 5.281654119491577\n",
      "Epoch: 0, batch: 4387\n",
      "loss None\n",
      "batch time cost: 5.256838083267212\n",
      "Epoch: 0, batch: 4388\n",
      "loss None\n",
      "batch time cost: 5.583120346069336\n",
      "Epoch: 0, batch: 4389\n",
      "loss None\n",
      "batch time cost: 5.306861162185669\n",
      "Epoch: 0, batch: 4390\n",
      "loss None\n",
      "batch time cost: 5.3132641315460205\n",
      "Relu Train Epoch: 0 [280960/318582 (1%)]\tLoss: 0.666785\n",
      "Epoch: 0, batch: 4391\n",
      "loss None\n",
      "batch time cost: 5.295555830001831\n",
      "Epoch: 0, batch: 4392\n",
      "loss None\n",
      "batch time cost: 5.2477240562438965\n",
      "Epoch: 0, batch: 4393\n",
      "loss None\n",
      "batch time cost: 5.2957518100738525\n",
      "Epoch: 0, batch: 4394\n",
      "loss None\n",
      "batch time cost: 5.325102090835571\n",
      "Epoch: 0, batch: 4395\n",
      "loss None\n",
      "batch time cost: 5.6308979988098145\n",
      "Epoch: 0, batch: 4396\n",
      "loss None\n",
      "batch time cost: 5.2481372356414795\n",
      "Epoch: 0, batch: 4397\n",
      "loss None\n",
      "batch time cost: 5.24438214302063\n",
      "Epoch: 0, batch: 4398\n",
      "loss None\n",
      "batch time cost: 5.370822906494141\n",
      "Epoch: 0, batch: 4399\n",
      "loss None\n",
      "batch time cost: 5.300694942474365\n",
      "Epoch: 0, batch: 4400\n",
      "loss None\n",
      "batch time cost: 5.288182020187378\n",
      "Relu Train Epoch: 0 [281600/318582 (1%)]\tLoss: 0.794332\n",
      "Epoch: 0, batch: 4401\n",
      "loss None\n",
      "batch time cost: 5.289342880249023\n",
      "Epoch: 0, batch: 4402\n",
      "loss None\n",
      "batch time cost: 5.2532689571380615\n",
      "Epoch: 0, batch: 4403\n",
      "loss None\n",
      "batch time cost: 5.551112174987793\n",
      "Epoch: 0, batch: 4404\n",
      "loss None\n",
      "batch time cost: 5.8675267696380615\n",
      "Epoch: 0, batch: 4405\n",
      "loss None\n",
      "batch time cost: 7.607985019683838\n",
      "Epoch: 0, batch: 4406\n",
      "loss None\n",
      "batch time cost: 6.766894102096558\n",
      "Epoch: 0, batch: 4407\n",
      "loss None\n",
      "batch time cost: 5.874948024749756\n",
      "Epoch: 0, batch: 4408\n",
      "loss None\n",
      "batch time cost: 5.322091102600098\n",
      "Epoch: 0, batch: 4409\n",
      "loss None\n",
      "batch time cost: 5.336044073104858\n",
      "Epoch: 0, batch: 4410\n",
      "loss None\n",
      "batch time cost: 5.78251314163208\n",
      "Relu Train Epoch: 0 [282240/318582 (1%)]\tLoss: 0.801331\n",
      "Epoch: 0, batch: 4411\n",
      "loss None\n",
      "batch time cost: 5.316086053848267\n",
      "Epoch: 0, batch: 4412\n",
      "loss None\n",
      "batch time cost: 5.246718883514404\n",
      "Epoch: 0, batch: 4413\n",
      "loss None\n",
      "batch time cost: 5.295806884765625\n",
      "Epoch: 0, batch: 4414\n",
      "loss None\n",
      "batch time cost: 5.2820820808410645\n",
      "Epoch: 0, batch: 4415\n",
      "loss None\n",
      "batch time cost: 5.298676013946533\n",
      "Epoch: 0, batch: 4416\n",
      "loss None\n",
      "batch time cost: 5.437596082687378\n",
      "Epoch: 0, batch: 4417\n",
      "loss None\n",
      "batch time cost: 8.92183518409729\n",
      "Epoch: 0, batch: 4418\n",
      "loss None\n",
      "batch time cost: 7.045703172683716\n",
      "Epoch: 0, batch: 4419\n",
      "loss None\n",
      "batch time cost: 7.753051042556763\n",
      "Epoch: 0, batch: 4420\n",
      "loss None\n",
      "batch time cost: 8.39090085029602\n",
      "Relu Train Epoch: 0 [282880/318582 (1%)]\tLoss: 0.796710\n",
      "Epoch: 0, batch: 4421\n",
      "loss None\n",
      "batch time cost: 5.432898998260498\n",
      "Epoch: 0, batch: 4422\n",
      "loss None\n",
      "batch time cost: 5.302426099777222\n",
      "Epoch: 0, batch: 4423\n",
      "loss None\n",
      "batch time cost: 5.162752866744995\n",
      "Epoch: 0, batch: 4424\n",
      "loss None\n",
      "batch time cost: 5.594888210296631\n",
      "Epoch: 0, batch: 4425\n",
      "loss None\n",
      "batch time cost: 5.253229141235352\n",
      "Epoch: 0, batch: 4426\n",
      "loss None\n",
      "batch time cost: 5.252141714096069\n",
      "Epoch: 0, batch: 4427\n",
      "loss None\n",
      "batch time cost: 5.20386528968811\n",
      "Epoch: 0, batch: 4428\n",
      "loss None\n",
      "batch time cost: 5.313036918640137\n",
      "Epoch: 0, batch: 4429\n",
      "loss None\n",
      "batch time cost: 5.438977003097534\n",
      "Epoch: 0, batch: 4430\n",
      "loss None\n",
      "batch time cost: 5.241546392440796\n",
      "Relu Train Epoch: 0 [283520/318582 (1%)]\tLoss: 0.763324\n",
      "Epoch: 0, batch: 4431\n",
      "loss None\n",
      "batch time cost: 5.490525960922241\n",
      "Epoch: 0, batch: 4432\n",
      "loss None\n",
      "batch time cost: 5.215067148208618\n",
      "Epoch: 0, batch: 4433\n",
      "loss None\n",
      "batch time cost: 5.257250070571899\n",
      "Epoch: 0, batch: 4434\n",
      "loss None\n",
      "batch time cost: 5.225077152252197\n",
      "Epoch: 0, batch: 4435\n",
      "loss None\n",
      "batch time cost: 5.267239093780518\n",
      "Epoch: 0, batch: 4436\n",
      "loss None\n",
      "batch time cost: 5.1989099979400635\n",
      "Epoch: 0, batch: 4437\n",
      "loss None\n",
      "batch time cost: 5.210844039916992\n",
      "Epoch: 0, batch: 4438\n",
      "loss None\n",
      "batch time cost: 5.241763114929199\n",
      "Epoch: 0, batch: 4439\n",
      "loss None\n",
      "batch time cost: 5.522316932678223\n",
      "Epoch: 0, batch: 4440\n",
      "loss None\n",
      "batch time cost: 5.240642070770264\n",
      "Relu Train Epoch: 0 [284160/318582 (1%)]\tLoss: 1.135096\n",
      "Epoch: 0, batch: 4441\n",
      "loss None\n",
      "batch time cost: 5.230036973953247\n",
      "Epoch: 0, batch: 4442\n",
      "loss None\n",
      "batch time cost: 5.232467889785767\n",
      "Epoch: 0, batch: 4443\n",
      "loss None\n",
      "batch time cost: 5.210066318511963\n",
      "Epoch: 0, batch: 4444\n",
      "loss None\n",
      "batch time cost: 5.228827953338623\n",
      "Epoch: 0, batch: 4445\n",
      "loss None\n",
      "batch time cost: 5.2123799324035645\n",
      "Epoch: 0, batch: 4446\n",
      "loss None\n",
      "batch time cost: 5.573758125305176\n",
      "Epoch: 0, batch: 4447\n",
      "loss None\n",
      "batch time cost: 5.236626863479614\n",
      "Epoch: 0, batch: 4448\n",
      "loss None\n",
      "batch time cost: 5.2290589809417725\n",
      "Epoch: 0, batch: 4449\n",
      "loss None\n",
      "batch time cost: 5.256792068481445\n",
      "Epoch: 0, batch: 4450\n",
      "loss None\n",
      "batch time cost: 5.25242805480957\n",
      "Relu Train Epoch: 0 [284800/318582 (1%)]\tLoss: 0.861679\n",
      "Epoch: 0, batch: 4451\n",
      "loss None\n",
      "batch time cost: 5.222106218338013\n",
      "Epoch: 0, batch: 4452\n",
      "loss None\n",
      "batch time cost: 5.237462043762207\n",
      "Epoch: 0, batch: 4453\n",
      "loss None\n",
      "batch time cost: 5.556580066680908\n",
      "Epoch: 0, batch: 4454\n",
      "loss None\n",
      "batch time cost: 5.290786027908325\n",
      "Epoch: 0, batch: 4455\n",
      "loss None\n",
      "batch time cost: 5.206480026245117\n",
      "Epoch: 0, batch: 4456\n",
      "loss None\n",
      "batch time cost: 5.23834490776062\n",
      "Epoch: 0, batch: 4457\n",
      "loss None\n",
      "batch time cost: 5.227299213409424\n",
      "Epoch: 0, batch: 4458\n",
      "loss None\n",
      "batch time cost: 5.19215989112854\n",
      "Epoch: 0, batch: 4459\n",
      "loss None\n",
      "batch time cost: 5.297561883926392\n",
      "Epoch: 0, batch: 4460\n",
      "loss None\n",
      "batch time cost: 5.521440029144287\n",
      "Relu Train Epoch: 0 [285440/318582 (1%)]\tLoss: 0.848718\n",
      "Epoch: 0, batch: 4461\n",
      "loss None\n",
      "batch time cost: 5.201443672180176\n",
      "Epoch: 0, batch: 4462\n",
      "loss None\n",
      "batch time cost: 5.233896970748901\n",
      "Epoch: 0, batch: 4463\n",
      "loss None\n",
      "batch time cost: 5.214706182479858\n",
      "Epoch: 0, batch: 4464\n",
      "loss None\n",
      "batch time cost: 5.264920949935913\n",
      "Epoch: 0, batch: 4465\n",
      "loss None\n",
      "batch time cost: 5.289709806442261\n",
      "Epoch: 0, batch: 4466\n",
      "loss None\n",
      "batch time cost: 5.221161127090454\n",
      "Epoch: 0, batch: 4467\n",
      "loss None\n",
      "batch time cost: 5.240015983581543\n",
      "Epoch: 0, batch: 4468\n",
      "loss None\n",
      "batch time cost: 5.558879375457764\n",
      "Epoch: 0, batch: 4469\n",
      "loss None\n",
      "batch time cost: 5.2641990184783936\n",
      "Epoch: 0, batch: 4470\n",
      "loss None\n",
      "batch time cost: 5.22845983505249\n",
      "Relu Train Epoch: 0 [286080/318582 (1%)]\tLoss: 0.870032\n",
      "Epoch: 0, batch: 4471\n",
      "loss None\n",
      "batch time cost: 5.246182918548584\n",
      "Epoch: 0, batch: 4472\n",
      "loss None\n",
      "batch time cost: 5.20949912071228\n",
      "Epoch: 0, batch: 4473\n",
      "loss None\n",
      "batch time cost: 5.235110759735107\n",
      "Epoch: 0, batch: 4474\n",
      "loss None\n",
      "batch time cost: 5.230784177780151\n",
      "Epoch: 0, batch: 4475\n",
      "loss None\n",
      "batch time cost: 5.633088111877441\n",
      "Epoch: 0, batch: 4476\n",
      "loss None\n",
      "batch time cost: 5.24163818359375\n",
      "Epoch: 0, batch: 4477\n",
      "loss None\n",
      "batch time cost: 5.230118989944458\n",
      "Epoch: 0, batch: 4478\n",
      "loss None\n",
      "batch time cost: 5.286333799362183\n",
      "Epoch: 0, batch: 4479\n",
      "loss None\n",
      "batch time cost: 5.23580527305603\n",
      "Epoch: 0, batch: 4480\n",
      "loss None\n",
      "batch time cost: 5.2187652587890625\n",
      "Relu Train Epoch: 0 [286720/318582 (1%)]\tLoss: 0.968371\n",
      "Epoch: 0, batch: 4481\n",
      "loss None\n",
      "batch time cost: 5.221139192581177\n",
      "Epoch: 0, batch: 4482\n",
      "loss None\n",
      "batch time cost: 5.670815944671631\n",
      "Epoch: 0, batch: 4483\n",
      "loss None\n",
      "batch time cost: 5.294381856918335\n",
      "Epoch: 0, batch: 4484\n",
      "loss None\n",
      "batch time cost: 5.236089706420898\n",
      "Epoch: 0, batch: 4485\n",
      "loss None\n",
      "batch time cost: 5.200307846069336\n",
      "Epoch: 0, batch: 4486\n",
      "loss None\n",
      "batch time cost: 5.195026874542236\n",
      "Epoch: 0, batch: 4487\n",
      "loss None\n",
      "batch time cost: 5.249724864959717\n",
      "Epoch: 0, batch: 4488\n",
      "loss None\n",
      "batch time cost: 5.194819927215576\n",
      "Epoch: 0, batch: 4489\n",
      "loss None\n",
      "batch time cost: 5.592702865600586\n",
      "Epoch: 0, batch: 4490\n",
      "loss None\n",
      "batch time cost: 5.239609241485596\n",
      "Relu Train Epoch: 0 [287360/318582 (1%)]\tLoss: 0.818845\n",
      "Epoch: 0, batch: 4491\n",
      "loss None\n",
      "batch time cost: 5.216475963592529\n",
      "Epoch: 0, batch: 4492\n",
      "loss None\n",
      "batch time cost: 5.205344915390015\n",
      "Epoch: 0, batch: 4493\n",
      "loss None\n",
      "batch time cost: 5.207453966140747\n",
      "Epoch: 0, batch: 4494\n",
      "loss None\n",
      "batch time cost: 5.256850004196167\n",
      "Epoch: 0, batch: 4495\n",
      "loss None\n",
      "batch time cost: 5.239559888839722\n",
      "Epoch: 0, batch: 4496\n",
      "loss None\n",
      "batch time cost: 5.555124044418335\n",
      "Epoch: 0, batch: 4497\n",
      "loss None\n",
      "batch time cost: 5.203981637954712\n",
      "Epoch: 0, batch: 4498\n",
      "loss None\n",
      "batch time cost: 5.2502641677856445\n",
      "Epoch: 0, batch: 4499\n",
      "loss None\n",
      "batch time cost: 5.259736776351929\n",
      "Epoch: 0, batch: 4500\n",
      "loss None\n",
      "batch time cost: 5.208338022232056\n",
      "Relu Train Epoch: 0 [288000/318582 (1%)]\tLoss: 0.729631\n",
      "Epoch: 0, batch: 4501\n",
      "loss None\n",
      "batch time cost: 5.286832809448242\n",
      "Epoch: 0, batch: 4502\n",
      "loss None\n",
      "batch time cost: 5.175916910171509\n",
      "Epoch: 0, batch: 4503\n",
      "loss None\n",
      "batch time cost: 5.237088918685913\n",
      "Epoch: 0, batch: 4504\n",
      "loss None\n",
      "batch time cost: 5.514456033706665\n",
      "Epoch: 0, batch: 4505\n",
      "loss None\n",
      "batch time cost: 5.269855976104736\n",
      "Epoch: 0, batch: 4506\n",
      "loss None\n",
      "batch time cost: 5.245591640472412\n",
      "Epoch: 0, batch: 4507\n",
      "loss None\n",
      "batch time cost: 5.2288360595703125\n",
      "Epoch: 0, batch: 4508\n",
      "loss None\n",
      "batch time cost: 5.223597764968872\n",
      "Epoch: 0, batch: 4509\n",
      "loss None\n",
      "batch time cost: 5.260056018829346\n",
      "Epoch: 0, batch: 4510\n",
      "loss None\n",
      "batch time cost: 5.205461025238037\n",
      "Relu Train Epoch: 0 [288640/318582 (1%)]\tLoss: 1.059077\n",
      "Epoch: 0, batch: 4511\n",
      "loss None\n",
      "batch time cost: 5.52004599571228\n",
      "Epoch: 0, batch: 4512\n",
      "loss None\n",
      "batch time cost: 5.2936131954193115\n",
      "Epoch: 0, batch: 4513\n",
      "loss None\n",
      "batch time cost: 5.227984189987183\n",
      "Epoch: 0, batch: 4514\n",
      "loss None\n",
      "batch time cost: 5.261461973190308\n",
      "Epoch: 0, batch: 4515\n",
      "loss None\n",
      "batch time cost: 5.237609148025513\n",
      "Epoch: 0, batch: 4516\n",
      "loss None\n",
      "batch time cost: 5.201317071914673\n",
      "Epoch: 0, batch: 4517\n",
      "loss None\n",
      "batch time cost: 5.249680995941162\n",
      "Epoch: 0, batch: 4518\n",
      "loss None\n",
      "batch time cost: 5.535672903060913\n",
      "Epoch: 0, batch: 4519\n",
      "loss None\n",
      "batch time cost: 5.2815821170806885\n",
      "Epoch: 0, batch: 4520\n",
      "loss None\n",
      "batch time cost: 5.290255069732666\n",
      "Relu Train Epoch: 0 [289280/318582 (1%)]\tLoss: 0.792476\n",
      "Epoch: 0, batch: 4521\n",
      "loss None\n",
      "batch time cost: 5.2963950634002686\n",
      "Epoch: 0, batch: 4522\n",
      "loss None\n",
      "batch time cost: 5.294834852218628\n",
      "Epoch: 0, batch: 4523\n",
      "loss None\n",
      "batch time cost: 5.229387998580933\n",
      "Epoch: 0, batch: 4524\n",
      "loss None\n",
      "batch time cost: 5.307369947433472\n",
      "Epoch: 0, batch: 4525\n",
      "loss None\n",
      "batch time cost: 5.561930894851685\n",
      "Epoch: 0, batch: 4526\n",
      "loss None\n",
      "batch time cost: 5.239985942840576\n",
      "Epoch: 0, batch: 4527\n",
      "loss None\n",
      "batch time cost: 5.262248277664185\n",
      "Epoch: 0, batch: 4528\n",
      "loss None\n",
      "batch time cost: 5.2514588832855225\n",
      "Epoch: 0, batch: 4529\n",
      "loss None\n",
      "batch time cost: 5.2285850048065186\n",
      "Epoch: 0, batch: 4530\n",
      "loss None\n",
      "batch time cost: 5.264714002609253\n",
      "Relu Train Epoch: 0 [289920/318582 (1%)]\tLoss: 0.637483\n",
      "Epoch: 0, batch: 4531\n",
      "loss None\n",
      "batch time cost: 5.209040880203247\n",
      "Epoch: 0, batch: 4532\n",
      "loss None\n",
      "batch time cost: 5.224479913711548\n",
      "Epoch: 0, batch: 4533\n",
      "loss None\n",
      "batch time cost: 5.628445863723755\n",
      "Epoch: 0, batch: 4534\n",
      "loss None\n",
      "batch time cost: 5.295718193054199\n",
      "Epoch: 0, batch: 4535\n",
      "loss None\n",
      "batch time cost: 5.364688873291016\n",
      "Epoch: 0, batch: 4536\n",
      "loss None\n",
      "batch time cost: 5.230372190475464\n",
      "Epoch: 0, batch: 4537\n",
      "loss None\n",
      "batch time cost: 5.282895088195801\n",
      "Epoch: 0, batch: 4538\n",
      "loss None\n",
      "batch time cost: 5.223557710647583\n",
      "Epoch: 0, batch: 4539\n",
      "loss None\n",
      "batch time cost: 5.246800184249878\n",
      "Epoch: 0, batch: 4540\n",
      "loss None\n",
      "batch time cost: 5.518646955490112\n",
      "Relu Train Epoch: 0 [290560/318582 (1%)]\tLoss: 0.650583\n",
      "Epoch: 0, batch: 4541\n",
      "loss None\n",
      "batch time cost: 5.255346775054932\n",
      "Epoch: 0, batch: 4542\n",
      "loss None\n",
      "batch time cost: 5.221727132797241\n",
      "Epoch: 0, batch: 4543\n",
      "loss None\n",
      "batch time cost: 5.231302976608276\n",
      "Epoch: 0, batch: 4544\n",
      "loss None\n",
      "batch time cost: 5.281706809997559\n",
      "Epoch: 0, batch: 4545\n",
      "loss None\n",
      "batch time cost: 5.266195058822632\n",
      "Epoch: 0, batch: 4546\n",
      "loss None\n",
      "batch time cost: 5.184314012527466\n",
      "Epoch: 0, batch: 4547\n",
      "loss None\n",
      "batch time cost: 5.549673080444336\n",
      "Epoch: 0, batch: 4548\n",
      "loss None\n",
      "batch time cost: 5.298137903213501\n",
      "Epoch: 0, batch: 4549\n",
      "loss None\n",
      "batch time cost: 5.1987810134887695\n",
      "Epoch: 0, batch: 4550\n",
      "loss None\n",
      "batch time cost: 5.2533557415008545\n",
      "Relu Train Epoch: 0 [291200/318582 (1%)]\tLoss: 0.807940\n",
      "Epoch: 0, batch: 4551\n",
      "loss None\n",
      "batch time cost: 5.231878757476807\n",
      "Epoch: 0, batch: 4552\n",
      "loss None\n",
      "batch time cost: 5.209356069564819\n",
      "Epoch: 0, batch: 4553\n",
      "loss None\n",
      "batch time cost: 5.253835916519165\n",
      "Epoch: 0, batch: 4554\n",
      "loss None\n",
      "batch time cost: 5.625746250152588\n",
      "Epoch: 0, batch: 4555\n",
      "loss None\n",
      "batch time cost: 5.203258752822876\n",
      "Epoch: 0, batch: 4556\n",
      "loss None\n",
      "batch time cost: 5.232184886932373\n",
      "Epoch: 0, batch: 4557\n",
      "loss None\n",
      "batch time cost: 5.295217990875244\n",
      "Epoch: 0, batch: 4558\n",
      "loss None\n",
      "batch time cost: 5.256180763244629\n",
      "Epoch: 0, batch: 4559\n",
      "loss None\n",
      "batch time cost: 5.187534809112549\n",
      "Epoch: 0, batch: 4560\n",
      "loss None\n",
      "batch time cost: 5.270664930343628\n",
      "Relu Train Epoch: 0 [291840/318582 (1%)]\tLoss: 0.683532\n",
      "Epoch: 0, batch: 4561\n",
      "loss None\n",
      "batch time cost: 5.586444139480591\n",
      "Epoch: 0, batch: 4562\n",
      "loss None\n",
      "batch time cost: 5.20936393737793\n",
      "Epoch: 0, batch: 4563\n",
      "loss None\n",
      "batch time cost: 5.219141721725464\n",
      "Epoch: 0, batch: 4564\n",
      "loss None\n",
      "batch time cost: 5.197534799575806\n",
      "Epoch: 0, batch: 4565\n",
      "loss None\n",
      "batch time cost: 5.250095844268799\n",
      "Epoch: 0, batch: 4566\n",
      "loss None\n",
      "batch time cost: 5.221562147140503\n",
      "Epoch: 0, batch: 4567\n",
      "loss None\n",
      "batch time cost: 5.25237512588501\n",
      "Epoch: 0, batch: 4568\n",
      "loss None\n",
      "batch time cost: 5.221159934997559\n",
      "Epoch: 0, batch: 4569\n",
      "loss None\n",
      "batch time cost: 5.5749452114105225\n",
      "Epoch: 0, batch: 4570\n",
      "loss None\n",
      "batch time cost: 5.257238149642944\n",
      "Relu Train Epoch: 0 [292480/318582 (1%)]\tLoss: 0.660138\n",
      "Epoch: 0, batch: 4571\n",
      "loss None\n",
      "batch time cost: 5.232085943222046\n",
      "Epoch: 0, batch: 4572\n",
      "loss None\n",
      "batch time cost: 5.23393988609314\n",
      "Epoch: 0, batch: 4573\n",
      "loss None\n",
      "batch time cost: 5.256657838821411\n",
      "Epoch: 0, batch: 4574\n",
      "loss None\n",
      "batch time cost: 5.269196033477783\n",
      "Epoch: 0, batch: 4575\n",
      "loss None\n",
      "batch time cost: 5.267457008361816\n",
      "Epoch: 0, batch: 4576\n",
      "loss None\n",
      "batch time cost: 5.519850969314575\n",
      "Epoch: 0, batch: 4577\n",
      "loss None\n",
      "batch time cost: 5.183252811431885\n",
      "Epoch: 0, batch: 4578\n",
      "loss None\n",
      "batch time cost: 5.324656248092651\n",
      "Epoch: 0, batch: 4579\n",
      "loss None\n",
      "batch time cost: 5.232066869735718\n",
      "Epoch: 0, batch: 4580\n",
      "loss None\n",
      "batch time cost: 5.2421181201934814\n",
      "Relu Train Epoch: 0 [293120/318582 (1%)]\tLoss: 0.925259\n",
      "Epoch: 0, batch: 4581\n",
      "loss None\n",
      "batch time cost: 5.210804224014282\n",
      "Epoch: 0, batch: 4582\n",
      "loss None\n",
      "batch time cost: 5.199326038360596\n",
      "Epoch: 0, batch: 4583\n",
      "loss None\n",
      "batch time cost: 5.546657085418701\n",
      "Epoch: 0, batch: 4584\n",
      "loss None\n",
      "batch time cost: 5.236799001693726\n",
      "Epoch: 0, batch: 4585\n",
      "loss None\n",
      "batch time cost: 5.274715900421143\n",
      "Epoch: 0, batch: 4586\n",
      "loss None\n",
      "batch time cost: 5.281332969665527\n",
      "Epoch: 0, batch: 4587\n",
      "loss None\n",
      "batch time cost: 5.2383739948272705\n",
      "Epoch: 0, batch: 4588\n",
      "loss None\n",
      "batch time cost: 5.241003036499023\n",
      "Epoch: 0, batch: 4589\n",
      "loss None\n",
      "batch time cost: 5.240278005599976\n",
      "Epoch: 0, batch: 4590\n",
      "loss None\n",
      "batch time cost: 5.574882984161377\n",
      "Relu Train Epoch: 0 [293760/318582 (1%)]\tLoss: 0.746768\n",
      "Epoch: 0, batch: 4591\n",
      "loss None\n",
      "batch time cost: 5.286803960800171\n",
      "Epoch: 0, batch: 4592\n",
      "loss None\n",
      "batch time cost: 5.310163974761963\n",
      "Epoch: 0, batch: 4593\n",
      "loss None\n",
      "batch time cost: 5.311546087265015\n",
      "Epoch: 0, batch: 4594\n",
      "loss None\n",
      "batch time cost: 5.212787866592407\n",
      "Epoch: 0, batch: 4595\n",
      "loss None\n",
      "batch time cost: 5.23323917388916\n",
      "Epoch: 0, batch: 4596\n",
      "loss None\n",
      "batch time cost: 5.208112001419067\n",
      "Epoch: 0, batch: 4597\n",
      "loss None\n",
      "batch time cost: 5.255835294723511\n",
      "Epoch: 0, batch: 4598\n",
      "loss None\n",
      "batch time cost: 5.550262689590454\n",
      "Epoch: 0, batch: 4599\n",
      "loss None\n",
      "batch time cost: 5.259571075439453\n",
      "Epoch: 0, batch: 4600\n",
      "loss None\n",
      "batch time cost: 5.281084775924683\n",
      "Relu Train Epoch: 0 [294400/318582 (1%)]\tLoss: 0.690873\n",
      "Epoch: 0, batch: 4601\n",
      "loss None\n",
      "batch time cost: 5.293673992156982\n",
      "Epoch: 0, batch: 4602\n",
      "loss None\n",
      "batch time cost: 5.2013161182403564\n",
      "Epoch: 0, batch: 4603\n",
      "loss None\n",
      "batch time cost: 5.235454082489014\n",
      "Epoch: 0, batch: 4604\n",
      "loss None\n",
      "batch time cost: 5.253556251525879\n",
      "Epoch: 0, batch: 4605\n",
      "loss None\n",
      "batch time cost: 5.56134295463562\n",
      "Epoch: 0, batch: 4606\n",
      "loss None\n",
      "batch time cost: 5.341789960861206\n",
      "Epoch: 0, batch: 4607\n",
      "loss None\n",
      "batch time cost: 5.262009143829346\n",
      "Epoch: 0, batch: 4608\n",
      "loss None\n",
      "batch time cost: 5.232474088668823\n",
      "Epoch: 0, batch: 4609\n",
      "loss None\n",
      "batch time cost: 5.294722080230713\n",
      "Epoch: 0, batch: 4610\n",
      "loss None\n",
      "batch time cost: 5.2662482261657715\n",
      "Relu Train Epoch: 0 [295040/318582 (1%)]\tLoss: 0.800796\n",
      "Epoch: 0, batch: 4611\n",
      "loss None\n",
      "batch time cost: 5.258934020996094\n",
      "Epoch: 0, batch: 4612\n",
      "loss None\n",
      "batch time cost: 5.600572109222412\n",
      "Epoch: 0, batch: 4613\n",
      "loss None\n",
      "batch time cost: 5.2831711769104\n",
      "Epoch: 0, batch: 4614\n",
      "loss None\n",
      "batch time cost: 5.252825021743774\n",
      "Epoch: 0, batch: 4615\n",
      "loss None\n",
      "batch time cost: 5.240346908569336\n",
      "Epoch: 0, batch: 4616\n",
      "loss None\n",
      "batch time cost: 5.265342950820923\n",
      "Epoch: 0, batch: 4617\n",
      "loss None\n",
      "batch time cost: 5.2558839321136475\n",
      "Epoch: 0, batch: 4618\n",
      "loss None\n",
      "batch time cost: 5.232481956481934\n",
      "Epoch: 0, batch: 4619\n",
      "loss None\n",
      "batch time cost: 5.547580718994141\n",
      "Epoch: 0, batch: 4620\n",
      "loss None\n",
      "batch time cost: 5.263304948806763\n",
      "Relu Train Epoch: 0 [295680/318582 (1%)]\tLoss: 0.937952\n",
      "Epoch: 0, batch: 4621\n",
      "loss None\n",
      "batch time cost: 5.239195108413696\n",
      "Epoch: 0, batch: 4622\n",
      "loss None\n",
      "batch time cost: 5.229223966598511\n",
      "Epoch: 0, batch: 4623\n",
      "loss None\n",
      "batch time cost: 5.256188869476318\n",
      "Epoch: 0, batch: 4624\n",
      "loss None\n",
      "batch time cost: 5.19750714302063\n",
      "Epoch: 0, batch: 4625\n",
      "loss None\n",
      "batch time cost: 5.230670928955078\n",
      "Epoch: 0, batch: 4626\n",
      "loss None\n",
      "batch time cost: 5.557215929031372\n",
      "Epoch: 0, batch: 4627\n",
      "loss None\n",
      "batch time cost: 5.24588680267334\n",
      "Epoch: 0, batch: 4628\n",
      "loss None\n",
      "batch time cost: 5.140597105026245\n",
      "Epoch: 0, batch: 4629\n",
      "loss None\n",
      "batch time cost: 5.244932174682617\n",
      "Epoch: 0, batch: 4630\n",
      "loss None\n",
      "batch time cost: 5.247060060501099\n",
      "Relu Train Epoch: 0 [296320/318582 (1%)]\tLoss: 0.736004\n",
      "Epoch: 0, batch: 4631\n",
      "loss None\n",
      "batch time cost: 5.24369215965271\n",
      "Epoch: 0, batch: 4632\n",
      "loss None\n",
      "batch time cost: 5.247591018676758\n",
      "Epoch: 0, batch: 4633\n",
      "loss None\n",
      "batch time cost: 5.266735076904297\n",
      "Epoch: 0, batch: 4634\n",
      "loss None\n",
      "batch time cost: 5.512959003448486\n",
      "Epoch: 0, batch: 4635\n",
      "loss None\n",
      "batch time cost: 5.248214960098267\n",
      "Epoch: 0, batch: 4636\n",
      "loss None\n",
      "batch time cost: 5.284947872161865\n",
      "Epoch: 0, batch: 4637\n",
      "loss None\n",
      "batch time cost: 5.237811088562012\n",
      "Epoch: 0, batch: 4638\n",
      "loss None\n",
      "batch time cost: 5.231784343719482\n",
      "Epoch: 0, batch: 4639\n",
      "loss None\n",
      "batch time cost: 5.325411081314087\n",
      "Epoch: 0, batch: 4640\n",
      "loss None\n",
      "batch time cost: 5.251636028289795\n",
      "Relu Train Epoch: 0 [296960/318582 (1%)]\tLoss: 0.978962\n",
      "Epoch: 0, batch: 4641\n",
      "loss None\n",
      "batch time cost: 5.542684316635132\n",
      "Epoch: 0, batch: 4642\n",
      "loss None\n",
      "batch time cost: 5.239727020263672\n",
      "Epoch: 0, batch: 4643\n",
      "loss None\n",
      "batch time cost: 5.252124071121216\n",
      "Epoch: 0, batch: 4644\n",
      "loss None\n",
      "batch time cost: 5.276089906692505\n",
      "Epoch: 0, batch: 4645\n",
      "loss None\n",
      "batch time cost: 5.250481843948364\n",
      "Epoch: 0, batch: 4646\n",
      "loss None\n",
      "batch time cost: 5.268766164779663\n",
      "Epoch: 0, batch: 4647\n",
      "loss None\n",
      "batch time cost: 5.288833141326904\n",
      "Epoch: 0, batch: 4648\n",
      "loss None\n",
      "batch time cost: 5.559261083602905\n",
      "Epoch: 0, batch: 4649\n",
      "loss None\n",
      "batch time cost: 5.268525123596191\n",
      "Epoch: 0, batch: 4650\n",
      "loss None\n",
      "batch time cost: 5.2909181118011475\n",
      "Relu Train Epoch: 0 [297600/318582 (1%)]\tLoss: 0.955095\n",
      "Epoch: 0, batch: 4651\n",
      "loss None\n",
      "batch time cost: 5.230164051055908\n",
      "Epoch: 0, batch: 4652\n",
      "loss None\n",
      "batch time cost: 5.262923002243042\n",
      "Epoch: 0, batch: 4653\n",
      "loss None\n",
      "batch time cost: 5.2157721519470215\n",
      "Epoch: 0, batch: 4654\n",
      "loss None\n",
      "batch time cost: 5.254095792770386\n",
      "Epoch: 0, batch: 4655\n",
      "loss None\n",
      "batch time cost: 5.589615821838379\n",
      "Epoch: 0, batch: 4656\n",
      "loss None\n",
      "batch time cost: 5.258151054382324\n",
      "Epoch: 0, batch: 4657\n",
      "loss None\n",
      "batch time cost: 8.632850885391235\n",
      "Epoch: 0, batch: 4658\n",
      "loss None\n",
      "batch time cost: 5.3478920459747314\n",
      "Epoch: 0, batch: 4659\n",
      "loss None\n",
      "batch time cost: 5.261493921279907\n",
      "Epoch: 0, batch: 4660\n",
      "loss None\n",
      "batch time cost: 5.282235145568848\n",
      "Relu Train Epoch: 0 [298240/318582 (1%)]\tLoss: 0.752114\n",
      "Epoch: 0, batch: 4661\n",
      "loss None\n",
      "batch time cost: 5.27276873588562\n",
      "Epoch: 0, batch: 4662\n",
      "loss None\n",
      "batch time cost: 5.295823097229004\n",
      "Epoch: 0, batch: 4663\n",
      "loss None\n",
      "batch time cost: 6.1490702629089355\n",
      "Epoch: 0, batch: 4664\n",
      "loss None\n",
      "batch time cost: 6.07889199256897\n",
      "Epoch: 0, batch: 4665\n",
      "loss None\n",
      "batch time cost: 5.9802937507629395\n",
      "Epoch: 0, batch: 4666\n",
      "loss None\n",
      "batch time cost: 5.602644205093384\n",
      "Epoch: 0, batch: 4667\n",
      "loss None\n",
      "batch time cost: 5.337269067764282\n",
      "Epoch: 0, batch: 4668\n",
      "loss None\n",
      "batch time cost: 5.346379041671753\n",
      "Epoch: 0, batch: 4669\n",
      "loss None\n",
      "batch time cost: 5.278891086578369\n",
      "Epoch: 0, batch: 4670\n",
      "loss None\n",
      "batch time cost: 5.626551151275635\n",
      "Relu Train Epoch: 0 [298880/318582 (1%)]\tLoss: 0.989849\n",
      "Epoch: 0, batch: 4671\n",
      "loss None\n",
      "batch time cost: 5.309719085693359\n",
      "Epoch: 0, batch: 4672\n",
      "loss None\n",
      "batch time cost: 5.2822041511535645\n",
      "Epoch: 0, batch: 4673\n",
      "loss None\n",
      "batch time cost: 5.316053152084351\n",
      "Epoch: 0, batch: 4674\n",
      "loss None\n",
      "batch time cost: 5.3325278759002686\n",
      "Epoch: 0, batch: 4675\n",
      "loss None\n",
      "batch time cost: 5.2425007820129395\n",
      "Epoch: 0, batch: 4676\n",
      "loss None\n",
      "batch time cost: 5.221422910690308\n",
      "Epoch: 0, batch: 4677\n",
      "loss None\n",
      "batch time cost: 5.584027051925659\n",
      "Epoch: 0, batch: 4678\n",
      "loss None\n",
      "batch time cost: 5.2863380908966064\n",
      "Epoch: 0, batch: 4679\n",
      "loss None\n",
      "batch time cost: 5.259958982467651\n",
      "Epoch: 0, batch: 4680\n",
      "loss None\n",
      "batch time cost: 5.265427112579346\n",
      "Relu Train Epoch: 0 [299520/318582 (1%)]\tLoss: 0.872524\n",
      "Epoch: 0, batch: 4681\n",
      "loss None\n",
      "batch time cost: 5.2971861362457275\n",
      "Epoch: 0, batch: 4682\n",
      "loss None\n",
      "batch time cost: 5.289044141769409\n",
      "Epoch: 0, batch: 4683\n",
      "loss None\n",
      "batch time cost: 5.250871896743774\n",
      "Epoch: 0, batch: 4684\n",
      "loss None\n",
      "batch time cost: 5.571591854095459\n",
      "Epoch: 0, batch: 4685\n",
      "loss None\n",
      "batch time cost: 5.239480972290039\n",
      "Epoch: 0, batch: 4686\n",
      "loss None\n",
      "batch time cost: 5.30787992477417\n",
      "Epoch: 0, batch: 4687\n",
      "loss None\n",
      "batch time cost: 5.27587103843689\n",
      "Epoch: 0, batch: 4688\n",
      "loss None\n",
      "batch time cost: 5.257678270339966\n",
      "Epoch: 0, batch: 4689\n",
      "loss None\n",
      "batch time cost: 5.271227121353149\n",
      "Epoch: 0, batch: 4690\n",
      "loss None\n",
      "batch time cost: 5.2942140102386475\n",
      "Relu Train Epoch: 0 [300160/318582 (1%)]\tLoss: 0.943687\n",
      "Epoch: 0, batch: 4691\n",
      "loss None\n",
      "batch time cost: 5.739305019378662\n",
      "Epoch: 0, batch: 4692\n",
      "loss None\n",
      "batch time cost: 5.277936935424805\n",
      "Epoch: 0, batch: 4693\n",
      "loss None\n",
      "batch time cost: 5.257503986358643\n",
      "Epoch: 0, batch: 4694\n",
      "loss None\n",
      "batch time cost: 5.293781995773315\n",
      "Epoch: 0, batch: 4695\n",
      "loss None\n",
      "batch time cost: 5.348718881607056\n",
      "Epoch: 0, batch: 4696\n",
      "loss None\n",
      "batch time cost: 5.345139026641846\n",
      "Epoch: 0, batch: 4697\n",
      "loss None\n",
      "batch time cost: 5.233470916748047\n",
      "Epoch: 0, batch: 4698\n",
      "loss None\n",
      "batch time cost: 5.273516893386841\n",
      "Epoch: 0, batch: 4699\n",
      "loss None\n",
      "batch time cost: 5.64480996131897\n",
      "Epoch: 0, batch: 4700\n",
      "loss None\n",
      "batch time cost: 5.3177220821380615\n",
      "Relu Train Epoch: 0 [300800/318582 (1%)]\tLoss: 0.741277\n",
      "Epoch: 0, batch: 4701\n",
      "loss None\n",
      "batch time cost: 5.287733554840088\n",
      "Epoch: 0, batch: 4702\n",
      "loss None\n",
      "batch time cost: 5.290143013000488\n",
      "Epoch: 0, batch: 4703\n",
      "loss None\n",
      "batch time cost: 5.307886123657227\n",
      "Epoch: 0, batch: 4704\n",
      "loss None\n",
      "batch time cost: 5.445349216461182\n",
      "Epoch: 0, batch: 4705\n",
      "loss None\n",
      "batch time cost: 5.298692941665649\n",
      "Epoch: 0, batch: 4706\n",
      "loss None\n",
      "batch time cost: 5.643409967422485\n",
      "Epoch: 0, batch: 4707\n",
      "loss None\n",
      "batch time cost: 5.334938049316406\n",
      "Epoch: 0, batch: 4708\n",
      "loss None\n",
      "batch time cost: 5.380120038986206\n",
      "Epoch: 0, batch: 4709\n",
      "loss None\n",
      "batch time cost: 5.301076173782349\n",
      "Epoch: 0, batch: 4710\n",
      "loss None\n",
      "batch time cost: 5.335708856582642\n",
      "Relu Train Epoch: 0 [301440/318582 (1%)]\tLoss: 0.824225\n",
      "Epoch: 0, batch: 4711\n",
      "loss None\n",
      "batch time cost: 5.291071891784668\n",
      "Epoch: 0, batch: 4712\n",
      "loss None\n",
      "batch time cost: 5.3084259033203125\n",
      "Epoch: 0, batch: 4713\n",
      "loss None\n",
      "batch time cost: 5.634522914886475\n",
      "Epoch: 0, batch: 4714\n",
      "loss None\n",
      "batch time cost: 5.220614910125732\n",
      "Epoch: 0, batch: 4715\n",
      "loss None\n",
      "batch time cost: 5.332035779953003\n",
      "Epoch: 0, batch: 4716\n",
      "loss None\n",
      "batch time cost: 5.318295001983643\n",
      "Epoch: 0, batch: 4717\n",
      "loss None\n",
      "batch time cost: 5.289916753768921\n",
      "Epoch: 0, batch: 4718\n",
      "loss None\n",
      "batch time cost: 5.317072153091431\n",
      "Epoch: 0, batch: 4719\n",
      "loss None\n",
      "batch time cost: 5.287362098693848\n",
      "Epoch: 0, batch: 4720\n",
      "loss None\n",
      "batch time cost: 5.550518035888672\n",
      "Relu Train Epoch: 0 [302080/318582 (1%)]\tLoss: 0.935053\n",
      "Epoch: 0, batch: 4721\n",
      "loss None\n",
      "batch time cost: 5.2398340702056885\n",
      "Epoch: 0, batch: 4722\n",
      "loss None\n",
      "batch time cost: 5.289685964584351\n",
      "Epoch: 0, batch: 4723\n",
      "loss None\n",
      "batch time cost: 5.270318984985352\n",
      "Epoch: 0, batch: 4724\n",
      "loss None\n",
      "batch time cost: 5.284070253372192\n",
      "Epoch: 0, batch: 4725\n",
      "loss None\n",
      "batch time cost: 5.283214807510376\n",
      "Epoch: 0, batch: 4726\n",
      "loss None\n",
      "batch time cost: 5.2847840785980225\n",
      "Epoch: 0, batch: 4727\n",
      "loss None\n",
      "batch time cost: 5.257807016372681\n",
      "Epoch: 0, batch: 4728\n",
      "loss None\n",
      "batch time cost: 5.568760871887207\n",
      "Epoch: 0, batch: 4729\n",
      "loss None\n",
      "batch time cost: 5.3180999755859375\n",
      "Epoch: 0, batch: 4730\n",
      "loss None\n",
      "batch time cost: 5.277850866317749\n",
      "Relu Train Epoch: 0 [302720/318582 (1%)]\tLoss: 0.810067\n",
      "Epoch: 0, batch: 4731\n",
      "loss None\n",
      "batch time cost: 5.314668893814087\n",
      "Epoch: 0, batch: 4732\n",
      "loss None\n",
      "batch time cost: 5.283102989196777\n",
      "Epoch: 0, batch: 4733\n",
      "loss None\n",
      "batch time cost: 5.255393028259277\n",
      "Epoch: 0, batch: 4734\n",
      "loss None\n",
      "batch time cost: 5.271016836166382\n",
      "Epoch: 0, batch: 4735\n",
      "loss None\n",
      "batch time cost: 5.635769844055176\n",
      "Epoch: 0, batch: 4736\n",
      "loss None\n",
      "batch time cost: 5.265172958374023\n",
      "Epoch: 0, batch: 4737\n",
      "loss None\n",
      "batch time cost: 5.254482746124268\n",
      "Epoch: 0, batch: 4738\n",
      "loss None\n",
      "batch time cost: 5.263604164123535\n",
      "Epoch: 0, batch: 4739\n",
      "loss None\n",
      "batch time cost: 5.245957136154175\n",
      "Epoch: 0, batch: 4740\n",
      "loss None\n",
      "batch time cost: 5.318433046340942\n",
      "Relu Train Epoch: 0 [303360/318582 (1%)]\tLoss: 0.885821\n",
      "Epoch: 0, batch: 4741\n",
      "loss None\n",
      "batch time cost: 5.264455318450928\n",
      "Epoch: 0, batch: 4742\n",
      "loss None\n",
      "batch time cost: 5.712568998336792\n",
      "Epoch: 0, batch: 4743\n",
      "loss None\n",
      "batch time cost: 5.323407173156738\n",
      "Epoch: 0, batch: 4744\n",
      "loss None\n",
      "batch time cost: 5.285362005233765\n",
      "Epoch: 0, batch: 4745\n",
      "loss None\n",
      "batch time cost: 5.24547004699707\n",
      "Epoch: 0, batch: 4746\n",
      "loss None\n",
      "batch time cost: 5.255409002304077\n",
      "Epoch: 0, batch: 4747\n",
      "loss None\n",
      "batch time cost: 5.311034917831421\n",
      "Epoch: 0, batch: 4748\n",
      "loss None\n",
      "batch time cost: 5.245126962661743\n",
      "Epoch: 0, batch: 4749\n",
      "loss None\n",
      "batch time cost: 7.075887680053711\n",
      "Epoch: 0, batch: 4750\n",
      "loss None\n",
      "batch time cost: 5.4374940395355225\n",
      "Relu Train Epoch: 0 [304000/318582 (1%)]\tLoss: 0.672977\n",
      "Epoch: 0, batch: 4751\n",
      "loss None\n",
      "batch time cost: 5.27994704246521\n",
      "Epoch: 0, batch: 4752\n",
      "loss None\n",
      "batch time cost: 5.260339975357056\n",
      "Epoch: 0, batch: 4753\n",
      "loss None\n",
      "batch time cost: 5.476078033447266\n",
      "Epoch: 0, batch: 4754\n",
      "loss None\n",
      "batch time cost: 5.273938179016113\n",
      "Epoch: 0, batch: 4755\n",
      "loss None\n",
      "batch time cost: 5.295661211013794\n",
      "Epoch: 0, batch: 4756\n",
      "loss None\n",
      "batch time cost: 5.590420246124268\n",
      "Epoch: 0, batch: 4757\n",
      "loss None\n",
      "batch time cost: 5.319031000137329\n",
      "Epoch: 0, batch: 4758\n",
      "loss None\n",
      "batch time cost: 5.243470191955566\n",
      "Epoch: 0, batch: 4759\n",
      "loss None\n",
      "batch time cost: 5.275038957595825\n",
      "Epoch: 0, batch: 4760\n",
      "loss None\n",
      "batch time cost: 5.306771993637085\n",
      "Relu Train Epoch: 0 [304640/318582 (1%)]\tLoss: 0.814169\n",
      "Epoch: 0, batch: 4761\n",
      "loss None\n",
      "batch time cost: 5.194400072097778\n",
      "Epoch: 0, batch: 4762\n",
      "loss None\n",
      "batch time cost: 5.2018821239471436\n",
      "Epoch: 0, batch: 4763\n",
      "loss None\n",
      "batch time cost: 5.2797510623931885\n",
      "Epoch: 0, batch: 4764\n",
      "loss None\n",
      "batch time cost: 5.712109088897705\n",
      "Epoch: 0, batch: 4765\n",
      "loss None\n",
      "batch time cost: 5.198452949523926\n",
      "Epoch: 0, batch: 4766\n",
      "loss None\n",
      "batch time cost: 5.228545904159546\n",
      "Epoch: 0, batch: 4767\n",
      "loss None\n",
      "batch time cost: 5.253063917160034\n",
      "Epoch: 0, batch: 4768\n",
      "loss None\n",
      "batch time cost: 5.342162847518921\n",
      "Epoch: 0, batch: 4769\n",
      "loss None\n",
      "batch time cost: 5.232905149459839\n",
      "Epoch: 0, batch: 4770\n",
      "loss None\n",
      "batch time cost: 5.268378257751465\n",
      "Relu Train Epoch: 0 [305280/318582 (1%)]\tLoss: 0.890861\n",
      "Epoch: 0, batch: 4771\n",
      "loss None\n",
      "batch time cost: 5.618457078933716\n",
      "Epoch: 0, batch: 4772\n",
      "loss None\n",
      "batch time cost: 5.276993989944458\n",
      "Epoch: 0, batch: 4773\n",
      "loss None\n",
      "batch time cost: 5.250478982925415\n",
      "Epoch: 0, batch: 4774\n",
      "loss None\n",
      "batch time cost: 5.269790887832642\n",
      "Epoch: 0, batch: 4775\n",
      "loss None\n",
      "batch time cost: 5.986356973648071\n",
      "Epoch: 0, batch: 4776\n",
      "loss None\n",
      "batch time cost: 5.355277061462402\n",
      "Epoch: 0, batch: 4777\n",
      "loss None\n",
      "batch time cost: 5.301891088485718\n",
      "Epoch: 0, batch: 4778\n",
      "loss None\n",
      "batch time cost: 5.64762020111084\n",
      "Epoch: 0, batch: 4779\n",
      "loss None\n",
      "batch time cost: 5.256732940673828\n",
      "Epoch: 0, batch: 4780\n",
      "loss None\n",
      "batch time cost: 5.295742988586426\n",
      "Relu Train Epoch: 0 [305920/318582 (1%)]\tLoss: 0.779844\n",
      "Epoch: 0, batch: 4781\n",
      "loss None\n",
      "batch time cost: 5.272291660308838\n",
      "Epoch: 0, batch: 4782\n",
      "loss None\n",
      "batch time cost: 6.7909088134765625\n",
      "Epoch: 0, batch: 4783\n",
      "loss None\n",
      "batch time cost: 7.45933198928833\n",
      "Epoch: 0, batch: 4784\n",
      "loss None\n",
      "batch time cost: 7.624693155288696\n",
      "Epoch: 0, batch: 4785\n",
      "loss None\n",
      "batch time cost: 5.833832025527954\n",
      "Epoch: 0, batch: 4786\n",
      "loss None\n",
      "batch time cost: 5.370068788528442\n",
      "Epoch: 0, batch: 4787\n",
      "loss None\n",
      "batch time cost: 6.209316968917847\n",
      "Epoch: 0, batch: 4788\n",
      "loss None\n",
      "batch time cost: 6.801668167114258\n",
      "Epoch: 0, batch: 4789\n",
      "loss None\n",
      "batch time cost: 8.031234979629517\n",
      "Epoch: 0, batch: 4790\n",
      "loss None\n",
      "batch time cost: 8.526778936386108\n",
      "Relu Train Epoch: 0 [306560/318582 (1%)]\tLoss: 0.875378\n",
      "Epoch: 0, batch: 4791\n",
      "loss None\n",
      "batch time cost: 8.106781005859375\n",
      "Epoch: 0, batch: 4792\n",
      "loss None\n",
      "batch time cost: 8.414974927902222\n",
      "Epoch: 0, batch: 4793\n",
      "loss None\n",
      "batch time cost: 8.905682802200317\n",
      "Epoch: 0, batch: 4794\n",
      "loss None\n",
      "batch time cost: 6.466102123260498\n",
      "Epoch: 0, batch: 4795\n",
      "loss None\n",
      "batch time cost: 5.37646484375\n",
      "Epoch: 0, batch: 4796\n",
      "loss None\n",
      "batch time cost: 5.335602045059204\n",
      "Epoch: 0, batch: 4797\n",
      "loss None\n",
      "batch time cost: 5.758687973022461\n",
      "Epoch: 0, batch: 4798\n",
      "loss None\n",
      "batch time cost: 5.391903877258301\n",
      "Epoch: 0, batch: 4799\n",
      "loss None\n",
      "batch time cost: 5.445966958999634\n",
      "Epoch: 0, batch: 4800\n",
      "loss None\n",
      "batch time cost: 5.630478858947754\n",
      "Relu Train Epoch: 0 [307200/318582 (1%)]\tLoss: 0.908034\n",
      "Epoch: 0, batch: 4801\n",
      "loss None\n",
      "batch time cost: 5.235419034957886\n",
      "Epoch: 0, batch: 4802\n",
      "loss None\n",
      "batch time cost: 5.3389809131622314\n",
      "Epoch: 0, batch: 4803\n",
      "loss None\n",
      "batch time cost: 5.306904077529907\n",
      "Epoch: 0, batch: 4804\n",
      "loss None\n",
      "batch time cost: 5.277055978775024\n",
      "Epoch: 0, batch: 4805\n",
      "loss None\n",
      "batch time cost: 5.410674810409546\n",
      "Epoch: 0, batch: 4806\n",
      "loss None\n",
      "batch time cost: 6.343724012374878\n",
      "Epoch: 0, batch: 4807\n",
      "loss None\n",
      "batch time cost: 8.367632150650024\n",
      "Epoch: 0, batch: 4808\n",
      "loss None\n",
      "batch time cost: 5.332603931427002\n",
      "Epoch: 0, batch: 4809\n",
      "loss None\n",
      "batch time cost: 5.287276029586792\n",
      "Epoch: 0, batch: 4810\n",
      "loss None\n",
      "batch time cost: 5.286029100418091\n",
      "Relu Train Epoch: 0 [307840/318582 (1%)]\tLoss: 0.854317\n",
      "Epoch: 0, batch: 4811\n",
      "loss None\n",
      "batch time cost: 5.242098331451416\n",
      "Epoch: 0, batch: 4812\n",
      "loss None\n",
      "batch time cost: 5.175035238265991\n",
      "Epoch: 0, batch: 4813\n",
      "loss None\n",
      "batch time cost: 5.304818153381348\n",
      "Epoch: 0, batch: 4814\n",
      "loss None\n",
      "batch time cost: 6.7372963428497314\n",
      "Epoch: 0, batch: 4815\n",
      "loss None\n",
      "batch time cost: 6.289385080337524\n",
      "Epoch: 0, batch: 4816\n",
      "loss None\n",
      "batch time cost: 5.409616947174072\n",
      "Epoch: 0, batch: 4817\n",
      "loss None\n",
      "batch time cost: 5.251935005187988\n",
      "Epoch: 0, batch: 4818\n",
      "loss None\n",
      "batch time cost: 5.298435211181641\n",
      "Epoch: 0, batch: 4819\n",
      "loss None\n",
      "batch time cost: 5.298652172088623\n",
      "Epoch: 0, batch: 4820\n",
      "loss None\n",
      "batch time cost: 8.921854972839355\n",
      "Relu Train Epoch: 0 [308480/318582 (1%)]\tLoss: 0.705907\n",
      "Epoch: 0, batch: 4821\n",
      "loss None\n",
      "batch time cost: 9.404639959335327\n",
      "Epoch: 0, batch: 4822\n",
      "loss None\n",
      "batch time cost: 8.238969087600708\n",
      "Epoch: 0, batch: 4823\n",
      "loss None\n",
      "batch time cost: 6.1167449951171875\n",
      "Epoch: 0, batch: 4824\n",
      "loss None\n",
      "batch time cost: 5.381287097930908\n",
      "Epoch: 0, batch: 4825\n",
      "loss None\n",
      "batch time cost: 5.379906892776489\n",
      "Epoch: 0, batch: 4826\n",
      "loss None\n",
      "batch time cost: 5.2944557666778564\n",
      "Epoch: 0, batch: 4827\n",
      "loss None\n",
      "batch time cost: 5.247528076171875\n",
      "Epoch: 0, batch: 4828\n",
      "loss None\n",
      "batch time cost: 5.296058177947998\n",
      "Epoch: 0, batch: 4829\n",
      "loss None\n",
      "batch time cost: 5.6454079151153564\n",
      "Epoch: 0, batch: 4830\n",
      "loss None\n",
      "batch time cost: 5.361937046051025\n",
      "Relu Train Epoch: 0 [309120/318582 (1%)]\tLoss: 0.876076\n",
      "Epoch: 0, batch: 4831\n",
      "loss None\n",
      "batch time cost: 5.202404737472534\n",
      "Epoch: 0, batch: 4832\n",
      "loss None\n",
      "batch time cost: 5.3277459144592285\n",
      "Epoch: 0, batch: 4833\n",
      "loss None\n",
      "batch time cost: 5.305121183395386\n",
      "Epoch: 0, batch: 4834\n",
      "loss None\n",
      "batch time cost: 5.273571729660034\n",
      "Epoch: 0, batch: 4835\n",
      "loss None\n",
      "batch time cost: 5.283168077468872\n",
      "Epoch: 0, batch: 4836\n",
      "loss None\n",
      "batch time cost: 5.670819997787476\n",
      "Epoch: 0, batch: 4837\n",
      "loss None\n",
      "batch time cost: 5.368450164794922\n",
      "Epoch: 0, batch: 4838\n",
      "loss None\n",
      "batch time cost: 5.379734039306641\n",
      "Epoch: 0, batch: 4839\n",
      "loss None\n",
      "batch time cost: 7.1425087451934814\n",
      "Epoch: 0, batch: 4840\n",
      "loss None\n",
      "batch time cost: 6.785853147506714\n",
      "Relu Train Epoch: 0 [309760/318582 (1%)]\tLoss: 0.777889\n",
      "Epoch: 0, batch: 4841\n",
      "loss None\n",
      "batch time cost: 5.632822036743164\n",
      "Epoch: 0, batch: 4842\n",
      "loss None\n",
      "batch time cost: 5.271703004837036\n",
      "Epoch: 0, batch: 4843\n",
      "loss None\n",
      "batch time cost: 5.66599702835083\n",
      "Epoch: 0, batch: 4844\n",
      "loss None\n",
      "batch time cost: 5.311495780944824\n",
      "Epoch: 0, batch: 4845\n",
      "loss None\n",
      "batch time cost: 5.275441884994507\n",
      "Epoch: 0, batch: 4846\n",
      "loss None\n",
      "batch time cost: 5.319683074951172\n",
      "Epoch: 0, batch: 4847\n",
      "loss None\n",
      "batch time cost: 5.316275119781494\n",
      "Epoch: 0, batch: 4848\n",
      "loss None\n",
      "batch time cost: 5.363692998886108\n",
      "Epoch: 0, batch: 4849\n",
      "loss None\n",
      "batch time cost: 5.264601707458496\n",
      "Epoch: 0, batch: 4850\n",
      "loss None\n",
      "batch time cost: 5.592619895935059\n",
      "Relu Train Epoch: 0 [310400/318582 (1%)]\tLoss: 0.968647\n",
      "Epoch: 0, batch: 4851\n",
      "loss None\n",
      "batch time cost: 5.3236799240112305\n",
      "Epoch: 0, batch: 4852\n",
      "loss None\n",
      "batch time cost: 5.314499139785767\n",
      "Epoch: 0, batch: 4853\n",
      "loss None\n",
      "batch time cost: 5.319120168685913\n",
      "Epoch: 0, batch: 4854\n",
      "loss None\n",
      "batch time cost: 5.317240953445435\n",
      "Epoch: 0, batch: 4855\n",
      "loss None\n",
      "batch time cost: 5.265555381774902\n",
      "Epoch: 0, batch: 4856\n",
      "loss None\n",
      "batch time cost: 5.803171873092651\n",
      "Epoch: 0, batch: 4857\n",
      "loss None\n",
      "batch time cost: 5.3790247440338135\n",
      "Epoch: 0, batch: 4858\n",
      "loss None\n",
      "batch time cost: 5.6766357421875\n",
      "Epoch: 0, batch: 4859\n",
      "loss None\n",
      "batch time cost: 5.344917058944702\n",
      "Epoch: 0, batch: 4860\n",
      "loss None\n",
      "batch time cost: 5.3795788288116455\n",
      "Relu Train Epoch: 0 [311040/318582 (1%)]\tLoss: 0.824232\n",
      "Epoch: 0, batch: 4861\n",
      "loss None\n",
      "batch time cost: 5.342808961868286\n",
      "Epoch: 0, batch: 4862\n",
      "loss None\n",
      "batch time cost: 5.329007148742676\n",
      "Epoch: 0, batch: 4863\n",
      "loss None\n",
      "batch time cost: 5.285689830780029\n",
      "Epoch: 0, batch: 4864\n",
      "loss None\n",
      "batch time cost: 5.248248815536499\n",
      "Epoch: 0, batch: 4865\n",
      "loss None\n",
      "batch time cost: 5.6632399559021\n",
      "Epoch: 0, batch: 4866\n",
      "loss None\n",
      "batch time cost: 5.251507043838501\n",
      "Epoch: 0, batch: 4867\n",
      "loss None\n",
      "batch time cost: 5.334864854812622\n",
      "Epoch: 0, batch: 4868\n",
      "loss None\n",
      "batch time cost: 5.29978084564209\n",
      "Epoch: 0, batch: 4869\n",
      "loss None\n",
      "batch time cost: 5.312291145324707\n",
      "Epoch: 0, batch: 4870\n",
      "loss None\n",
      "batch time cost: 5.924600839614868\n",
      "Relu Train Epoch: 0 [311680/318582 (1%)]\tLoss: 0.643707\n",
      "Epoch: 0, batch: 4871\n",
      "loss None\n",
      "batch time cost: 5.340403079986572\n",
      "Epoch: 0, batch: 4872\n",
      "loss None\n",
      "batch time cost: 5.717283725738525\n",
      "Epoch: 0, batch: 4873\n",
      "loss None\n",
      "batch time cost: 5.477810859680176\n",
      "Epoch: 0, batch: 4874\n",
      "loss None\n",
      "batch time cost: 5.400088787078857\n",
      "Epoch: 0, batch: 4875\n",
      "loss None\n",
      "batch time cost: 5.399235963821411\n",
      "Epoch: 0, batch: 4876\n",
      "loss None\n",
      "batch time cost: 5.287868976593018\n",
      "Epoch: 0, batch: 4877\n",
      "loss None\n",
      "batch time cost: 5.335893869400024\n",
      "Epoch: 0, batch: 4878\n",
      "loss None\n",
      "batch time cost: 5.774249076843262\n",
      "Epoch: 0, batch: 4879\n",
      "loss None\n",
      "batch time cost: 6.755478858947754\n",
      "Epoch: 0, batch: 4880\n",
      "loss None\n",
      "batch time cost: 6.812563896179199\n",
      "Relu Train Epoch: 0 [312320/318582 (1%)]\tLoss: 0.723594\n",
      "Epoch: 0, batch: 4881\n",
      "loss None\n",
      "batch time cost: 8.778081893920898\n",
      "Epoch: 0, batch: 4882\n",
      "loss None\n",
      "batch time cost: 6.665855884552002\n",
      "Epoch: 0, batch: 4883\n",
      "loss None\n",
      "batch time cost: 6.730741024017334\n",
      "Epoch: 0, batch: 4884\n",
      "loss None\n",
      "batch time cost: 5.461824893951416\n",
      "Epoch: 0, batch: 4885\n",
      "loss None\n",
      "batch time cost: 5.307392120361328\n",
      "Epoch: 0, batch: 4886\n",
      "loss None\n",
      "batch time cost: 6.49536395072937\n",
      "Epoch: 0, batch: 4887\n",
      "loss None\n",
      "batch time cost: 6.792623996734619\n",
      "Epoch: 0, batch: 4888\n",
      "loss None\n",
      "batch time cost: 5.542818069458008\n",
      "Epoch: 0, batch: 4889\n",
      "loss None\n",
      "batch time cost: 5.517090082168579\n",
      "Epoch: 0, batch: 4890\n",
      "loss None\n",
      "batch time cost: 7.757117033004761\n",
      "Relu Train Epoch: 0 [312960/318582 (1%)]\tLoss: 0.773185\n",
      "Epoch: 0, batch: 4891\n",
      "loss None\n",
      "batch time cost: 6.7246198654174805\n",
      "Epoch: 0, batch: 4892\n",
      "loss None\n",
      "batch time cost: 5.407898187637329\n",
      "Epoch: 0, batch: 4893\n",
      "loss None\n",
      "batch time cost: 6.09247612953186\n",
      "Epoch: 0, batch: 4894\n",
      "loss None\n",
      "batch time cost: 7.623586177825928\n",
      "Epoch: 0, batch: 4895\n",
      "loss None\n",
      "batch time cost: 5.751293897628784\n",
      "Epoch: 0, batch: 4896\n",
      "loss None\n",
      "batch time cost: 7.191638946533203\n",
      "Epoch: 0, batch: 4897\n",
      "loss None\n",
      "batch time cost: 6.484157085418701\n",
      "Epoch: 0, batch: 4898\n",
      "loss None\n",
      "batch time cost: 6.134711027145386\n",
      "Epoch: 0, batch: 4899\n",
      "loss None\n",
      "batch time cost: 6.623525142669678\n",
      "Epoch: 0, batch: 4900\n",
      "loss None\n",
      "batch time cost: 6.298394203186035\n",
      "Relu Train Epoch: 0 [313600/318582 (1%)]\tLoss: 0.878046\n",
      "Epoch: 0, batch: 4901\n",
      "loss None\n",
      "batch time cost: 6.142052888870239\n",
      "Epoch: 0, batch: 4902\n",
      "loss None\n",
      "batch time cost: 6.667530059814453\n",
      "Epoch: 0, batch: 4903\n",
      "loss None\n",
      "batch time cost: 7.069824934005737\n",
      "Epoch: 0, batch: 4904\n",
      "loss None\n",
      "batch time cost: 5.887084007263184\n",
      "Epoch: 0, batch: 4905\n",
      "loss None\n",
      "batch time cost: 6.423367023468018\n",
      "Epoch: 0, batch: 4906\n",
      "loss None\n",
      "batch time cost: 6.379667043685913\n",
      "Epoch: 0, batch: 4907\n",
      "loss None\n",
      "batch time cost: 5.82030987739563\n",
      "Epoch: 0, batch: 4908\n",
      "loss None\n",
      "batch time cost: 5.737999200820923\n",
      "Epoch: 0, batch: 4909\n",
      "loss None\n",
      "batch time cost: 5.4710938930511475\n",
      "Epoch: 0, batch: 4910\n",
      "loss None\n",
      "batch time cost: 5.388418674468994\n",
      "Relu Train Epoch: 0 [314240/318582 (1%)]\tLoss: 0.960347\n",
      "Epoch: 0, batch: 4911\n",
      "loss None\n",
      "batch time cost: 5.372607946395874\n",
      "Epoch: 0, batch: 4912\n",
      "loss None\n",
      "batch time cost: 5.602396726608276\n",
      "Epoch: 0, batch: 4913\n",
      "loss None\n",
      "batch time cost: 5.536041021347046\n",
      "Epoch: 0, batch: 4914\n",
      "loss None\n",
      "batch time cost: 5.6132659912109375\n",
      "Epoch: 0, batch: 4915\n",
      "loss None\n",
      "batch time cost: 6.975838899612427\n",
      "Epoch: 0, batch: 4916\n",
      "loss None\n",
      "batch time cost: 5.909432888031006\n",
      "Epoch: 0, batch: 4917\n",
      "loss None\n",
      "batch time cost: 7.24898099899292\n",
      "Epoch: 0, batch: 4918\n",
      "loss None\n",
      "batch time cost: 5.8464601039886475\n",
      "Epoch: 0, batch: 4919\n",
      "loss None\n",
      "batch time cost: 6.426857948303223\n",
      "Epoch: 0, batch: 4920\n",
      "loss None\n",
      "batch time cost: 5.902320861816406\n",
      "Relu Train Epoch: 0 [314880/318582 (1%)]\tLoss: 0.772497\n",
      "Epoch: 0, batch: 4921\n",
      "loss None\n",
      "batch time cost: 5.3462629318237305\n",
      "Epoch: 0, batch: 4922\n",
      "loss None\n",
      "batch time cost: 5.360790014266968\n",
      "Epoch: 0, batch: 4923\n",
      "loss None\n",
      "batch time cost: 6.589285850524902\n",
      "Epoch: 0, batch: 4924\n",
      "loss None\n",
      "batch time cost: 6.882521867752075\n",
      "Epoch: 0, batch: 4925\n",
      "loss None\n",
      "batch time cost: 6.610347032546997\n",
      "Epoch: 0, batch: 4926\n",
      "loss None\n",
      "batch time cost: 7.1426990032196045\n",
      "Epoch: 0, batch: 4927\n",
      "loss None\n",
      "batch time cost: 6.804709196090698\n",
      "Epoch: 0, batch: 4928\n",
      "loss None\n",
      "batch time cost: 7.0263049602508545\n",
      "Epoch: 0, batch: 4929\n",
      "loss None\n",
      "batch time cost: 5.807649850845337\n",
      "Epoch: 0, batch: 4930\n",
      "loss None\n",
      "batch time cost: 6.7748658657073975\n",
      "Relu Train Epoch: 0 [315520/318582 (1%)]\tLoss: 1.052944\n",
      "Epoch: 0, batch: 4931\n",
      "loss None\n",
      "batch time cost: 6.4860358238220215\n",
      "Epoch: 0, batch: 4932\n",
      "loss None\n",
      "batch time cost: 5.3947272300720215\n",
      "Epoch: 0, batch: 4933\n",
      "loss None\n",
      "batch time cost: 5.337068796157837\n",
      "Epoch: 0, batch: 4934\n",
      "loss None\n",
      "batch time cost: 5.419738054275513\n",
      "Epoch: 0, batch: 4935\n",
      "loss None\n",
      "batch time cost: 5.434498071670532\n",
      "Epoch: 0, batch: 4936\n",
      "loss None\n",
      "batch time cost: 6.110754013061523\n",
      "Epoch: 0, batch: 4937\n",
      "loss None\n",
      "batch time cost: 6.624032735824585\n",
      "Epoch: 0, batch: 4938\n",
      "loss None\n",
      "batch time cost: 6.369683027267456\n",
      "Epoch: 0, batch: 4939\n",
      "loss None\n",
      "batch time cost: 5.429723262786865\n",
      "Epoch: 0, batch: 4940\n",
      "loss None\n",
      "batch time cost: 5.576804876327515\n",
      "Relu Train Epoch: 0 [316160/318582 (1%)]\tLoss: 0.967772\n",
      "Epoch: 0, batch: 4941\n",
      "loss None\n",
      "batch time cost: 5.3536601066589355\n",
      "Epoch: 0, batch: 4942\n",
      "loss None\n",
      "batch time cost: 5.773827075958252\n",
      "Epoch: 0, batch: 4943\n",
      "loss None\n",
      "batch time cost: 5.427735805511475\n",
      "Epoch: 0, batch: 4944\n",
      "loss None\n",
      "batch time cost: 6.527848958969116\n",
      "Epoch: 0, batch: 4945\n",
      "loss None\n",
      "batch time cost: 6.923222064971924\n",
      "Epoch: 0, batch: 4946\n",
      "loss None\n",
      "batch time cost: 7.0594940185546875\n",
      "Epoch: 0, batch: 4947\n",
      "loss None\n",
      "batch time cost: 6.620731830596924\n",
      "Epoch: 0, batch: 4948\n",
      "loss None\n",
      "batch time cost: 7.128241062164307\n",
      "Epoch: 0, batch: 4949\n",
      "loss None\n",
      "batch time cost: 6.791862964630127\n",
      "Epoch: 0, batch: 4950\n",
      "loss None\n",
      "batch time cost: 6.624680280685425\n",
      "Relu Train Epoch: 0 [316800/318582 (1%)]\tLoss: 0.723088\n",
      "Epoch: 0, batch: 4951\n",
      "loss None\n",
      "batch time cost: 7.132350921630859\n",
      "Epoch: 0, batch: 4952\n",
      "loss None\n",
      "batch time cost: 6.417939901351929\n",
      "Epoch: 0, batch: 4953\n",
      "loss None\n",
      "batch time cost: 5.480258941650391\n",
      "Epoch: 0, batch: 4954\n",
      "loss None\n",
      "batch time cost: 5.580731153488159\n",
      "Epoch: 0, batch: 4955\n",
      "loss None\n",
      "batch time cost: 5.340121030807495\n",
      "Epoch: 0, batch: 4956\n",
      "loss None\n",
      "batch time cost: 5.951059818267822\n",
      "Epoch: 0, batch: 4957\n",
      "loss None\n",
      "batch time cost: 6.374634027481079\n",
      "Epoch: 0, batch: 4958\n",
      "loss None\n",
      "batch time cost: 7.219011068344116\n",
      "Epoch: 0, batch: 4959\n",
      "loss None\n",
      "batch time cost: 6.277559757232666\n",
      "Epoch: 0, batch: 4960\n",
      "loss None\n",
      "batch time cost: 7.8727850914001465\n",
      "Relu Train Epoch: 0 [317440/318582 (1%)]\tLoss: 0.960053\n",
      "Epoch: 0, batch: 4961\n",
      "loss None\n",
      "batch time cost: 8.789241075515747\n",
      "Epoch: 0, batch: 4962\n",
      "loss None\n",
      "batch time cost: 6.40631103515625\n",
      "Epoch: 0, batch: 4963\n",
      "loss None\n",
      "batch time cost: 5.721218109130859\n",
      "Epoch: 0, batch: 4964\n",
      "loss None\n",
      "batch time cost: 5.732545852661133\n",
      "Epoch: 0, batch: 4965\n",
      "loss None\n",
      "batch time cost: 8.746053218841553\n",
      "Epoch: 0, batch: 4966\n",
      "loss None\n",
      "batch time cost: 6.351339817047119\n",
      "Epoch: 0, batch: 4967\n",
      "loss None\n",
      "batch time cost: 5.416459083557129\n",
      "Epoch: 0, batch: 4968\n",
      "loss None\n",
      "batch time cost: 5.383435964584351\n",
      "Epoch: 0, batch: 4969\n",
      "loss None\n",
      "batch time cost: 9.568154096603394\n",
      "Epoch: 0, batch: 4970\n",
      "loss None\n",
      "batch time cost: 7.522525787353516\n",
      "Relu Train Epoch: 0 [318080/318582 (1%)]\tLoss: 0.591395\n",
      "Epoch: 0, batch: 4971\n",
      "loss None\n",
      "batch time cost: 5.5621349811553955\n",
      "Epoch: 0, batch: 4972\n",
      "loss None\n",
      "batch time cost: 5.546884059906006\n",
      "Epoch: 0, batch: 4973\n",
      "loss None\n",
      "batch time cost: 7.034994840621948\n",
      "Epoch: 0, batch: 4974\n",
      "loss None\n",
      "batch time cost: 5.402071952819824\n",
      "Epoch: 0, batch: 4975\n",
      "loss None\n",
      "batch time cost: 5.299526929855347\n",
      "Epoch: 0, batch: 4976\n",
      "loss None\n",
      "batch time cost: 5.342090845108032\n",
      "Epoch: 0, batch: 4977\n",
      "loss None\n",
      "batch time cost: 4.446278095245361\n",
      "Epoch: 1, batch: 0\n",
      "loss None\n",
      "batch time cost: 5.362607717514038\n",
      "Relu Train Epoch: 1 [0/318582 (0%)]\tLoss: 0.870261\n",
      "Epoch: 1, batch: 1\n",
      "loss None\n",
      "batch time cost: 5.5513811111450195\n",
      "Epoch: 1, batch: 2\n",
      "loss None\n",
      "batch time cost: 7.250955104827881\n",
      "Epoch: 1, batch: 3\n",
      "loss None\n",
      "batch time cost: 7.044924736022949\n",
      "Epoch: 1, batch: 4\n",
      "loss None\n",
      "batch time cost: 5.457527160644531\n",
      "Epoch: 1, batch: 5\n",
      "loss None\n",
      "batch time cost: 5.407847881317139\n",
      "Epoch: 1, batch: 6\n",
      "loss None\n",
      "batch time cost: 5.539873838424683\n",
      "Epoch: 1, batch: 7\n",
      "loss None\n",
      "batch time cost: 5.648866176605225\n",
      "Epoch: 1, batch: 8\n",
      "loss None\n",
      "batch time cost: 5.502130031585693\n",
      "Epoch: 1, batch: 9\n",
      "loss None\n",
      "batch time cost: 5.475184917449951\n",
      "Epoch: 1, batch: 10\n",
      "loss None\n",
      "batch time cost: 7.241520881652832\n",
      "Relu Train Epoch: 1 [640/318582 (0%)]\tLoss: 0.931815\n",
      "Epoch: 1, batch: 11\n",
      "loss None\n",
      "batch time cost: 5.44421911239624\n",
      "Epoch: 1, batch: 12\n",
      "loss None\n",
      "batch time cost: 6.716943740844727\n",
      "Epoch: 1, batch: 13\n",
      "loss None\n",
      "batch time cost: 8.7623450756073\n",
      "Epoch: 1, batch: 14\n",
      "loss None\n",
      "batch time cost: 7.2273828983306885\n",
      "Epoch: 1, batch: 15\n",
      "loss None\n",
      "batch time cost: 5.524427175521851\n",
      "Epoch: 1, batch: 16\n",
      "loss None\n",
      "batch time cost: 5.4314422607421875\n",
      "Epoch: 1, batch: 17\n",
      "loss None\n",
      "batch time cost: 9.173577070236206\n",
      "Epoch: 1, batch: 18\n",
      "loss None\n",
      "batch time cost: 5.65320086479187\n",
      "Epoch: 1, batch: 19\n",
      "loss None\n",
      "batch time cost: 5.39204216003418\n",
      "Epoch: 1, batch: 20\n",
      "loss None\n",
      "batch time cost: 5.305472135543823\n",
      "Relu Train Epoch: 1 [1280/318582 (0%)]\tLoss: 0.879303\n",
      "Epoch: 1, batch: 21\n",
      "loss None\n",
      "batch time cost: 5.511076927185059\n",
      "Epoch: 1, batch: 22\n",
      "loss None\n",
      "batch time cost: 5.363272190093994\n",
      "Epoch: 1, batch: 23\n",
      "loss None\n",
      "batch time cost: 5.286602020263672\n",
      "Epoch: 1, batch: 24\n",
      "loss None\n",
      "batch time cost: 5.811741828918457\n",
      "Epoch: 1, batch: 25\n",
      "loss None\n",
      "batch time cost: 5.372676849365234\n",
      "Epoch: 1, batch: 26\n",
      "loss None\n",
      "batch time cost: 5.453397989273071\n",
      "Epoch: 1, batch: 27\n",
      "loss None\n",
      "batch time cost: 5.58600378036499\n",
      "Epoch: 1, batch: 28\n",
      "loss None\n",
      "batch time cost: 5.4111528396606445\n",
      "Epoch: 1, batch: 29\n",
      "loss None\n",
      "batch time cost: 5.356875896453857\n",
      "Epoch: 1, batch: 30\n",
      "loss None\n",
      "batch time cost: 5.320688247680664\n",
      "Relu Train Epoch: 1 [1920/318582 (0%)]\tLoss: 0.975678\n",
      "Epoch: 1, batch: 31\n",
      "loss None\n",
      "batch time cost: 5.286139249801636\n",
      "Epoch: 1, batch: 32\n",
      "loss None\n",
      "batch time cost: 6.559901237487793\n",
      "Epoch: 1, batch: 33\n",
      "loss None\n",
      "batch time cost: 5.425210952758789\n",
      "Epoch: 1, batch: 34\n",
      "loss None\n",
      "batch time cost: 5.294964075088501\n",
      "Epoch: 1, batch: 35\n",
      "loss None\n",
      "batch time cost: 5.306916952133179\n",
      "Epoch: 1, batch: 36\n",
      "loss None\n",
      "batch time cost: 7.114936113357544\n",
      "Epoch: 1, batch: 37\n",
      "loss None\n",
      "batch time cost: 7.047597646713257\n",
      "Epoch: 1, batch: 38\n",
      "loss None\n",
      "batch time cost: 9.74384593963623\n",
      "Epoch: 1, batch: 39\n",
      "loss None\n",
      "batch time cost: 16.474419832229614\n",
      "Epoch: 1, batch: 40\n",
      "loss None\n",
      "batch time cost: 13.895408153533936\n",
      "Relu Train Epoch: 1 [2560/318582 (0%)]\tLoss: 0.812382\n",
      "Epoch: 1, batch: 41\n",
      "loss None\n",
      "batch time cost: 14.130079984664917\n",
      "Epoch: 1, batch: 42\n",
      "loss None\n",
      "batch time cost: 16.34928297996521\n",
      "Epoch: 1, batch: 43\n",
      "loss None\n",
      "batch time cost: 15.53704023361206\n",
      "Epoch: 1, batch: 44\n",
      "loss None\n",
      "batch time cost: 13.735416889190674\n",
      "Epoch: 1, batch: 45\n",
      "loss None\n",
      "batch time cost: 13.292253017425537\n",
      "Epoch: 1, batch: 46\n",
      "loss None\n",
      "batch time cost: 15.163810014724731\n",
      "Epoch: 1, batch: 47\n",
      "loss None\n",
      "batch time cost: 16.390609979629517\n",
      "Epoch: 1, batch: 48\n",
      "loss None\n",
      "batch time cost: 15.181535005569458\n",
      "Epoch: 1, batch: 49\n",
      "loss None\n",
      "batch time cost: 15.895969152450562\n",
      "Epoch: 1, batch: 50\n",
      "loss None\n",
      "batch time cost: 16.559403896331787\n",
      "Relu Train Epoch: 1 [3200/318582 (0%)]\tLoss: 0.773820\n",
      "Epoch: 1, batch: 51\n",
      "loss None\n",
      "batch time cost: 15.981924057006836\n",
      "Epoch: 1, batch: 52\n",
      "loss None\n",
      "batch time cost: 13.666239023208618\n",
      "Epoch: 1, batch: 53\n",
      "loss None\n",
      "batch time cost: 15.562431812286377\n",
      "Epoch: 1, batch: 54\n",
      "loss None\n",
      "batch time cost: 15.500072956085205\n",
      "Epoch: 1, batch: 55\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [29], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m model \u001B[38;5;241m=\u001B[39m Discriminator2mean()\n\u001B[0;32m----> 2\u001B[0m \u001B[43mtrain_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn [27], line 9\u001B[0m, in \u001B[0;36mtrain_epoch\u001B[0;34m(data_loader, discriminator, args)\u001B[0m\n\u001B[1;32m      7\u001B[0m data, target \u001B[38;5;241m=\u001B[39m data, target\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m) \u001B[38;5;66;03m# data is 2-d list [batch_size, length(after padding)], target is 1-d list [batch_size]\u001B[39;00m\n\u001B[1;32m      8\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m----> 9\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43mdiscriminator\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     10\u001B[0m loss \u001B[38;5;241m=\u001B[39m jt\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mnll_loss(output, target)\n\u001B[1;32m     11\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep(loss)\n",
      "File \u001B[0;32m/opt/miniconda3/envs/pplm/lib/python3.8/site-packages/jittor/__init__.py:1103\u001B[0m, in \u001B[0;36mModule.__call__\u001B[0;34m(self, *args, **kw)\u001B[0m\n\u001B[1;32m   1102\u001B[0m \u001B[39mdef\u001B[39;00m \u001B[39m__call__\u001B[39m(\u001B[39mself\u001B[39m, \u001B[39m*\u001B[39margs, \u001B[39m*\u001B[39m\u001B[39m*\u001B[39mkw):\n\u001B[0;32m-> 1103\u001B[0m     \u001B[39mreturn\u001B[39;00m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mexecute(\u001B[39m*\u001B[39;49margs, \u001B[39m*\u001B[39;49m\u001B[39m*\u001B[39;49mkw)\n",
      "Cell \u001B[0;32mIn [24], line 32\u001B[0m, in \u001B[0;36mDiscriminator2mean.execute\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     30\u001B[0m mask_src \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(mask_src\u001B[38;5;241m.\u001B[39mtolist())\n\u001B[1;32m     31\u001B[0m x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(x\u001B[38;5;241m.\u001B[39mtolist(),dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mlong)\n\u001B[0;32m---> 32\u001B[0m output_dict \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m     33\u001B[0m hidden \u001B[38;5;241m=\u001B[39m output_dict\u001B[38;5;241m.\u001B[39mhidden_states[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m     35\u001B[0m hidden \u001B[38;5;241m=\u001B[39m hidden\u001B[38;5;241m.\u001B[39mpermute(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m/opt/miniconda3/envs/pplm/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1186\u001B[0m \u001B[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1187\u001B[0m \u001B[39m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1188\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mnot\u001B[39;00m (\u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_backward_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_forward_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_forward_pre_hooks \u001B[39mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1189\u001B[0m         \u001B[39mor\u001B[39;00m _global_forward_hooks \u001B[39mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1190\u001B[0m     \u001B[39mreturn\u001B[39;00m forward_call(\u001B[39m*\u001B[39;49m\u001B[39minput\u001B[39;49m, \u001B[39m*\u001B[39;49m\u001B[39m*\u001B[39;49mkwargs)\n\u001B[1;32m   1191\u001B[0m \u001B[39m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[39m=\u001B[39m [], []\n",
      "File \u001B[0;32m/opt/miniconda3/envs/pplm/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py:1046\u001B[0m, in \u001B[0;36mGPT2LMHeadModel.forward\u001B[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m   1038\u001B[0m \u001B[39mr\u001B[39m\u001B[39m\"\"\"\u001B[39;00m\n\u001B[1;32m   1039\u001B[0m \u001B[39mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001B[39;00m\n\u001B[1;32m   1040\u001B[0m \u001B[39m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001B[39;00m\n\u001B[1;32m   1041\u001B[0m \u001B[39m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001B[39;00m\n\u001B[1;32m   1042\u001B[0m \u001B[39m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001B[39;00m\n\u001B[1;32m   1043\u001B[0m \u001B[39m\"\"\"\u001B[39;00m\n\u001B[1;32m   1044\u001B[0m return_dict \u001B[39m=\u001B[39m return_dict \u001B[39mif\u001B[39;00m return_dict \u001B[39mis\u001B[39;00m \u001B[39mnot\u001B[39;00m \u001B[39mNone\u001B[39;00m \u001B[39melse\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mconfig\u001B[39m.\u001B[39muse_return_dict\n\u001B[0;32m-> 1046\u001B[0m transformer_outputs \u001B[39m=\u001B[39m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mtransformer(\n\u001B[1;32m   1047\u001B[0m     input_ids,\n\u001B[1;32m   1048\u001B[0m     past_key_values\u001B[39m=\u001B[39;49mpast_key_values,\n\u001B[1;32m   1049\u001B[0m     attention_mask\u001B[39m=\u001B[39;49mattention_mask,\n\u001B[1;32m   1050\u001B[0m     token_type_ids\u001B[39m=\u001B[39;49mtoken_type_ids,\n\u001B[1;32m   1051\u001B[0m     position_ids\u001B[39m=\u001B[39;49mposition_ids,\n\u001B[1;32m   1052\u001B[0m     head_mask\u001B[39m=\u001B[39;49mhead_mask,\n\u001B[1;32m   1053\u001B[0m     inputs_embeds\u001B[39m=\u001B[39;49minputs_embeds,\n\u001B[1;32m   1054\u001B[0m     encoder_hidden_states\u001B[39m=\u001B[39;49mencoder_hidden_states,\n\u001B[1;32m   1055\u001B[0m     encoder_attention_mask\u001B[39m=\u001B[39;49mencoder_attention_mask,\n\u001B[1;32m   1056\u001B[0m     use_cache\u001B[39m=\u001B[39;49muse_cache,\n\u001B[1;32m   1057\u001B[0m     output_attentions\u001B[39m=\u001B[39;49moutput_attentions,\n\u001B[1;32m   1058\u001B[0m     output_hidden_states\u001B[39m=\u001B[39;49moutput_hidden_states,\n\u001B[1;32m   1059\u001B[0m     return_dict\u001B[39m=\u001B[39;49mreturn_dict,\n\u001B[1;32m   1060\u001B[0m )\n\u001B[1;32m   1061\u001B[0m hidden_states \u001B[39m=\u001B[39m transformer_outputs[\u001B[39m0\u001B[39m]\n\u001B[1;32m   1063\u001B[0m \u001B[39m# Set device for model parallelism\u001B[39;00m\n",
      "File \u001B[0;32m/opt/miniconda3/envs/pplm/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1186\u001B[0m \u001B[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1187\u001B[0m \u001B[39m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1188\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mnot\u001B[39;00m (\u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_backward_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_forward_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_forward_pre_hooks \u001B[39mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1189\u001B[0m         \u001B[39mor\u001B[39;00m _global_forward_hooks \u001B[39mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1190\u001B[0m     \u001B[39mreturn\u001B[39;00m forward_call(\u001B[39m*\u001B[39;49m\u001B[39minput\u001B[39;49m, \u001B[39m*\u001B[39;49m\u001B[39m*\u001B[39;49mkwargs)\n\u001B[1;32m   1191\u001B[0m \u001B[39m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[39m=\u001B[39m [], []\n",
      "File \u001B[0;32m/opt/miniconda3/envs/pplm/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py:889\u001B[0m, in \u001B[0;36mGPT2Model.forward\u001B[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m    879\u001B[0m     outputs \u001B[39m=\u001B[39m torch\u001B[39m.\u001B[39mutils\u001B[39m.\u001B[39mcheckpoint\u001B[39m.\u001B[39mcheckpoint(\n\u001B[1;32m    880\u001B[0m         create_custom_forward(block),\n\u001B[1;32m    881\u001B[0m         hidden_states,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    886\u001B[0m         encoder_attention_mask,\n\u001B[1;32m    887\u001B[0m     )\n\u001B[1;32m    888\u001B[0m \u001B[39melse\u001B[39;00m:\n\u001B[0;32m--> 889\u001B[0m     outputs \u001B[39m=\u001B[39m block(\n\u001B[1;32m    890\u001B[0m         hidden_states,\n\u001B[1;32m    891\u001B[0m         layer_past\u001B[39m=\u001B[39;49mlayer_past,\n\u001B[1;32m    892\u001B[0m         attention_mask\u001B[39m=\u001B[39;49mattention_mask,\n\u001B[1;32m    893\u001B[0m         head_mask\u001B[39m=\u001B[39;49mhead_mask[i],\n\u001B[1;32m    894\u001B[0m         encoder_hidden_states\u001B[39m=\u001B[39;49mencoder_hidden_states,\n\u001B[1;32m    895\u001B[0m         encoder_attention_mask\u001B[39m=\u001B[39;49mencoder_attention_mask,\n\u001B[1;32m    896\u001B[0m         use_cache\u001B[39m=\u001B[39;49muse_cache,\n\u001B[1;32m    897\u001B[0m         output_attentions\u001B[39m=\u001B[39;49moutput_attentions,\n\u001B[1;32m    898\u001B[0m     )\n\u001B[1;32m    900\u001B[0m hidden_states \u001B[39m=\u001B[39m outputs[\u001B[39m0\u001B[39m]\n\u001B[1;32m    901\u001B[0m \u001B[39mif\u001B[39;00m use_cache \u001B[39mis\u001B[39;00m \u001B[39mTrue\u001B[39;00m:\n",
      "File \u001B[0;32m/opt/miniconda3/envs/pplm/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1186\u001B[0m \u001B[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1187\u001B[0m \u001B[39m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1188\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mnot\u001B[39;00m (\u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_backward_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_forward_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_forward_pre_hooks \u001B[39mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1189\u001B[0m         \u001B[39mor\u001B[39;00m _global_forward_hooks \u001B[39mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1190\u001B[0m     \u001B[39mreturn\u001B[39;00m forward_call(\u001B[39m*\u001B[39;49m\u001B[39minput\u001B[39;49m, \u001B[39m*\u001B[39;49m\u001B[39m*\u001B[39;49mkwargs)\n\u001B[1;32m   1191\u001B[0m \u001B[39m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[39m=\u001B[39m [], []\n",
      "File \u001B[0;32m/opt/miniconda3/envs/pplm/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py:389\u001B[0m, in \u001B[0;36mGPT2Block.forward\u001B[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001B[0m\n\u001B[1;32m    387\u001B[0m residual \u001B[39m=\u001B[39m hidden_states\n\u001B[1;32m    388\u001B[0m hidden_states \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mln_1(hidden_states)\n\u001B[0;32m--> 389\u001B[0m attn_outputs \u001B[39m=\u001B[39m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mattn(\n\u001B[1;32m    390\u001B[0m     hidden_states,\n\u001B[1;32m    391\u001B[0m     layer_past\u001B[39m=\u001B[39;49mlayer_past,\n\u001B[1;32m    392\u001B[0m     attention_mask\u001B[39m=\u001B[39;49mattention_mask,\n\u001B[1;32m    393\u001B[0m     head_mask\u001B[39m=\u001B[39;49mhead_mask,\n\u001B[1;32m    394\u001B[0m     use_cache\u001B[39m=\u001B[39;49muse_cache,\n\u001B[1;32m    395\u001B[0m     output_attentions\u001B[39m=\u001B[39;49moutput_attentions,\n\u001B[1;32m    396\u001B[0m )\n\u001B[1;32m    397\u001B[0m attn_output \u001B[39m=\u001B[39m attn_outputs[\u001B[39m0\u001B[39m]  \u001B[39m# output_attn: a, present, (attentions)\u001B[39;00m\n\u001B[1;32m    398\u001B[0m outputs \u001B[39m=\u001B[39m attn_outputs[\u001B[39m1\u001B[39m:]\n",
      "File \u001B[0;32m/opt/miniconda3/envs/pplm/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1186\u001B[0m \u001B[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1187\u001B[0m \u001B[39m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1188\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mnot\u001B[39;00m (\u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_backward_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_forward_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_forward_pre_hooks \u001B[39mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1189\u001B[0m         \u001B[39mor\u001B[39;00m _global_forward_hooks \u001B[39mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1190\u001B[0m     \u001B[39mreturn\u001B[39;00m forward_call(\u001B[39m*\u001B[39;49m\u001B[39minput\u001B[39;49m, \u001B[39m*\u001B[39;49m\u001B[39m*\u001B[39;49mkwargs)\n\u001B[1;32m   1191\u001B[0m \u001B[39m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[39m=\u001B[39m [], []\n",
      "File \u001B[0;32m/opt/miniconda3/envs/pplm/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py:311\u001B[0m, in \u001B[0;36mGPT2Attention.forward\u001B[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001B[0m\n\u001B[1;32m    309\u001B[0m     attention_mask \u001B[39m=\u001B[39m encoder_attention_mask\n\u001B[1;32m    310\u001B[0m \u001B[39melse\u001B[39;00m:\n\u001B[0;32m--> 311\u001B[0m     query, key, value \u001B[39m=\u001B[39m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mc_attn(hidden_states)\u001B[39m.\u001B[39msplit(\u001B[39mself\u001B[39m\u001B[39m.\u001B[39msplit_size, dim\u001B[39m=\u001B[39m\u001B[39m2\u001B[39m)\n\u001B[1;32m    313\u001B[0m query \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_split_heads(query, \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mnum_heads, \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mhead_dim)\n\u001B[1;32m    314\u001B[0m key \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_split_heads(key, \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mnum_heads, \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mhead_dim)\n",
      "File \u001B[0;32m/opt/miniconda3/envs/pplm/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1186\u001B[0m \u001B[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1187\u001B[0m \u001B[39m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1188\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mnot\u001B[39;00m (\u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_backward_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_forward_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_forward_pre_hooks \u001B[39mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1189\u001B[0m         \u001B[39mor\u001B[39;00m _global_forward_hooks \u001B[39mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1190\u001B[0m     \u001B[39mreturn\u001B[39;00m forward_call(\u001B[39m*\u001B[39;49m\u001B[39minput\u001B[39;49m, \u001B[39m*\u001B[39;49m\u001B[39m*\u001B[39;49mkwargs)\n\u001B[1;32m   1191\u001B[0m \u001B[39m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[39m=\u001B[39m [], []\n",
      "File \u001B[0;32m/opt/miniconda3/envs/pplm/lib/python3.8/site-packages/transformers/pytorch_utils.py:112\u001B[0m, in \u001B[0;36mConv1D.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    110\u001B[0m \u001B[39mdef\u001B[39;00m \u001B[39mforward\u001B[39m(\u001B[39mself\u001B[39m, x):\n\u001B[1;32m    111\u001B[0m     size_out \u001B[39m=\u001B[39m x\u001B[39m.\u001B[39msize()[:\u001B[39m-\u001B[39m\u001B[39m1\u001B[39m] \u001B[39m+\u001B[39m (\u001B[39mself\u001B[39m\u001B[39m.\u001B[39mnf,)\n\u001B[0;32m--> 112\u001B[0m     x \u001B[39m=\u001B[39m torch\u001B[39m.\u001B[39;49maddmm(\u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mbias, x\u001B[39m.\u001B[39;49mview(\u001B[39m-\u001B[39;49m\u001B[39m1\u001B[39;49m, x\u001B[39m.\u001B[39;49msize(\u001B[39m-\u001B[39;49m\u001B[39m1\u001B[39;49m)), \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mweight)\n\u001B[1;32m    113\u001B[0m     x \u001B[39m=\u001B[39m x\u001B[39m.\u001B[39mview(size_out)\n\u001B[1;32m    114\u001B[0m     \u001B[39mreturn\u001B[39;00m x\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model = Discriminator2mean()\n",
    "train_epoch(train_dataset, model, args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('pplm')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "54f0cfbc081d2dbd9b32bca22e677f6cddd072e682c5c874abb322034cb62c09"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
